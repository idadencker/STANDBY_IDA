{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b7e62b0-9f07-4839-8543-3691f9f7b10a",
   "metadata": {},
   "source": [
    "# Testing classifiers on the 10k pairs dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477b01f2-c45f-4f84-a823-e03bffd42f8f",
   "metadata": {},
   "source": [
    "## Loading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "102009ac-072c-4bbb-a53b-24be2a65f8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas \n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "588870b4-7f13-457f-90c6-11c553e018d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>replied_to_reply_count</th>\n",
       "      <th>referenced_tweets_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>PNR</th>\n",
       "      <th>...</th>\n",
       "      <th>A/R</th>\n",
       "      <th>fasttext_cos_sim_hate_sentence</th>\n",
       "      <th>fasttext_cos_sim_prosocial_sentence</th>\n",
       "      <th>tweeter_username</th>\n",
       "      <th>tweeter_name</th>\n",
       "      <th>pair_num</th>\n",
       "      <th>type</th>\n",
       "      <th>like_n</th>\n",
       "      <th>retweet_n</th>\n",
       "      <th>quote_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1036583587242549248</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-09-03 21:04:41</td>\n",
       "      <td>1036721666628444160</td>\n",
       "      <td>@frkomo Jeg siger det vel strengt taget bare t...</td>\n",
       "      <td>1666088336</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1036721302692917250</td>\n",
       "      <td>148061237</td>\n",
       "      <td>1311570613</td>\n",
       "      <td>...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0.762309</td>\n",
       "      <td>0.959726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>reply</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1036583587242549248</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-09-03 21:03:14</td>\n",
       "      <td>1036721302692917250</td>\n",
       "      <td>@MonbergSF Sig det til spillerforeningen, som ...</td>\n",
       "      <td>148061237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1666088336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>frkomo</td>\n",
       "      <td>Sarah Agerklint</td>\n",
       "      <td>1</td>\n",
       "      <td>tweet</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>899548260863488002</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-08-21 12:10:42</td>\n",
       "      <td>899604671375052801</td>\n",
       "      <td>@PeterHuggler Had alt det, du vil. Men du skal...</td>\n",
       "      <td>547416021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>899603561323081729</td>\n",
       "      <td>3301029597</td>\n",
       "      <td>1405772015</td>\n",
       "      <td>...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0.836744</td>\n",
       "      <td>0.958750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>reply</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>899548260863488002</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-08-21 12:06:17</td>\n",
       "      <td>899603561323081729</td>\n",
       "      <td>@brianweichardt Jeg hader den her slags: Du gå...</td>\n",
       "      <td>3301029597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>547416021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PeterHuggler</td>\n",
       "      <td>Peter Huggler</td>\n",
       "      <td>2</td>\n",
       "      <td>tweet</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1345496479583113217</td>\n",
       "      <td>da</td>\n",
       "      <td>2021-01-03 12:38:16</td>\n",
       "      <td>1345711074407014400</td>\n",
       "      <td>@nielscallesoe @Heunicke Din første indvending...</td>\n",
       "      <td>87923613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1345524516311748608</td>\n",
       "      <td>23341699</td>\n",
       "      <td>0908801199</td>\n",
       "      <td>...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0.746267</td>\n",
       "      <td>0.957824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>reply</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>1430605648878784513</td>\n",
       "      <td>da</td>\n",
       "      <td>2021-08-25 19:00:13</td>\n",
       "      <td>1430605952722604045</td>\n",
       "      <td>@PSkipperEL Træk den røde linje nu.\\n\\n#VæltMe...</td>\n",
       "      <td>2345329126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>611076925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M_K_Petersen</td>\n",
       "      <td>Michael K. Petersen</td>\n",
       "      <td>9998</td>\n",
       "      <td>tweet</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>822180433681088513</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-01-19 20:55:03</td>\n",
       "      <td>822185628620226560</td>\n",
       "      <td>@sllaursen har svært ved at afgøre om jeg ægte...</td>\n",
       "      <td>546738902</td>\n",
       "      <td>1.0</td>\n",
       "      <td>822180433681088513</td>\n",
       "      <td>43529378</td>\n",
       "      <td>1007802400</td>\n",
       "      <td>...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0.886249</td>\n",
       "      <td>0.839126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9999</td>\n",
       "      <td>reply</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>822180433681088513</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-01-19 20:34:25</td>\n",
       "      <td>822180433681088513</td>\n",
       "      <td>Når et sponsorat rammer ESPN, er man kommet ok...</td>\n",
       "      <td>43529378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>steen</td>\n",
       "      <td>Steen Laursen</td>\n",
       "      <td>9999</td>\n",
       "      <td>tweet</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>953648851721826304</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-01-17 18:22:52</td>\n",
       "      <td>953694124049420288</td>\n",
       "      <td>@emilnielsen @pelledragsted Tak skal du have. ...</td>\n",
       "      <td>26210681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>953655858675757057</td>\n",
       "      <td>19391295</td>\n",
       "      <td>2010772527</td>\n",
       "      <td>...</td>\n",
       "      <td>0-1</td>\n",
       "      <td>0.886244</td>\n",
       "      <td>0.897734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>reply</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>953648851721826304</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-01-17 15:50:49</td>\n",
       "      <td>953655858675757057</td>\n",
       "      <td>Der findes ikke nogen mere irriterende politis...</td>\n",
       "      <td>19391295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19391295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>emilnielsen</td>\n",
       "      <td>Emil Nielsen</td>\n",
       "      <td>10000</td>\n",
       "      <td>tweet</td>\n",
       "      <td>115</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           conversation_id lang           created_at                   id  \\\n",
       "0      1036583587242549248   da  2018-09-03 21:04:41  1036721666628444160   \n",
       "1      1036583587242549248   da  2018-09-03 21:03:14  1036721302692917250   \n",
       "2       899548260863488002   da  2017-08-21 12:10:42   899604671375052801   \n",
       "3       899548260863488002   da  2017-08-21 12:06:17   899603561323081729   \n",
       "4      1345496479583113217   da  2021-01-03 12:38:16  1345711074407014400   \n",
       "...                    ...  ...                  ...                  ...   \n",
       "19995  1430605648878784513   da  2021-08-25 19:00:13  1430605952722604045   \n",
       "19996   822180433681088513   da  2017-01-19 20:55:03   822185628620226560   \n",
       "19997   822180433681088513   da  2017-01-19 20:34:25   822180433681088513   \n",
       "19998   953648851721826304   da  2018-01-17 18:22:52   953694124049420288   \n",
       "19999   953648851721826304   da  2018-01-17 15:50:49   953655858675757057   \n",
       "\n",
       "                                                    text   author_id  \\\n",
       "0      @frkomo Jeg siger det vel strengt taget bare t...  1666088336   \n",
       "1      @MonbergSF Sig det til spillerforeningen, som ...   148061237   \n",
       "2      @PeterHuggler Had alt det, du vil. Men du skal...   547416021   \n",
       "3      @brianweichardt Jeg hader den her slags: Du gå...  3301029597   \n",
       "4      @nielscallesoe @Heunicke Din første indvending...    87923613   \n",
       "...                                                  ...         ...   \n",
       "19995  @PSkipperEL Træk den røde linje nu.\\n\\n#VæltMe...  2345329126   \n",
       "19996  @sllaursen har svært ved at afgøre om jeg ægte...   546738902   \n",
       "19997  Når et sponsorat rammer ESPN, er man kommet ok...    43529378   \n",
       "19998  @emilnielsen @pelledragsted Tak skal du have. ...    26210681   \n",
       "19999  Der findes ikke nogen mere irriterende politis...    19391295   \n",
       "\n",
       "       replied_to_reply_count referenced_tweets_id in_reply_to_user_id  \\\n",
       "0                         1.0  1036721302692917250           148061237   \n",
       "1                         NaN                  NaN          1666088336   \n",
       "2                         1.0   899603561323081729          3301029597   \n",
       "3                         NaN                  NaN           547416021   \n",
       "4                         1.0  1345524516311748608            23341699   \n",
       "...                       ...                  ...                 ...   \n",
       "19995                     NaN                  NaN           611076925   \n",
       "19996                     1.0   822180433681088513            43529378   \n",
       "19997                     NaN                  NaN                 NaN   \n",
       "19998                     0.0   953655858675757057            19391295   \n",
       "19999                     NaN                  NaN            19391295   \n",
       "\n",
       "              PNR  ...  A/R  fasttext_cos_sim_hate_sentence  \\\n",
       "0      1311570613  ...  0-0                        0.762309   \n",
       "1             NaN  ...  NaN                             NaN   \n",
       "2      1405772015  ...  0-0                        0.836744   \n",
       "3             NaN  ...  NaN                             NaN   \n",
       "4      0908801199  ...  0-0                        0.746267   \n",
       "...           ...  ...  ...                             ...   \n",
       "19995         NaN  ...  NaN                             NaN   \n",
       "19996  1007802400  ...  0-0                        0.886249   \n",
       "19997         NaN  ...  NaN                             NaN   \n",
       "19998  2010772527  ...  0-1                        0.886244   \n",
       "19999         NaN  ...  NaN                             NaN   \n",
       "\n",
       "       fasttext_cos_sim_prosocial_sentence  tweeter_username  \\\n",
       "0                                 0.959726               NaN   \n",
       "1                                      NaN            frkomo   \n",
       "2                                 0.958750               NaN   \n",
       "3                                      NaN      PeterHuggler   \n",
       "4                                 0.957824               NaN   \n",
       "...                                    ...               ...   \n",
       "19995                                  NaN      M_K_Petersen   \n",
       "19996                             0.839126               NaN   \n",
       "19997                                  NaN             steen   \n",
       "19998                             0.897734               NaN   \n",
       "19999                                  NaN       emilnielsen   \n",
       "\n",
       "              tweeter_name pair_num   type  like_n retweet_n quote_n  \n",
       "0                      NaN        1  reply       1         0       0  \n",
       "1          Sarah Agerklint        1  tweet       1         0       0  \n",
       "2                      NaN        2  reply       0         0       0  \n",
       "3            Peter Huggler        2  tweet       1         0       0  \n",
       "4                      NaN        3  reply       1         0       0  \n",
       "...                    ...      ...    ...     ...       ...     ...  \n",
       "19995  Michael K. Petersen     9998  tweet      16         0       0  \n",
       "19996                  NaN     9999  reply       3         0       0  \n",
       "19997        Steen Laursen     9999  tweet      13         1       0  \n",
       "19998                  NaN    10000  reply      10         0       0  \n",
       "19999         Emil Nielsen    10000  tweet     115         3       3  \n",
       "\n",
       "[20000 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in data\n",
    "\n",
    "dtype_dict_all = {\n",
    "    'conversation_id': 'object',\n",
    "    'id': 'object',\n",
    "    'author_id': 'object',\n",
    "    'referenced_tweets_id': 'object',\n",
    "    'in_reply_to_user_id': 'object',\n",
    "    'PNR': 'object'\n",
    "}\n",
    "\n",
    "pairs = pd.read_csv('/Users/idahelenedencker/Desktop/STANDBY_Ida/Creating dataset of reference tweets/10k_twitter_pairs.csv', dtype=dtype_dict_all )\n",
    "\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3511ea3-2784-4114-9c4d-3535cb3abdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conversation_id                         object\n",
       "lang                                    object\n",
       "created_at                              object\n",
       "id                                      object\n",
       "text                                    object\n",
       "author_id                               object\n",
       "replied_to_reply_count                 float64\n",
       "referenced_tweets_id                    object\n",
       "in_reply_to_user_id                     object\n",
       "PNR                                     object\n",
       "surveyXact_externke                     object\n",
       "non_unique_twitter_author_id           float64\n",
       "started_survey                         float64\n",
       "rec-nition                             float64\n",
       "attack                                 float64\n",
       "A/R                                     object\n",
       "fasttext_cos_sim_hate_sentence         float64\n",
       "fasttext_cos_sim_prosocial_sentence    float64\n",
       "tweeter_username                        object\n",
       "tweeter_name                            object\n",
       "pair_num                                 int64\n",
       "type                                    object\n",
       "like_n                                   int64\n",
       "retweet_n                                int64\n",
       "quote_n                                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f69710-04ed-4ce6-95aa-63641065f2f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.44.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.24.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.66.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers\n",
    "!pip install --upgrade tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93f6992a-73ce-4951-8c06-a07c4972595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a test df to work with \n",
    "\n",
    "pairs_small= pairs.head(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adc46148-3aea-4364-89a4-93a948918022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "translating: 100%|██████████████████████████| 2000/2000 [52:05<00:00,  1.56s/it]\n",
      "/var/folders/ds/0d9wxy210kx_fvknqn3hcg_h0000gn/T/ipykernel_28024/1558181926.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pairs_small['translated'] = list\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>replied_to_reply_count</th>\n",
       "      <th>referenced_tweets_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>PNR</th>\n",
       "      <th>...</th>\n",
       "      <th>fasttext_cos_sim_hate_sentence</th>\n",
       "      <th>fasttext_cos_sim_prosocial_sentence</th>\n",
       "      <th>tweeter_username</th>\n",
       "      <th>tweeter_name</th>\n",
       "      <th>pair_num</th>\n",
       "      <th>type</th>\n",
       "      <th>like_n</th>\n",
       "      <th>retweet_n</th>\n",
       "      <th>quote_n</th>\n",
       "      <th>translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1036583587242549248</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-09-03 21:04:41</td>\n",
       "      <td>1036721666628444160</td>\n",
       "      <td>@frkomo Jeg siger det vel strengt taget bare t...</td>\n",
       "      <td>1666088336</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1036721302692917250</td>\n",
       "      <td>148061237</td>\n",
       "      <td>1311570613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.762309</td>\n",
       "      <td>0.959726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>reply</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@frkomo I guess I'm saying it strictly just to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1036583587242549248</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-09-03 21:03:14</td>\n",
       "      <td>1036721302692917250</td>\n",
       "      <td>@MonbergSF Sig det til spillerforeningen, som ...</td>\n",
       "      <td>148061237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1666088336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>frkomo</td>\n",
       "      <td>Sarah Agerklint</td>\n",
       "      <td>1</td>\n",
       "      <td>tweet</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@MonbergSF Tell it to the gaming association, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>899548260863488002</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-08-21 12:10:42</td>\n",
       "      <td>899604671375052801</td>\n",
       "      <td>@PeterHuggler Had alt det, du vil. Men du skal...</td>\n",
       "      <td>547416021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>899603561323081729</td>\n",
       "      <td>3301029597</td>\n",
       "      <td>1405772015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836744</td>\n",
       "      <td>0.958750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>reply</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@PeterHuggler Had everything you want. But don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>899548260863488002</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-08-21 12:06:17</td>\n",
       "      <td>899603561323081729</td>\n",
       "      <td>@brianweichardt Jeg hader den her slags: Du gå...</td>\n",
       "      <td>3301029597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>547416021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PeterHuggler</td>\n",
       "      <td>Peter Huggler</td>\n",
       "      <td>2</td>\n",
       "      <td>tweet</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@brianweichardt I hate this kind of thing: You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1345496479583113217</td>\n",
       "      <td>da</td>\n",
       "      <td>2021-01-03 12:38:16</td>\n",
       "      <td>1345711074407014400</td>\n",
       "      <td>@nielscallesoe @Heunicke Din første indvending...</td>\n",
       "      <td>87923613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1345524516311748608</td>\n",
       "      <td>23341699</td>\n",
       "      <td>0908801199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.746267</td>\n",
       "      <td>0.957824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>reply</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@nielsallesoe @Heunicke Your first objection m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1285495153202024448</td>\n",
       "      <td>da</td>\n",
       "      <td>2020-07-21 10:22:06</td>\n",
       "      <td>1285520419529863168</td>\n",
       "      <td>@SimonStoerup @perlysholt Hm. Man ville som ud...</td>\n",
       "      <td>27626050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>383396359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nielsfez</td>\n",
       "      <td>Niels Pedersen</td>\n",
       "      <td>998</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@SimonStoerup @perlysholt Hm. You would be abl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>da</td>\n",
       "      <td>2019-09-18 19:10:18</td>\n",
       "      <td>1174400270710820870</td>\n",
       "      <td>@R4nd4hl @khoenge Sjovt du synes netop Hønge b...</td>\n",
       "      <td>861057936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>72823792</td>\n",
       "      <td>1508892043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736094</td>\n",
       "      <td>0.932785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999</td>\n",
       "      <td>reply</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@R4nd4hl @khoenge Funny you think just Hønge s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>da</td>\n",
       "      <td>2019-09-18 18:50:58</td>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>Detektor har undersøgt det: @khoenge talte usa...</td>\n",
       "      <td>72823792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R4nd4hl</td>\n",
       "      <td>Randahl Fink</td>\n",
       "      <td>999</td>\n",
       "      <td>tweet</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Detector has examined it: @khoenge spoke untru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1481298462238982144</td>\n",
       "      <td>da</td>\n",
       "      <td>2022-01-12 19:25:54</td>\n",
       "      <td>1481346717513662464</td>\n",
       "      <td>@ReneAndersenDK Forskellen er, at ham her også...</td>\n",
       "      <td>805874425988087811</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1481345545721495554</td>\n",
       "      <td>4776986009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787638</td>\n",
       "      <td>0.932775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>reply</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@ReneAndersenDK The difference is that this gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1481298462238982144</td>\n",
       "      <td>da</td>\n",
       "      <td>2022-01-12 19:21:14</td>\n",
       "      <td>1481345545721495554</td>\n",
       "      <td>@baretraet Sådan et mål har vi sgu da alle sam...</td>\n",
       "      <td>4776986009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>805874425988087811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>theotherguy_78</td>\n",
       "      <td>René</td>\n",
       "      <td>1000</td>\n",
       "      <td>tweet</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@baretraet Such a goal have we all made for tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          conversation_id lang           created_at                   id  \\\n",
       "0     1036583587242549248   da  2018-09-03 21:04:41  1036721666628444160   \n",
       "1     1036583587242549248   da  2018-09-03 21:03:14  1036721302692917250   \n",
       "2      899548260863488002   da  2017-08-21 12:10:42   899604671375052801   \n",
       "3      899548260863488002   da  2017-08-21 12:06:17   899603561323081729   \n",
       "4     1345496479583113217   da  2021-01-03 12:38:16  1345711074407014400   \n",
       "...                   ...  ...                  ...                  ...   \n",
       "1995  1285495153202024448   da  2020-07-21 10:22:06  1285520419529863168   \n",
       "1996  1174395406719102976   da  2019-09-18 19:10:18  1174400270710820870   \n",
       "1997  1174395406719102976   da  2019-09-18 18:50:58  1174395406719102976   \n",
       "1998  1481298462238982144   da  2022-01-12 19:25:54  1481346717513662464   \n",
       "1999  1481298462238982144   da  2022-01-12 19:21:14  1481345545721495554   \n",
       "\n",
       "                                                   text           author_id  \\\n",
       "0     @frkomo Jeg siger det vel strengt taget bare t...          1666088336   \n",
       "1     @MonbergSF Sig det til spillerforeningen, som ...           148061237   \n",
       "2     @PeterHuggler Had alt det, du vil. Men du skal...           547416021   \n",
       "3     @brianweichardt Jeg hader den her slags: Du gå...          3301029597   \n",
       "4     @nielscallesoe @Heunicke Din første indvending...            87923613   \n",
       "...                                                 ...                 ...   \n",
       "1995  @SimonStoerup @perlysholt Hm. Man ville som ud...            27626050   \n",
       "1996  @R4nd4hl @khoenge Sjovt du synes netop Hønge b...           861057936   \n",
       "1997  Detektor har undersøgt det: @khoenge talte usa...            72823792   \n",
       "1998  @ReneAndersenDK Forskellen er, at ham her også...  805874425988087811   \n",
       "1999  @baretraet Sådan et mål har vi sgu da alle sam...          4776986009   \n",
       "\n",
       "      replied_to_reply_count referenced_tweets_id in_reply_to_user_id  \\\n",
       "0                        1.0  1036721302692917250           148061237   \n",
       "1                        NaN                  NaN          1666088336   \n",
       "2                        1.0   899603561323081729          3301029597   \n",
       "3                        NaN                  NaN           547416021   \n",
       "4                        1.0  1345524516311748608            23341699   \n",
       "...                      ...                  ...                 ...   \n",
       "1995                     NaN                  NaN           383396359   \n",
       "1996                     0.0  1174395406719102976            72823792   \n",
       "1997                     NaN                  NaN                 NaN   \n",
       "1998                     1.0  1481345545721495554          4776986009   \n",
       "1999                     NaN                  NaN  805874425988087811   \n",
       "\n",
       "             PNR  ... fasttext_cos_sim_hate_sentence  \\\n",
       "0     1311570613  ...                       0.762309   \n",
       "1            NaN  ...                            NaN   \n",
       "2     1405772015  ...                       0.836744   \n",
       "3            NaN  ...                            NaN   \n",
       "4     0908801199  ...                       0.746267   \n",
       "...          ...  ...                            ...   \n",
       "1995         NaN  ...                            NaN   \n",
       "1996  1508892043  ...                       0.736094   \n",
       "1997         NaN  ...                            NaN   \n",
       "1998         NaN  ...                       0.787638   \n",
       "1999         NaN  ...                            NaN   \n",
       "\n",
       "      fasttext_cos_sim_prosocial_sentence  tweeter_username     tweeter_name  \\\n",
       "0                                0.959726               NaN              NaN   \n",
       "1                                     NaN            frkomo  Sarah Agerklint   \n",
       "2                                0.958750               NaN              NaN   \n",
       "3                                     NaN      PeterHuggler    Peter Huggler   \n",
       "4                                0.957824               NaN              NaN   \n",
       "...                                   ...               ...              ...   \n",
       "1995                                  NaN          nielsfez   Niels Pedersen   \n",
       "1996                             0.932785               NaN              NaN   \n",
       "1997                                  NaN           R4nd4hl     Randahl Fink   \n",
       "1998                             0.932775               NaN              NaN   \n",
       "1999                                  NaN    theotherguy_78             René   \n",
       "\n",
       "      pair_num   type  like_n  retweet_n quote_n  \\\n",
       "0            1  reply       1          0       0   \n",
       "1            1  tweet       1          0       0   \n",
       "2            2  reply       0          0       0   \n",
       "3            2  tweet       1          0       0   \n",
       "4            3  reply       1          0       0   \n",
       "...        ...    ...     ...        ...     ...   \n",
       "1995       998  tweet       2          0       0   \n",
       "1996       999  reply       2          0       0   \n",
       "1997       999  tweet      20          3       0   \n",
       "1998      1000  reply       2          0       0   \n",
       "1999      1000  tweet       3          0       0   \n",
       "\n",
       "                                             translated  \n",
       "0     @frkomo I guess I'm saying it strictly just to...  \n",
       "1     @MonbergSF Tell it to the gaming association, ...  \n",
       "2     @PeterHuggler Had everything you want. But don...  \n",
       "3     @brianweichardt I hate this kind of thing: You...  \n",
       "4     @nielsallesoe @Heunicke Your first objection m...  \n",
       "...                                                 ...  \n",
       "1995  @SimonStoerup @perlysholt Hm. You would be abl...  \n",
       "1996  @R4nd4hl @khoenge Funny you think just Hønge s...  \n",
       "1997  Detector has examined it: @khoenge spoke untru...  \n",
       "1998  @ReneAndersenDK The difference is that this gu...  \n",
       "1999  @baretraet Such a goal have we all made for tr...  \n",
       "\n",
       "[2000 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a translated text column (on the small df)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = 'Helsinki-NLP/opus-mt-da-en'\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "def translate(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "    # Generate translation\n",
    "    translated_tokens = model.generate(**inputs)\n",
    "    # Decode the tokens to text\n",
    "    translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "    return translated_text\n",
    "\n",
    "\n",
    "# List to store the scores\n",
    "list = []\n",
    "\n",
    "# Iterate over each text\n",
    "for text in (tqdm(pairs_small['text'], desc= \"translating\")) :\n",
    "    result = translate(text)\n",
    "    # Append to the list\n",
    "    list.append(result)\n",
    "\n",
    "# Add the scores as a new column in the DataFrame\n",
    "pairs_small['translated'] = list\n",
    "pairs_small\n",
    "\n",
    "# Save translated as new df\n",
    "pairs_small.to_csv('/Users/idahelenedencker/Desktop/w_translated_small.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2ca0271-9ad5-4d2f-ade2-fb9f90aeaff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in again\n",
    "dtype_dict_all = {\n",
    "    'conversation_id': 'object',\n",
    "    'id': 'object',\n",
    "    'author_id': 'object',\n",
    "    'referenced_tweets_id': 'object',\n",
    "    'in_reply_to_user_id': 'object',\n",
    "    'PNR': 'object'\n",
    "}\n",
    "\n",
    "pairs_small = pd.read_csv('/Users/idahelenedencker/Desktop/w_translated_small.csv', dtype=dtype_dict_all)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cacf2e3-1d67-40a6-b527-8e6b7defbddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  @frkomo Jeg siger det vel strengt taget bare t...   \n",
      "1  @MonbergSF Sig det til spillerforeningen, som ...   \n",
      "2  @PeterHuggler Had alt det, du vil. Men du skal...   \n",
      "3  @brianweichardt Jeg hader den her slags: Du gå...   \n",
      "4  @nielscallesoe @Heunicke Din første indvending...   \n",
      "5  @stinuslindgreen @Heunicke I min optik, er det...   \n",
      "6  @RasmusMalver @radikale Det er jeg ked af. Jeg...   \n",
      "7  Indtil for en time siden var @stinuslindgreen ...   \n",
      "8  @larskohler @BEsbensen @PiaOlsen Lidt, men jeg...   \n",
      "9  @ThomasMonbergSF Vi løber vist i ring!... Ha e...   \n",
      "\n",
      "                                          translated  \n",
      "0  @frkomo I guess I'm saying it strictly just to...  \n",
      "1  @MonbergSF Tell it to the gaming association, ...  \n",
      "2  @PeterHuggler Had everything you want. But don...  \n",
      "3  @brianweichardt I hate this kind of thing: You...  \n",
      "4  @nielsallesoe @Heunicke Your first objection m...  \n",
      "5  @stinuslindgreen @Heunicke In my optics, it is...  \n",
      "6  @RasmusMalver @radical I'm sorry. I want to un...  \n",
      "7  Until an hour ago, @stinuslindgreen was on my ...  \n",
      "8  @larskohler @BEsbensen @PiaOlsen A little, but...  \n",
      "9  @ThomasMonbergSF I think we're running in a ci...  \n"
     ]
    }
   ],
   "source": [
    "print(pairs_small[['text', 'translated']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2458cd-90cc-4c27-9dfe-22e8c9045ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a translated text column (on the full df)\n",
    "\n",
    "#from tqdm import tqdm\n",
    "#from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "#model_name = 'Helsinki-NLP/opus-mt-da-en'\n",
    "#tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "#model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "#def translate(text):\n",
    "    # Tokenize the input text\n",
    "    #inputs = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "    # Generate translation\n",
    "    #translated_tokens = model.generate(**inputs)\n",
    "    # Decode the tokens to text\n",
    "    #translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "    #return translated_text\n",
    "\n",
    "\n",
    "# List to store the scores\n",
    "list = []\n",
    "\n",
    "# Iterate over each text\n",
    "for text in (tqdm(pairs['text'], desc= \"translating\")) :\n",
    "    result = translate(text)\n",
    "    # Append to the list\n",
    "    list.append(result)\n",
    "\n",
    "# Add the scores as a new column in the DataFrame\n",
    "pairs['translated'] = list\n",
    "pairs\n",
    "\n",
    "# Save\n",
    "pairs.to_csv('/Users/idahelenedencker/Desktop/w_translated_full.csv', index=False)\n",
    "\n",
    "#Load in\n",
    "dtype_dict_all = {\n",
    "    'conversation_id': 'object',\n",
    "    'id': 'object',\n",
    "    'author_id': 'object',\n",
    "    'referenced_tweets_id': 'object',\n",
    "    'in_reply_to_user_id': 'object',\n",
    "    'PNR': 'object'\n",
    "}\n",
    "\n",
    "pairs = pd.read_csv('/Users/idahelenedencker/Desktop/w_translated_full.csv', dtype=dtype_dict_all)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e850ced-e35b-4727-8db4-9e71a68906be",
   "metadata": {},
   "source": [
    "## Zero shot learning (3 different models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3487e1cf-d647-47ba-abc7-3db19cea186e",
   "metadata": {},
   "source": [
    "In zero shot learning a pre-trained model is used to predict the give a probability on any given label using embeddings, even though the label(s) has not been part of the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21fe73e-2e59-44f2-b28c-3f8f5c83fc45",
   "metadata": {},
   "source": [
    "### facebook/bart-large-mnli model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ef5f2ca-d746-480b-8291-39b8023d2ca7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eb75d4a-d914-435c-a124-ab99a294d0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipe_1 = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52ab3a1a-22e1-4d81-8745-be41f6f7fe54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'jeg forstår hvad du mener, men din kommentar er ikke særlig konstruktiv',\n",
       " 'labels': ['counterspeech', 'neutral tone', 'hate'],\n",
       " 'scores': [0.819023072719574, 0.17399725317955017, 0.006979694124311209]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_labels = ['counterspeech', 'hate', 'neutral tone']\n",
    "\n",
    "sequence_to_classify_1 = \"i see your point but i dont think it is very constructive\"\n",
    "sequence_to_classify_2 = \"jeg forstår hvad du mener, men din kommentar er ikke særlig konstruktiv\"\n",
    "sequence_to_classify_3 = pairs['text'][3]\n",
    "sequence_to_classify_4 = \"today i went for a walk outside with my dog, nice sunny weather\"\n",
    "\n",
    "pipe_1(sequence_to_classify_2, candidate_labels)\n",
    "\n",
    "# seems good on danish too\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f667e41f-f40a-4414-9375-503b33ac64ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting scores: 100%|████████████████████| 2000/2000 [06:47<00:00,  4.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>replied_to_reply_count</th>\n",
       "      <th>referenced_tweets_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>PNR</th>\n",
       "      <th>...</th>\n",
       "      <th>pair_num</th>\n",
       "      <th>type</th>\n",
       "      <th>like_n</th>\n",
       "      <th>retweet_n</th>\n",
       "      <th>quote_n</th>\n",
       "      <th>translated</th>\n",
       "      <th>ZS_counterspeech_score</th>\n",
       "      <th>ZS_hate_score</th>\n",
       "      <th>ZS_neutral_score</th>\n",
       "      <th>ZS_counterspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1036583587242549248</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-09-03 21:04:41</td>\n",
       "      <td>1036721666628444160</td>\n",
       "      <td>@frkomo Jeg siger det vel strengt taget bare t...</td>\n",
       "      <td>1666088336</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1036721302692917250</td>\n",
       "      <td>148061237</td>\n",
       "      <td>1311570613</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>reply</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@frkomo I guess I'm saying it strictly just to...</td>\n",
       "      <td>0.632259</td>\n",
       "      <td>0.034136</td>\n",
       "      <td>0.333605</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1036583587242549248</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-09-03 21:03:14</td>\n",
       "      <td>1036721302692917250</td>\n",
       "      <td>@MonbergSF Sig det til spillerforeningen, som ...</td>\n",
       "      <td>148061237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1666088336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>tweet</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@MonbergSF Tell it to the gaming association, ...</td>\n",
       "      <td>0.951389</td>\n",
       "      <td>0.019291</td>\n",
       "      <td>0.029320</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>899548260863488002</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-08-21 12:10:42</td>\n",
       "      <td>899604671375052801</td>\n",
       "      <td>@PeterHuggler Had alt det, du vil. Men du skal...</td>\n",
       "      <td>547416021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>899603561323081729</td>\n",
       "      <td>3301029597</td>\n",
       "      <td>1405772015</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>reply</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@PeterHuggler Had everything you want. But don...</td>\n",
       "      <td>0.317035</td>\n",
       "      <td>0.016395</td>\n",
       "      <td>0.666571</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>899548260863488002</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-08-21 12:06:17</td>\n",
       "      <td>899603561323081729</td>\n",
       "      <td>@brianweichardt Jeg hader den her slags: Du gå...</td>\n",
       "      <td>3301029597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>547416021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>tweet</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@brianweichardt I hate this kind of thing: You...</td>\n",
       "      <td>0.095866</td>\n",
       "      <td>0.883837</td>\n",
       "      <td>0.020297</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1345496479583113217</td>\n",
       "      <td>da</td>\n",
       "      <td>2021-01-03 12:38:16</td>\n",
       "      <td>1345711074407014400</td>\n",
       "      <td>@nielscallesoe @Heunicke Din første indvending...</td>\n",
       "      <td>87923613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1345524516311748608</td>\n",
       "      <td>23341699</td>\n",
       "      <td>0908801199</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>reply</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@nielsallesoe @Heunicke Your first objection m...</td>\n",
       "      <td>0.863429</td>\n",
       "      <td>0.016685</td>\n",
       "      <td>0.119886</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1285495153202024448</td>\n",
       "      <td>da</td>\n",
       "      <td>2020-07-21 10:22:06</td>\n",
       "      <td>1285520419529863168</td>\n",
       "      <td>@SimonStoerup @perlysholt Hm. Man ville som ud...</td>\n",
       "      <td>27626050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>383396359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>998</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@SimonStoerup @perlysholt Hm. You would be abl...</td>\n",
       "      <td>0.768433</td>\n",
       "      <td>0.012006</td>\n",
       "      <td>0.219561</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>da</td>\n",
       "      <td>2019-09-18 19:10:18</td>\n",
       "      <td>1174400270710820870</td>\n",
       "      <td>@R4nd4hl @khoenge Sjovt du synes netop Hønge b...</td>\n",
       "      <td>861057936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>72823792</td>\n",
       "      <td>1508892043</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>reply</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@R4nd4hl @khoenge Funny you think just Hønge s...</td>\n",
       "      <td>0.917323</td>\n",
       "      <td>0.018060</td>\n",
       "      <td>0.064617</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>da</td>\n",
       "      <td>2019-09-18 18:50:58</td>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>Detektor har undersøgt det: @khoenge talte usa...</td>\n",
       "      <td>72823792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>tweet</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Detector has examined it: @khoenge spoke untru...</td>\n",
       "      <td>0.829699</td>\n",
       "      <td>0.078995</td>\n",
       "      <td>0.091306</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1481298462238982144</td>\n",
       "      <td>da</td>\n",
       "      <td>2022-01-12 19:25:54</td>\n",
       "      <td>1481346717513662464</td>\n",
       "      <td>@ReneAndersenDK Forskellen er, at ham her også...</td>\n",
       "      <td>805874425988087811</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1481345545721495554</td>\n",
       "      <td>4776986009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1000</td>\n",
       "      <td>reply</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@ReneAndersenDK The difference is that this gu...</td>\n",
       "      <td>0.834556</td>\n",
       "      <td>0.091175</td>\n",
       "      <td>0.074269</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1481298462238982144</td>\n",
       "      <td>da</td>\n",
       "      <td>2022-01-12 19:21:14</td>\n",
       "      <td>1481345545721495554</td>\n",
       "      <td>@baretraet Sådan et mål har vi sgu da alle sam...</td>\n",
       "      <td>4776986009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>805874425988087811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1000</td>\n",
       "      <td>tweet</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@baretraet Such a goal have we all made for tr...</td>\n",
       "      <td>0.923320</td>\n",
       "      <td>0.009041</td>\n",
       "      <td>0.067639</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          conversation_id lang           created_at                   id  \\\n",
       "0     1036583587242549248   da  2018-09-03 21:04:41  1036721666628444160   \n",
       "1     1036583587242549248   da  2018-09-03 21:03:14  1036721302692917250   \n",
       "2      899548260863488002   da  2017-08-21 12:10:42   899604671375052801   \n",
       "3      899548260863488002   da  2017-08-21 12:06:17   899603561323081729   \n",
       "4     1345496479583113217   da  2021-01-03 12:38:16  1345711074407014400   \n",
       "...                   ...  ...                  ...                  ...   \n",
       "1995  1285495153202024448   da  2020-07-21 10:22:06  1285520419529863168   \n",
       "1996  1174395406719102976   da  2019-09-18 19:10:18  1174400270710820870   \n",
       "1997  1174395406719102976   da  2019-09-18 18:50:58  1174395406719102976   \n",
       "1998  1481298462238982144   da  2022-01-12 19:25:54  1481346717513662464   \n",
       "1999  1481298462238982144   da  2022-01-12 19:21:14  1481345545721495554   \n",
       "\n",
       "                                                   text           author_id  \\\n",
       "0     @frkomo Jeg siger det vel strengt taget bare t...          1666088336   \n",
       "1     @MonbergSF Sig det til spillerforeningen, som ...           148061237   \n",
       "2     @PeterHuggler Had alt det, du vil. Men du skal...           547416021   \n",
       "3     @brianweichardt Jeg hader den her slags: Du gå...          3301029597   \n",
       "4     @nielscallesoe @Heunicke Din første indvending...            87923613   \n",
       "...                                                 ...                 ...   \n",
       "1995  @SimonStoerup @perlysholt Hm. Man ville som ud...            27626050   \n",
       "1996  @R4nd4hl @khoenge Sjovt du synes netop Hønge b...           861057936   \n",
       "1997  Detektor har undersøgt det: @khoenge talte usa...            72823792   \n",
       "1998  @ReneAndersenDK Forskellen er, at ham her også...  805874425988087811   \n",
       "1999  @baretraet Sådan et mål har vi sgu da alle sam...          4776986009   \n",
       "\n",
       "      replied_to_reply_count referenced_tweets_id in_reply_to_user_id  \\\n",
       "0                        1.0  1036721302692917250           148061237   \n",
       "1                        NaN                  NaN          1666088336   \n",
       "2                        1.0   899603561323081729          3301029597   \n",
       "3                        NaN                  NaN           547416021   \n",
       "4                        1.0  1345524516311748608            23341699   \n",
       "...                      ...                  ...                 ...   \n",
       "1995                     NaN                  NaN           383396359   \n",
       "1996                     0.0  1174395406719102976            72823792   \n",
       "1997                     NaN                  NaN                 NaN   \n",
       "1998                     1.0  1481345545721495554          4776986009   \n",
       "1999                     NaN                  NaN  805874425988087811   \n",
       "\n",
       "             PNR  ... pair_num   type  like_n  retweet_n  quote_n  \\\n",
       "0     1311570613  ...        1  reply       1          0        0   \n",
       "1            NaN  ...        1  tweet       1          0        0   \n",
       "2     1405772015  ...        2  reply       0          0        0   \n",
       "3            NaN  ...        2  tweet       1          0        0   \n",
       "4     0908801199  ...        3  reply       1          0        0   \n",
       "...          ...  ...      ...    ...     ...        ...      ...   \n",
       "1995         NaN  ...      998  tweet       2          0        0   \n",
       "1996  1508892043  ...      999  reply       2          0        0   \n",
       "1997         NaN  ...      999  tweet      20          3        0   \n",
       "1998         NaN  ...     1000  reply       2          0        0   \n",
       "1999         NaN  ...     1000  tweet       3          0        0   \n",
       "\n",
       "                                             translated  \\\n",
       "0     @frkomo I guess I'm saying it strictly just to...   \n",
       "1     @MonbergSF Tell it to the gaming association, ...   \n",
       "2     @PeterHuggler Had everything you want. But don...   \n",
       "3     @brianweichardt I hate this kind of thing: You...   \n",
       "4     @nielsallesoe @Heunicke Your first objection m...   \n",
       "...                                                 ...   \n",
       "1995  @SimonStoerup @perlysholt Hm. You would be abl...   \n",
       "1996  @R4nd4hl @khoenge Funny you think just Hønge s...   \n",
       "1997  Detector has examined it: @khoenge spoke untru...   \n",
       "1998  @ReneAndersenDK The difference is that this gu...   \n",
       "1999  @baretraet Such a goal have we all made for tr...   \n",
       "\n",
       "      ZS_counterspeech_score  ZS_hate_score ZS_neutral_score ZS_counterspeech  \n",
       "0                   0.632259       0.034136         0.333605               no  \n",
       "1                   0.951389       0.019291         0.029320              yes  \n",
       "2                   0.317035       0.016395         0.666571               no  \n",
       "3                   0.095866       0.883837         0.020297               no  \n",
       "4                   0.863429       0.016685         0.119886              yes  \n",
       "...                      ...            ...              ...              ...  \n",
       "1995                0.768433       0.012006         0.219561               no  \n",
       "1996                0.917323       0.018060         0.064617              yes  \n",
       "1997                0.829699       0.078995         0.091306              yes  \n",
       "1998                0.834556       0.091175         0.074269              yes  \n",
       "1999                0.923320       0.009041         0.067639              yes  \n",
       "\n",
       "[2000 rows x 30 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on test data (translated)\n",
    "\n",
    "# Candidate labels\n",
    "candidate_labels = ['counterspeech', 'hate', 'neutral tone']\n",
    "\n",
    "# List to store the scores\n",
    "counterspeech_scores = []\n",
    "hate_scores = []\n",
    "neutral_scores = []\n",
    "\n",
    "# Iterate over each text\n",
    "for text in (tqdm(pairs_small['translated'], desc= \"Extracting scores\")) :\n",
    "    result = pipe_1(text, candidate_labels)\n",
    "    # Extract the scores\n",
    "    counterspeech_score = dict(zip(result['labels'], result['scores']))['counterspeech']\n",
    "    hate_score = dict(zip(result['labels'], result['scores']))['hate']\n",
    "    neutral_score = dict(zip(result['labels'], result['scores']))['neutral tone']\n",
    "    # Append the scores to the lists\n",
    "    counterspeech_scores.append(counterspeech_score)\n",
    "    hate_scores.append(hate_score)\n",
    "    neutral_scores.append(neutral_score)\n",
    "\n",
    "# Add the scores as a new column in the DataFrame\n",
    "pairs_small['ZS_counterspeech_score'] = counterspeech_scores\n",
    "pairs_small['ZS_hate_score'] = hate_scores\n",
    "pairs_small['ZS_neutral_score'] = neutral_scores\n",
    "\n",
    "\n",
    "# Initialize the 'counterspeech' column with 'NA'\n",
    "pairs_small['ZS_counterspeech'] = 'NA'\n",
    "\n",
    "# Update the 'counterspeech' column based on the 'counterspeech_score'\n",
    "for index, row in pairs_small.iterrows():\n",
    "    if row['ZS_counterspeech_score'] > 0.8:\n",
    "        pairs_small.at[index, 'ZS_counterspeech'] = 'yes'\n",
    "    else:\n",
    "        pairs_small.at[index, 'ZS_counterspeech'] = 'no'    \n",
    "\n",
    "\n",
    "pairs_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d33b8037-0e2c-4c43-b099-ed8a125853e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting scores: 100%|████████████████████| 2000/2000 [08:21<00:00,  3.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>replied_to_reply_count</th>\n",
       "      <th>referenced_tweets_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>PNR</th>\n",
       "      <th>...</th>\n",
       "      <th>quote_n</th>\n",
       "      <th>translated</th>\n",
       "      <th>ZS_counterspeech_score</th>\n",
       "      <th>ZS_hate_score</th>\n",
       "      <th>ZS_neutral_score</th>\n",
       "      <th>ZS_counterspeech</th>\n",
       "      <th>ZS_counterspeech_score_dan</th>\n",
       "      <th>ZS_hate_score_dan</th>\n",
       "      <th>ZS_neutral_score_dan</th>\n",
       "      <th>ZS_counterspeech_dan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1036583587242549248</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-09-03 21:04:41</td>\n",
       "      <td>1036721666628444160</td>\n",
       "      <td>@frkomo Jeg siger det vel strengt taget bare t...</td>\n",
       "      <td>1666088336</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1036721302692917250</td>\n",
       "      <td>148061237</td>\n",
       "      <td>1311570613</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>@frkomo I guess I'm saying it strictly just to...</td>\n",
       "      <td>0.632259</td>\n",
       "      <td>0.034136</td>\n",
       "      <td>0.333605</td>\n",
       "      <td>no</td>\n",
       "      <td>0.765376</td>\n",
       "      <td>0.008536</td>\n",
       "      <td>0.226088</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1036583587242549248</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-09-03 21:03:14</td>\n",
       "      <td>1036721302692917250</td>\n",
       "      <td>@MonbergSF Sig det til spillerforeningen, som ...</td>\n",
       "      <td>148061237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1666088336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>@MonbergSF Tell it to the gaming association, ...</td>\n",
       "      <td>0.951389</td>\n",
       "      <td>0.019291</td>\n",
       "      <td>0.029320</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.853204</td>\n",
       "      <td>0.006963</td>\n",
       "      <td>0.139833</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>899548260863488002</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-08-21 12:10:42</td>\n",
       "      <td>899604671375052801</td>\n",
       "      <td>@PeterHuggler Had alt det, du vil. Men du skal...</td>\n",
       "      <td>547416021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>899603561323081729</td>\n",
       "      <td>3301029597</td>\n",
       "      <td>1405772015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>@PeterHuggler Had everything you want. But don...</td>\n",
       "      <td>0.317035</td>\n",
       "      <td>0.016395</td>\n",
       "      <td>0.666571</td>\n",
       "      <td>no</td>\n",
       "      <td>0.575550</td>\n",
       "      <td>0.030307</td>\n",
       "      <td>0.394142</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>899548260863488002</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-08-21 12:06:17</td>\n",
       "      <td>899603561323081729</td>\n",
       "      <td>@brianweichardt Jeg hader den her slags: Du gå...</td>\n",
       "      <td>3301029597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>547416021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>@brianweichardt I hate this kind of thing: You...</td>\n",
       "      <td>0.095866</td>\n",
       "      <td>0.883837</td>\n",
       "      <td>0.020297</td>\n",
       "      <td>no</td>\n",
       "      <td>0.616760</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>0.368008</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1345496479583113217</td>\n",
       "      <td>da</td>\n",
       "      <td>2021-01-03 12:38:16</td>\n",
       "      <td>1345711074407014400</td>\n",
       "      <td>@nielscallesoe @Heunicke Din første indvending...</td>\n",
       "      <td>87923613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1345524516311748608</td>\n",
       "      <td>23341699</td>\n",
       "      <td>0908801199</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>@nielsallesoe @Heunicke Your first objection m...</td>\n",
       "      <td>0.863429</td>\n",
       "      <td>0.016685</td>\n",
       "      <td>0.119886</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.815085</td>\n",
       "      <td>0.017978</td>\n",
       "      <td>0.166937</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1285495153202024448</td>\n",
       "      <td>da</td>\n",
       "      <td>2020-07-21 10:22:06</td>\n",
       "      <td>1285520419529863168</td>\n",
       "      <td>@SimonStoerup @perlysholt Hm. Man ville som ud...</td>\n",
       "      <td>27626050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>383396359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>@SimonStoerup @perlysholt Hm. You would be abl...</td>\n",
       "      <td>0.768433</td>\n",
       "      <td>0.012006</td>\n",
       "      <td>0.219561</td>\n",
       "      <td>no</td>\n",
       "      <td>0.770013</td>\n",
       "      <td>0.019735</td>\n",
       "      <td>0.210252</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>da</td>\n",
       "      <td>2019-09-18 19:10:18</td>\n",
       "      <td>1174400270710820870</td>\n",
       "      <td>@R4nd4hl @khoenge Sjovt du synes netop Hønge b...</td>\n",
       "      <td>861057936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>72823792</td>\n",
       "      <td>1508892043</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>@R4nd4hl @khoenge Funny you think just Hønge s...</td>\n",
       "      <td>0.917323</td>\n",
       "      <td>0.018060</td>\n",
       "      <td>0.064617</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.759511</td>\n",
       "      <td>0.142903</td>\n",
       "      <td>0.097587</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>da</td>\n",
       "      <td>2019-09-18 18:50:58</td>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>Detektor har undersøgt det: @khoenge talte usa...</td>\n",
       "      <td>72823792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Detector has examined it: @khoenge spoke untru...</td>\n",
       "      <td>0.829699</td>\n",
       "      <td>0.078995</td>\n",
       "      <td>0.091306</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.654120</td>\n",
       "      <td>0.126598</td>\n",
       "      <td>0.219282</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1481298462238982144</td>\n",
       "      <td>da</td>\n",
       "      <td>2022-01-12 19:25:54</td>\n",
       "      <td>1481346717513662464</td>\n",
       "      <td>@ReneAndersenDK Forskellen er, at ham her også...</td>\n",
       "      <td>805874425988087811</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1481345545721495554</td>\n",
       "      <td>4776986009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>@ReneAndersenDK The difference is that this gu...</td>\n",
       "      <td>0.834556</td>\n",
       "      <td>0.091175</td>\n",
       "      <td>0.074269</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.713310</td>\n",
       "      <td>0.019431</td>\n",
       "      <td>0.267258</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1481298462238982144</td>\n",
       "      <td>da</td>\n",
       "      <td>2022-01-12 19:21:14</td>\n",
       "      <td>1481345545721495554</td>\n",
       "      <td>@baretraet Sådan et mål har vi sgu da alle sam...</td>\n",
       "      <td>4776986009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>805874425988087811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>@baretraet Such a goal have we all made for tr...</td>\n",
       "      <td>0.923320</td>\n",
       "      <td>0.009041</td>\n",
       "      <td>0.067639</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.851687</td>\n",
       "      <td>0.055234</td>\n",
       "      <td>0.093079</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          conversation_id lang           created_at                   id  \\\n",
       "0     1036583587242549248   da  2018-09-03 21:04:41  1036721666628444160   \n",
       "1     1036583587242549248   da  2018-09-03 21:03:14  1036721302692917250   \n",
       "2      899548260863488002   da  2017-08-21 12:10:42   899604671375052801   \n",
       "3      899548260863488002   da  2017-08-21 12:06:17   899603561323081729   \n",
       "4     1345496479583113217   da  2021-01-03 12:38:16  1345711074407014400   \n",
       "...                   ...  ...                  ...                  ...   \n",
       "1995  1285495153202024448   da  2020-07-21 10:22:06  1285520419529863168   \n",
       "1996  1174395406719102976   da  2019-09-18 19:10:18  1174400270710820870   \n",
       "1997  1174395406719102976   da  2019-09-18 18:50:58  1174395406719102976   \n",
       "1998  1481298462238982144   da  2022-01-12 19:25:54  1481346717513662464   \n",
       "1999  1481298462238982144   da  2022-01-12 19:21:14  1481345545721495554   \n",
       "\n",
       "                                                   text           author_id  \\\n",
       "0     @frkomo Jeg siger det vel strengt taget bare t...          1666088336   \n",
       "1     @MonbergSF Sig det til spillerforeningen, som ...           148061237   \n",
       "2     @PeterHuggler Had alt det, du vil. Men du skal...           547416021   \n",
       "3     @brianweichardt Jeg hader den her slags: Du gå...          3301029597   \n",
       "4     @nielscallesoe @Heunicke Din første indvending...            87923613   \n",
       "...                                                 ...                 ...   \n",
       "1995  @SimonStoerup @perlysholt Hm. Man ville som ud...            27626050   \n",
       "1996  @R4nd4hl @khoenge Sjovt du synes netop Hønge b...           861057936   \n",
       "1997  Detektor har undersøgt det: @khoenge talte usa...            72823792   \n",
       "1998  @ReneAndersenDK Forskellen er, at ham her også...  805874425988087811   \n",
       "1999  @baretraet Sådan et mål har vi sgu da alle sam...          4776986009   \n",
       "\n",
       "      replied_to_reply_count referenced_tweets_id in_reply_to_user_id  \\\n",
       "0                        1.0  1036721302692917250           148061237   \n",
       "1                        NaN                  NaN          1666088336   \n",
       "2                        1.0   899603561323081729          3301029597   \n",
       "3                        NaN                  NaN           547416021   \n",
       "4                        1.0  1345524516311748608            23341699   \n",
       "...                      ...                  ...                 ...   \n",
       "1995                     NaN                  NaN           383396359   \n",
       "1996                     0.0  1174395406719102976            72823792   \n",
       "1997                     NaN                  NaN                 NaN   \n",
       "1998                     1.0  1481345545721495554          4776986009   \n",
       "1999                     NaN                  NaN  805874425988087811   \n",
       "\n",
       "             PNR  ... quote_n  \\\n",
       "0     1311570613  ...       0   \n",
       "1            NaN  ...       0   \n",
       "2     1405772015  ...       0   \n",
       "3            NaN  ...       0   \n",
       "4     0908801199  ...       0   \n",
       "...          ...  ...     ...   \n",
       "1995         NaN  ...       0   \n",
       "1996  1508892043  ...       0   \n",
       "1997         NaN  ...       0   \n",
       "1998         NaN  ...       0   \n",
       "1999         NaN  ...       0   \n",
       "\n",
       "                                             translated  \\\n",
       "0     @frkomo I guess I'm saying it strictly just to...   \n",
       "1     @MonbergSF Tell it to the gaming association, ...   \n",
       "2     @PeterHuggler Had everything you want. But don...   \n",
       "3     @brianweichardt I hate this kind of thing: You...   \n",
       "4     @nielsallesoe @Heunicke Your first objection m...   \n",
       "...                                                 ...   \n",
       "1995  @SimonStoerup @perlysholt Hm. You would be abl...   \n",
       "1996  @R4nd4hl @khoenge Funny you think just Hønge s...   \n",
       "1997  Detector has examined it: @khoenge spoke untru...   \n",
       "1998  @ReneAndersenDK The difference is that this gu...   \n",
       "1999  @baretraet Such a goal have we all made for tr...   \n",
       "\n",
       "      ZS_counterspeech_score  ZS_hate_score  ZS_neutral_score  \\\n",
       "0                   0.632259       0.034136          0.333605   \n",
       "1                   0.951389       0.019291          0.029320   \n",
       "2                   0.317035       0.016395          0.666571   \n",
       "3                   0.095866       0.883837          0.020297   \n",
       "4                   0.863429       0.016685          0.119886   \n",
       "...                      ...            ...               ...   \n",
       "1995                0.768433       0.012006          0.219561   \n",
       "1996                0.917323       0.018060          0.064617   \n",
       "1997                0.829699       0.078995          0.091306   \n",
       "1998                0.834556       0.091175          0.074269   \n",
       "1999                0.923320       0.009041          0.067639   \n",
       "\n",
       "     ZS_counterspeech  ZS_counterspeech_score_dan  ZS_hate_score_dan  \\\n",
       "0                  no                    0.765376           0.008536   \n",
       "1                 yes                    0.853204           0.006963   \n",
       "2                  no                    0.575550           0.030307   \n",
       "3                  no                    0.616760           0.015232   \n",
       "4                 yes                    0.815085           0.017978   \n",
       "...               ...                         ...                ...   \n",
       "1995               no                    0.770013           0.019735   \n",
       "1996              yes                    0.759511           0.142903   \n",
       "1997              yes                    0.654120           0.126598   \n",
       "1998              yes                    0.713310           0.019431   \n",
       "1999              yes                    0.851687           0.055234   \n",
       "\n",
       "     ZS_neutral_score_dan ZS_counterspeech_dan  \n",
       "0                0.226088                   no  \n",
       "1                0.139833                  yes  \n",
       "2                0.394142                   no  \n",
       "3                0.368008                   no  \n",
       "4                0.166937                  yes  \n",
       "...                   ...                  ...  \n",
       "1995             0.210252                   no  \n",
       "1996             0.097587                   no  \n",
       "1997             0.219282                   no  \n",
       "1998             0.267258                   no  \n",
       "1999             0.093079                  yes  \n",
       "\n",
       "[2000 rows x 34 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on test data (danish)\n",
    "\n",
    "# Candidate labels\n",
    "candidate_labels = ['counterspeech', 'hate', 'neutral tone']\n",
    "\n",
    "# List to store the scores\n",
    "counterspeech_scores = []\n",
    "hate_scores = []\n",
    "neutral_scores = []\n",
    "\n",
    "# Iterate over each text\n",
    "for text in (tqdm(pairs_small['text'], desc= \"Extracting scores\")) :\n",
    "    result = pipe_1(text, candidate_labels)\n",
    "    # Extract the scores\n",
    "    counterspeech_score = dict(zip(result['labels'], result['scores']))['counterspeech']\n",
    "    hate_score = dict(zip(result['labels'], result['scores']))['hate']\n",
    "    neutral_score = dict(zip(result['labels'], result['scores']))['neutral tone']\n",
    "    # Append the scores to the lists\n",
    "    counterspeech_scores.append(counterspeech_score)\n",
    "    hate_scores.append(hate_score)\n",
    "    neutral_scores.append(neutral_score)\n",
    "\n",
    "# Add the scores as a new column in the DataFrame\n",
    "pairs_small['ZS_counterspeech_score_dan'] = counterspeech_scores\n",
    "pairs_small['ZS_hate_score_dan'] = hate_scores\n",
    "pairs_small['ZS_neutral_score_dan'] = neutral_scores\n",
    "\n",
    "\n",
    "# Initialize the 'counterspeech' column with 'NA'\n",
    "pairs_small['ZS_counterspeech_dan'] = 'NA'\n",
    "\n",
    "# Update the 'counterspeech' column based on the 'counterspeech_score'\n",
    "for index, row in pairs_small.iterrows():\n",
    "    if row['ZS_counterspeech_score_dan'] > 0.8:\n",
    "        pairs_small.at[index, 'ZS_counterspeech_dan'] = 'yes'\n",
    "    else:\n",
    "        pairs_small.at[index, 'ZS_counterspeech_dan'] = 'no'    \n",
    "\n",
    "\n",
    "pairs_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21e4d2f9-a129-450d-9bee-2373d973c8f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting scores:   4%|▋                 | 797/20000 [07:40<3:05:01,  1.73it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Iterate over each text\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m (tqdm(pairs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m], desc\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting scores\u001b[39m\u001b[38;5;124m\"\u001b[39m)) :\n\u001b[0;32m---> 13\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Extract the scores\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     counterspeech_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m], result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m'\u001b[39m]))[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcounterspeech\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/zero_shot_classification.py:206\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline.__call__\u001b[0;34m(self, sequences, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to understand extra arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/base.py:1132\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ChunkPipeline):\n\u001b[0;32m-> 1132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1134\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   1135\u001b[0m                 [inputs], num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1136\u001b[0m             )\n\u001b[1;32m   1137\u001b[0m         )\n\u001b[1;32m   1138\u001b[0m     )\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:266\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[0;32m--> 266\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/base.py:1046\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1045\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1046\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1047\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/zero_shot_classification.py:229\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline._forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(model_forward)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    228\u001b[0m     model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcandidate_label\u001b[39m\u001b[38;5;124m\"\u001b[39m: candidate_label,\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m\"\u001b[39m: sequence,\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_last\u001b[39m\u001b[38;5;124m\"\u001b[39m: inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_last\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moutputs,\n\u001b[1;32m    236\u001b[0m }\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_outputs\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1539\u001b[0m, in \u001b[0;36mBartForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1535\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1536\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing input embeddings is currently not supported for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1537\u001b[0m     )\n\u001b[0;32m-> 1539\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1550\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1555\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# last hidden state\u001b[39;00m\n\u001b[1;32m   1557\u001b[0m eos_mask \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39meq(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39meos_token_id)\u001b[38;5;241m.\u001b[39mto(hidden_states\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1274\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1267\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1268\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1269\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1270\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1271\u001b[0m     )\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1274\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1132\u001b[0m, in \u001b[0;36mBartDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1121\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m   1122\u001b[0m         create_custom_forward(decoder_layer),\n\u001b[1;32m   1123\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1130\u001b[0m     )\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1145\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:427\u001b[0m, in \u001b[0;36mBartDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    425\u001b[0m self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;66;03m# add present self-attn cache to positions 1,2 of present_key_value tuple\u001b[39;00m\n\u001b[0;32m--> 427\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    435\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:291\u001b[0m, in \u001b[0;36mBartAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# Use the `embed_dim` from the config (stored in the class) rather than `hidden_state` because `attn_output` can be\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# partitioned across GPUs when using tensor-parallelism.\u001b[39;00m\n\u001b[1;32m    289\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(bsz, tgt_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim)\n\u001b[0;32m--> 291\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, attn_weights_reshaped, past_key_value\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#On full dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Candidate labels\n",
    "candidate_labels = ['counterspeech', 'hate', 'neutral tone']\n",
    "\n",
    "# List to store the scores\n",
    "counterspeech_scores = []\n",
    "hate_scores = []\n",
    "neutral_scores = []\n",
    "\n",
    "# Iterate over each text\n",
    "for text in (tqdm(pairs['translated'], desc= \"Extracting scores\")) :\n",
    "    result = pipe_1(text, candidate_labels)\n",
    "    # Extract the scores\n",
    "    counterspeech_score = dict(zip(result['labels'], result['scores']))['counterspeech']\n",
    "    hate_score = dict(zip(result['labels'], result['scores']))['hate']\n",
    "    neutral_score = dict(zip(result['labels'], result['scores']))['neutral tone']\n",
    "    # Append the scores to the lists\n",
    "    counterspeech_scores.append(counterspeech_score)\n",
    "    hate_scores.append(hate_score)\n",
    "    neutral_scores.append(neutral_score)\n",
    "\n",
    "# Add the scores as a new column in the DataFrame\n",
    "pairs['ZS_counterspeech_score'] = counterspeech_scores\n",
    "pairs['ZS_hate_score'] = hate_scores\n",
    "pairs['ZS_neutral_score'] = neutral_scores\n",
    "\n",
    "\n",
    "# Initialize the 'counterspeech' column with 'NA'\n",
    "pairs['ZS_counterspeech'] = 'NA'\n",
    "\n",
    "# Update the 'counterspeech' column based on the 'counterspeech_score'\n",
    "for index, row in pairs.iterrows():\n",
    "    if row['ZS_counterspeech_score'] > 0.8:\n",
    "        pairs.at[index, 'ZS_counterspeech'] = 'yes'\n",
    "    else:\n",
    "        pairs.at[index, 'ZS_counterspeech'] = 'no'    \n",
    "\n",
    "\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e238115-a8e8-4c7a-8ad4-69998ba4b1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.13.0)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.8.0)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from seaborn) (1.23.5)\n",
      "Requirement already satisfied: pandas>=1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from seaborn) (2.1.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "020f6208-0734-420b-bcb3-6dcf753e40f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZS_counterspeech_dan\n",
      "no     1380\n",
      "yes     620\n",
      "Name: count, dtype: int64\n",
      "ZS_counterspeech\n",
      "yes    1040\n",
      "no      960\n",
      "Name: count, dtype: int64\n",
      "Cohen's Kappa: 0.18242710795902284\n",
      "Simple Agreement: 0.585\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at performance and agreement (original vs. translated text) \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(pairs_small['ZS_counterspeech_dan'].value_counts(dropna=False))\n",
    "print(pairs_small['ZS_counterspeech'].value_counts(dropna=False))\n",
    "\n",
    "#agreement \n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "kappa = cohen_kappa_score(pairs_small['ZS_counterspeech_dan'], pairs_small['ZS_counterspeech'])\n",
    "print(f\"Cohen's Kappa: {kappa}\")\n",
    "\n",
    "agreement = (pairs_small['ZS_counterspeech_dan'] == pairs_small['ZS_counterspeech']).mean()\n",
    "print(f\"Simple Agreement: {agreement}\")\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(pairs_small['ZS_counterspeech_dan'], pairs_small['ZS_counterspeech'])\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['no', 'yes'], yticklabels=['no', 'yes'])\n",
    "\n",
    "# Add labels, title, and display the plot\n",
    "plt.ylabel('ZS_counterspeech_dan')\n",
    "plt.xlabel('ZS_counterspeech')\n",
    "plt.title('Confusion Matrix of Agreement')\n",
    "plt.show()\n",
    "\n",
    "#low level of agreement, close to random \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41e026a4-b6e6-448b-aa3e-ffcb783e71da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"@frkomo I guess I'm saying it strictly just to those who follow me;) But if you follow the subsequent discussion, then I'm just not impressed by the approach the players have:)\",\n",
       " \"@PeterHuggler Had everything you want. But don't judge what I think is a natural reaction. I'm not covering that case at all.\",\n",
       " '@brianweichardt I hate this kind of thing: You go in and make yourself a judge, based on a photo. Let the court do its job, and seek only to communicate the case.',\n",
       " '@stinuslindgreen @Heunicke In my optics, it is not a relevant concern. Several reasons. Main: First, because we do not have scale to make a difference. IF it gives increased selection in that direction, it happens no matter what we do. Second, we do not neglect other vaccines on that basis.',\n",
       " '@peterbrothersen Exactly... So thin post from @AnneFrostJepsen... \"Don\\'t beat the politicians even if they beat on a daily basis\" Adult communication requires a desire from the politicians to act adultly and we still need to see',\n",
       " '@JanniMT @BrondbyIF Please turn yourself down and pick up your suck, please.',\n",
       " 'When @mortenskaerbaek is in top shape, it is far from the sock holders. There should just be sound at this interview https://t.co/yHk4vB74m9',\n",
       " \"@Nikolaj32LFC @EsbenSuurballe @ClarkJamesYNWA @larsmathiasen It sums everything up well. Just call us old angry men, I'll call it due diligence. Hope sincerely, you're right, but I would call our sporting management outright naive if they plan on such hopes. There's too much likelihood of it going wrong.\",\n",
       " '@RolfBjerre @alternative_@uffeelbaek Would you like to refer me to research that supports your statements? As long as I do not see any concrete research that agrees with you, I feel it is a debate between my sources, and your gut feeling. This should not be taken as an attack, but rather as a desire to know more',\n",
       " '@larsloekke Enig. Let us never forget. But that is not enough, Lars. You must both as prime minister and as prime minister candidate make it clear that a party with precisely Nazi ideology can never become parliamentary basis for your government. We as a country need the announcement from your side #dkpol',\n",
       " '@MagnusPharao @politiken I completely disagree with that - the moralists do not win this case. That is exactly what election after election shows.',\n",
       " \"@MrMesserschmidt Or just the more pragmatic local policy, but it's probably not something you have the imagination to imagine.\",\n",
       " \"@janschouby fair enough, I just think history repeats itself, but let's all hope that this time it's just the right coach.\",\n",
       " '@mfsvendsen It was certainly not. I have covered AGF since 1996',\n",
       " '@t_wittenburg @tjep We will hardly agree on this and your judgment attitude is not comfortable. Several shops offer free returns but apparently not all - maybe not yours either. I trade in the future where the performance is free. Good day.',\n",
       " \"@KFrydensbjerg @Mikkelnw @laianders @LKarstenberg I think it's a long time before we can't use a player like him. But when that's said, I don't know much about his skills, i.e. besides the wildness - and as mentioned, I love those types.\",\n",
       " \"@quitte74 @Mikkelnw @laianders @LKarstenberg That's how I felt BEFORE he came to AGF. But he's fat as a fan. However, I would also say that a team like AGF has only moved in playwise when you can do without MS or the same type.\",\n",
       " '@FCKBuzz @football major I completely agree. We can do much better. Good with your son:)',\n",
       " \"@quitte74 @football major It makes me fucking happy to hear. My son is a good place now. It's just so sad that it should take so many years, especially when you've found out that this is happening systematically because of savings considerations in the municipalities. We can't be familiar with our kids.\",\n",
       " 'The good @OleRyborg says it best: Consider it a gl.Day Sunday Berlinger, where you are not forced to read it all, but can browse, rewind, skip and tap as needed. That being said, feedback is always appreciated. We never get better without it. Thank you!']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print\n",
    "conunt_yes_dan= pairs_small[pairs_small['ZS_counterspeech_dan'] == 'yes']\n",
    "conunt_no_dan= pairs_small[pairs_small['ZS_counterspeech_dan'] == 'no']\n",
    "conunt_yes_eng= pairs_small[pairs_small['ZS_counterspeech'] == 'yes']\n",
    "conunt_no_eng= pairs_small[pairs_small['ZS_counterspeech'] == 'no']\n",
    "\n",
    "\n",
    "text_to_print = conunt_yes_dan['text'].head(20).tolist()\n",
    "text_to_print #not very accurate\n",
    "\n",
    "text_to_print = conunt_no_dan['text'].head(20).tolist()\n",
    "text_to_print #seems almost as if the no's are more counterspeech than the yes's\n",
    "\n",
    "\n",
    "text_to_print = conunt_yes_eng['translated'].head(20).tolist()\n",
    "text_to_print #quite good \n",
    "\n",
    "text_to_print = conunt_no_eng['translated'].head(20).tolist()\n",
    "text_to_print #allright, but failed to classify some obvious examples of counterspeech as that\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "489d7127-898f-4307-9b67-3e5815098a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>replied_to_reply_count</th>\n",
       "      <th>referenced_tweets_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>PNR</th>\n",
       "      <th>...</th>\n",
       "      <th>quote_n</th>\n",
       "      <th>translated</th>\n",
       "      <th>ZS_counterspeech_score</th>\n",
       "      <th>ZS_hate_score</th>\n",
       "      <th>ZS_neutral_score</th>\n",
       "      <th>ZS_counterspeech</th>\n",
       "      <th>ZS_counterspeech_score_dan</th>\n",
       "      <th>ZS_hate_score_dan</th>\n",
       "      <th>ZS_neutral_score_dan</th>\n",
       "      <th>ZS_counterspeech_dan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1036583587242549248</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-09-03 21:04:41</td>\n",
       "      <td>1036721666628444160</td>\n",
       "      <td>@frkomo Jeg siger det vel strengt taget bare t...</td>\n",
       "      <td>1666088336</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1036721302692917250</td>\n",
       "      <td>148061237</td>\n",
       "      <td>1311570613</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>@frkomo I guess I'm saying it strictly just to...</td>\n",
       "      <td>0.632259</td>\n",
       "      <td>0.034136</td>\n",
       "      <td>0.333605</td>\n",
       "      <td>no</td>\n",
       "      <td>0.765376</td>\n",
       "      <td>0.008536</td>\n",
       "      <td>0.226088</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>899548260863488002</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-08-21 12:10:42</td>\n",
       "      <td>899604671375052801</td>\n",
       "      <td>@PeterHuggler Had alt det, du vil. Men du skal...</td>\n",
       "      <td>547416021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>899603561323081729</td>\n",
       "      <td>3301029597</td>\n",
       "      <td>1405772015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>@PeterHuggler Had everything you want. But don...</td>\n",
       "      <td>0.317035</td>\n",
       "      <td>0.016395</td>\n",
       "      <td>0.666571</td>\n",
       "      <td>no</td>\n",
       "      <td>0.575550</td>\n",
       "      <td>0.030307</td>\n",
       "      <td>0.394142</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>899548260863488002</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-08-21 12:06:17</td>\n",
       "      <td>899603561323081729</td>\n",
       "      <td>@brianweichardt Jeg hader den her slags: Du gå...</td>\n",
       "      <td>3301029597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>547416021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>@brianweichardt I hate this kind of thing: You...</td>\n",
       "      <td>0.095866</td>\n",
       "      <td>0.883837</td>\n",
       "      <td>0.020297</td>\n",
       "      <td>no</td>\n",
       "      <td>0.616760</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>0.368008</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1345496479583113217</td>\n",
       "      <td>da</td>\n",
       "      <td>2021-01-03 00:16:57</td>\n",
       "      <td>1345524516311748608</td>\n",
       "      <td>@stinuslindgreen @Heunicke I min optik, er det...</td>\n",
       "      <td>23341699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87923613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>@stinuslindgreen @Heunicke In my optics, it is...</td>\n",
       "      <td>0.628949</td>\n",
       "      <td>0.027665</td>\n",
       "      <td>0.343386</td>\n",
       "      <td>no</td>\n",
       "      <td>0.521844</td>\n",
       "      <td>0.021986</td>\n",
       "      <td>0.456171</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1238602270129913857</td>\n",
       "      <td>da</td>\n",
       "      <td>2020-03-14 00:05:06</td>\n",
       "      <td>1238617110496059392</td>\n",
       "      <td>@RasmusMalver @radikale Det er jeg ked af. Jeg...</td>\n",
       "      <td>87923613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1238602270129913857</td>\n",
       "      <td>737702576506994688</td>\n",
       "      <td>0908801199</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>@RasmusMalver @radical I'm sorry. I want to un...</td>\n",
       "      <td>0.876910</td>\n",
       "      <td>0.037730</td>\n",
       "      <td>0.085360</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.695842</td>\n",
       "      <td>0.030893</td>\n",
       "      <td>0.273265</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>1285495153202024448</td>\n",
       "      <td>da</td>\n",
       "      <td>2020-07-21 12:57:34</td>\n",
       "      <td>1285559543276150784</td>\n",
       "      <td>@nielsfez @perlysholt Gode pointer. Og du har ...</td>\n",
       "      <td>383396359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1285520419529863168</td>\n",
       "      <td>27626050</td>\n",
       "      <td>0307932903</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>@nielsfez @perlysholt Good pointer. And you're...</td>\n",
       "      <td>0.861533</td>\n",
       "      <td>0.042326</td>\n",
       "      <td>0.096141</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.799272</td>\n",
       "      <td>0.025806</td>\n",
       "      <td>0.174923</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1285495153202024448</td>\n",
       "      <td>da</td>\n",
       "      <td>2020-07-21 10:22:06</td>\n",
       "      <td>1285520419529863168</td>\n",
       "      <td>@SimonStoerup @perlysholt Hm. Man ville som ud...</td>\n",
       "      <td>27626050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>383396359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>@SimonStoerup @perlysholt Hm. You would be abl...</td>\n",
       "      <td>0.768433</td>\n",
       "      <td>0.012006</td>\n",
       "      <td>0.219561</td>\n",
       "      <td>no</td>\n",
       "      <td>0.770013</td>\n",
       "      <td>0.019735</td>\n",
       "      <td>0.210252</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>da</td>\n",
       "      <td>2019-09-18 19:10:18</td>\n",
       "      <td>1174400270710820870</td>\n",
       "      <td>@R4nd4hl @khoenge Sjovt du synes netop Hønge b...</td>\n",
       "      <td>861057936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>72823792</td>\n",
       "      <td>1508892043</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>@R4nd4hl @khoenge Funny you think just Hønge s...</td>\n",
       "      <td>0.917323</td>\n",
       "      <td>0.018060</td>\n",
       "      <td>0.064617</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.759511</td>\n",
       "      <td>0.142903</td>\n",
       "      <td>0.097587</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>da</td>\n",
       "      <td>2019-09-18 18:50:58</td>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>Detektor har undersøgt det: @khoenge talte usa...</td>\n",
       "      <td>72823792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Detector has examined it: @khoenge spoke untru...</td>\n",
       "      <td>0.829699</td>\n",
       "      <td>0.078995</td>\n",
       "      <td>0.091306</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.654120</td>\n",
       "      <td>0.126598</td>\n",
       "      <td>0.219282</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1481298462238982144</td>\n",
       "      <td>da</td>\n",
       "      <td>2022-01-12 19:25:54</td>\n",
       "      <td>1481346717513662464</td>\n",
       "      <td>@ReneAndersenDK Forskellen er, at ham her også...</td>\n",
       "      <td>805874425988087811</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1481345545721495554</td>\n",
       "      <td>4776986009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>@ReneAndersenDK The difference is that this gu...</td>\n",
       "      <td>0.834556</td>\n",
       "      <td>0.091175</td>\n",
       "      <td>0.074269</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.713310</td>\n",
       "      <td>0.019431</td>\n",
       "      <td>0.267258</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1380 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          conversation_id lang           created_at                   id  \\\n",
       "0     1036583587242549248   da  2018-09-03 21:04:41  1036721666628444160   \n",
       "2      899548260863488002   da  2017-08-21 12:10:42   899604671375052801   \n",
       "3      899548260863488002   da  2017-08-21 12:06:17   899603561323081729   \n",
       "5     1345496479583113217   da  2021-01-03 00:16:57  1345524516311748608   \n",
       "6     1238602270129913857   da  2020-03-14 00:05:06  1238617110496059392   \n",
       "...                   ...  ...                  ...                  ...   \n",
       "1994  1285495153202024448   da  2020-07-21 12:57:34  1285559543276150784   \n",
       "1995  1285495153202024448   da  2020-07-21 10:22:06  1285520419529863168   \n",
       "1996  1174395406719102976   da  2019-09-18 19:10:18  1174400270710820870   \n",
       "1997  1174395406719102976   da  2019-09-18 18:50:58  1174395406719102976   \n",
       "1998  1481298462238982144   da  2022-01-12 19:25:54  1481346717513662464   \n",
       "\n",
       "                                                   text           author_id  \\\n",
       "0     @frkomo Jeg siger det vel strengt taget bare t...          1666088336   \n",
       "2     @PeterHuggler Had alt det, du vil. Men du skal...           547416021   \n",
       "3     @brianweichardt Jeg hader den her slags: Du gå...          3301029597   \n",
       "5     @stinuslindgreen @Heunicke I min optik, er det...            23341699   \n",
       "6     @RasmusMalver @radikale Det er jeg ked af. Jeg...            87923613   \n",
       "...                                                 ...                 ...   \n",
       "1994  @nielsfez @perlysholt Gode pointer. Og du har ...           383396359   \n",
       "1995  @SimonStoerup @perlysholt Hm. Man ville som ud...            27626050   \n",
       "1996  @R4nd4hl @khoenge Sjovt du synes netop Hønge b...           861057936   \n",
       "1997  Detektor har undersøgt det: @khoenge talte usa...            72823792   \n",
       "1998  @ReneAndersenDK Forskellen er, at ham her også...  805874425988087811   \n",
       "\n",
       "      replied_to_reply_count referenced_tweets_id in_reply_to_user_id  \\\n",
       "0                        1.0  1036721302692917250           148061237   \n",
       "2                        1.0   899603561323081729          3301029597   \n",
       "3                        NaN                  NaN           547416021   \n",
       "5                        NaN                  NaN            87923613   \n",
       "6                        1.0  1238602270129913857  737702576506994688   \n",
       "...                      ...                  ...                 ...   \n",
       "1994                     0.0  1285520419529863168            27626050   \n",
       "1995                     NaN                  NaN           383396359   \n",
       "1996                     0.0  1174395406719102976            72823792   \n",
       "1997                     NaN                  NaN                 NaN   \n",
       "1998                     1.0  1481345545721495554          4776986009   \n",
       "\n",
       "             PNR  ... quote_n  \\\n",
       "0     1311570613  ...       0   \n",
       "2     1405772015  ...       0   \n",
       "3            NaN  ...       0   \n",
       "5            NaN  ...       0   \n",
       "6     0908801199  ...       0   \n",
       "...          ...  ...     ...   \n",
       "1994  0307932903  ...       0   \n",
       "1995         NaN  ...       0   \n",
       "1996  1508892043  ...       0   \n",
       "1997         NaN  ...       0   \n",
       "1998         NaN  ...       0   \n",
       "\n",
       "                                             translated  \\\n",
       "0     @frkomo I guess I'm saying it strictly just to...   \n",
       "2     @PeterHuggler Had everything you want. But don...   \n",
       "3     @brianweichardt I hate this kind of thing: You...   \n",
       "5     @stinuslindgreen @Heunicke In my optics, it is...   \n",
       "6     @RasmusMalver @radical I'm sorry. I want to un...   \n",
       "...                                                 ...   \n",
       "1994  @nielsfez @perlysholt Good pointer. And you're...   \n",
       "1995  @SimonStoerup @perlysholt Hm. You would be abl...   \n",
       "1996  @R4nd4hl @khoenge Funny you think just Hønge s...   \n",
       "1997  Detector has examined it: @khoenge spoke untru...   \n",
       "1998  @ReneAndersenDK The difference is that this gu...   \n",
       "\n",
       "      ZS_counterspeech_score  ZS_hate_score  ZS_neutral_score  \\\n",
       "0                   0.632259       0.034136          0.333605   \n",
       "2                   0.317035       0.016395          0.666571   \n",
       "3                   0.095866       0.883837          0.020297   \n",
       "5                   0.628949       0.027665          0.343386   \n",
       "6                   0.876910       0.037730          0.085360   \n",
       "...                      ...            ...               ...   \n",
       "1994                0.861533       0.042326          0.096141   \n",
       "1995                0.768433       0.012006          0.219561   \n",
       "1996                0.917323       0.018060          0.064617   \n",
       "1997                0.829699       0.078995          0.091306   \n",
       "1998                0.834556       0.091175          0.074269   \n",
       "\n",
       "     ZS_counterspeech  ZS_counterspeech_score_dan  ZS_hate_score_dan  \\\n",
       "0                  no                    0.765376           0.008536   \n",
       "2                  no                    0.575550           0.030307   \n",
       "3                  no                    0.616760           0.015232   \n",
       "5                  no                    0.521844           0.021986   \n",
       "6                 yes                    0.695842           0.030893   \n",
       "...               ...                         ...                ...   \n",
       "1994              yes                    0.799272           0.025806   \n",
       "1995               no                    0.770013           0.019735   \n",
       "1996              yes                    0.759511           0.142903   \n",
       "1997              yes                    0.654120           0.126598   \n",
       "1998              yes                    0.713310           0.019431   \n",
       "\n",
       "     ZS_neutral_score_dan ZS_counterspeech_dan  \n",
       "0                0.226088                   no  \n",
       "2                0.394142                   no  \n",
       "3                0.368008                   no  \n",
       "5                0.456171                   no  \n",
       "6                0.273265                   no  \n",
       "...                   ...                  ...  \n",
       "1994             0.174923                   no  \n",
       "1995             0.210252                   no  \n",
       "1996             0.097587                   no  \n",
       "1997             0.219282                   no  \n",
       "1998             0.267258                   no  \n",
       "\n",
       "[1380 rows x 34 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conunt_no_dan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65d98a40-de8c-4f73-bd03-405f507b1f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting scores: 100%|████████████████████| 2000/2000 [04:16<00:00,  7.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>replied_to_reply_count</th>\n",
       "      <th>referenced_tweets_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>PNR</th>\n",
       "      <th>...</th>\n",
       "      <th>ZS_hate_score</th>\n",
       "      <th>ZS_neutral_score</th>\n",
       "      <th>ZS_counterspeech</th>\n",
       "      <th>ZS_counterspeech_score_dan</th>\n",
       "      <th>ZS_hate_score_dan</th>\n",
       "      <th>ZS_neutral_score_dan</th>\n",
       "      <th>ZS_counterspeech_dan</th>\n",
       "      <th>ZS_counterspeech_score_new_labels</th>\n",
       "      <th>ZS_no_counterspeech_score_new_labels</th>\n",
       "      <th>ZS_counterspeech_new_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1036583587242549248</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-09-03 21:04:41</td>\n",
       "      <td>1036721666628444160</td>\n",
       "      <td>@frkomo Jeg siger det vel strengt taget bare t...</td>\n",
       "      <td>1666088336</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1036721302692917250</td>\n",
       "      <td>148061237</td>\n",
       "      <td>1311570613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034136</td>\n",
       "      <td>0.333605</td>\n",
       "      <td>no</td>\n",
       "      <td>0.765376</td>\n",
       "      <td>0.008536</td>\n",
       "      <td>0.226088</td>\n",
       "      <td>no</td>\n",
       "      <td>0.926184</td>\n",
       "      <td>0.073816</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1036583587242549248</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-09-03 21:03:14</td>\n",
       "      <td>1036721302692917250</td>\n",
       "      <td>@MonbergSF Sig det til spillerforeningen, som ...</td>\n",
       "      <td>148061237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1666088336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019291</td>\n",
       "      <td>0.029320</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.853204</td>\n",
       "      <td>0.006963</td>\n",
       "      <td>0.139833</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.976817</td>\n",
       "      <td>0.023183</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>899548260863488002</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-08-21 12:10:42</td>\n",
       "      <td>899604671375052801</td>\n",
       "      <td>@PeterHuggler Had alt det, du vil. Men du skal...</td>\n",
       "      <td>547416021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>899603561323081729</td>\n",
       "      <td>3301029597</td>\n",
       "      <td>1405772015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016395</td>\n",
       "      <td>0.666571</td>\n",
       "      <td>no</td>\n",
       "      <td>0.575550</td>\n",
       "      <td>0.030307</td>\n",
       "      <td>0.394142</td>\n",
       "      <td>no</td>\n",
       "      <td>0.852871</td>\n",
       "      <td>0.147129</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>899548260863488002</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-08-21 12:06:17</td>\n",
       "      <td>899603561323081729</td>\n",
       "      <td>@brianweichardt Jeg hader den her slags: Du gå...</td>\n",
       "      <td>3301029597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>547416021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883837</td>\n",
       "      <td>0.020297</td>\n",
       "      <td>no</td>\n",
       "      <td>0.616760</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>0.368008</td>\n",
       "      <td>no</td>\n",
       "      <td>0.911839</td>\n",
       "      <td>0.088161</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1345496479583113217</td>\n",
       "      <td>da</td>\n",
       "      <td>2021-01-03 12:38:16</td>\n",
       "      <td>1345711074407014400</td>\n",
       "      <td>@nielscallesoe @Heunicke Din første indvending...</td>\n",
       "      <td>87923613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1345524516311748608</td>\n",
       "      <td>23341699</td>\n",
       "      <td>0908801199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016685</td>\n",
       "      <td>0.119886</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.815085</td>\n",
       "      <td>0.017978</td>\n",
       "      <td>0.166937</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.962703</td>\n",
       "      <td>0.037297</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1285495153202024448</td>\n",
       "      <td>da</td>\n",
       "      <td>2020-07-21 10:22:06</td>\n",
       "      <td>1285520419529863168</td>\n",
       "      <td>@SimonStoerup @perlysholt Hm. Man ville som ud...</td>\n",
       "      <td>27626050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>383396359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012006</td>\n",
       "      <td>0.219561</td>\n",
       "      <td>no</td>\n",
       "      <td>0.770013</td>\n",
       "      <td>0.019735</td>\n",
       "      <td>0.210252</td>\n",
       "      <td>no</td>\n",
       "      <td>0.790419</td>\n",
       "      <td>0.209581</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>da</td>\n",
       "      <td>2019-09-18 19:10:18</td>\n",
       "      <td>1174400270710820870</td>\n",
       "      <td>@R4nd4hl @khoenge Sjovt du synes netop Hønge b...</td>\n",
       "      <td>861057936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>72823792</td>\n",
       "      <td>1508892043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018060</td>\n",
       "      <td>0.064617</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.759511</td>\n",
       "      <td>0.142903</td>\n",
       "      <td>0.097587</td>\n",
       "      <td>no</td>\n",
       "      <td>0.938951</td>\n",
       "      <td>0.061049</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>da</td>\n",
       "      <td>2019-09-18 18:50:58</td>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>Detektor har undersøgt det: @khoenge talte usa...</td>\n",
       "      <td>72823792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078995</td>\n",
       "      <td>0.091306</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.654120</td>\n",
       "      <td>0.126598</td>\n",
       "      <td>0.219282</td>\n",
       "      <td>no</td>\n",
       "      <td>0.964718</td>\n",
       "      <td>0.035282</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1481298462238982144</td>\n",
       "      <td>da</td>\n",
       "      <td>2022-01-12 19:25:54</td>\n",
       "      <td>1481346717513662464</td>\n",
       "      <td>@ReneAndersenDK Forskellen er, at ham her også...</td>\n",
       "      <td>805874425988087811</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1481345545721495554</td>\n",
       "      <td>4776986009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091175</td>\n",
       "      <td>0.074269</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.713310</td>\n",
       "      <td>0.019431</td>\n",
       "      <td>0.267258</td>\n",
       "      <td>no</td>\n",
       "      <td>0.935881</td>\n",
       "      <td>0.064119</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1481298462238982144</td>\n",
       "      <td>da</td>\n",
       "      <td>2022-01-12 19:21:14</td>\n",
       "      <td>1481345545721495554</td>\n",
       "      <td>@baretraet Sådan et mål har vi sgu da alle sam...</td>\n",
       "      <td>4776986009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>805874425988087811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009041</td>\n",
       "      <td>0.067639</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.851687</td>\n",
       "      <td>0.055234</td>\n",
       "      <td>0.093079</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.972140</td>\n",
       "      <td>0.027860</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          conversation_id lang           created_at                   id  \\\n",
       "0     1036583587242549248   da  2018-09-03 21:04:41  1036721666628444160   \n",
       "1     1036583587242549248   da  2018-09-03 21:03:14  1036721302692917250   \n",
       "2      899548260863488002   da  2017-08-21 12:10:42   899604671375052801   \n",
       "3      899548260863488002   da  2017-08-21 12:06:17   899603561323081729   \n",
       "4     1345496479583113217   da  2021-01-03 12:38:16  1345711074407014400   \n",
       "...                   ...  ...                  ...                  ...   \n",
       "1995  1285495153202024448   da  2020-07-21 10:22:06  1285520419529863168   \n",
       "1996  1174395406719102976   da  2019-09-18 19:10:18  1174400270710820870   \n",
       "1997  1174395406719102976   da  2019-09-18 18:50:58  1174395406719102976   \n",
       "1998  1481298462238982144   da  2022-01-12 19:25:54  1481346717513662464   \n",
       "1999  1481298462238982144   da  2022-01-12 19:21:14  1481345545721495554   \n",
       "\n",
       "                                                   text           author_id  \\\n",
       "0     @frkomo Jeg siger det vel strengt taget bare t...          1666088336   \n",
       "1     @MonbergSF Sig det til spillerforeningen, som ...           148061237   \n",
       "2     @PeterHuggler Had alt det, du vil. Men du skal...           547416021   \n",
       "3     @brianweichardt Jeg hader den her slags: Du gå...          3301029597   \n",
       "4     @nielscallesoe @Heunicke Din første indvending...            87923613   \n",
       "...                                                 ...                 ...   \n",
       "1995  @SimonStoerup @perlysholt Hm. Man ville som ud...            27626050   \n",
       "1996  @R4nd4hl @khoenge Sjovt du synes netop Hønge b...           861057936   \n",
       "1997  Detektor har undersøgt det: @khoenge talte usa...            72823792   \n",
       "1998  @ReneAndersenDK Forskellen er, at ham her også...  805874425988087811   \n",
       "1999  @baretraet Sådan et mål har vi sgu da alle sam...          4776986009   \n",
       "\n",
       "      replied_to_reply_count referenced_tweets_id in_reply_to_user_id  \\\n",
       "0                        1.0  1036721302692917250           148061237   \n",
       "1                        NaN                  NaN          1666088336   \n",
       "2                        1.0   899603561323081729          3301029597   \n",
       "3                        NaN                  NaN           547416021   \n",
       "4                        1.0  1345524516311748608            23341699   \n",
       "...                      ...                  ...                 ...   \n",
       "1995                     NaN                  NaN           383396359   \n",
       "1996                     0.0  1174395406719102976            72823792   \n",
       "1997                     NaN                  NaN                 NaN   \n",
       "1998                     1.0  1481345545721495554          4776986009   \n",
       "1999                     NaN                  NaN  805874425988087811   \n",
       "\n",
       "             PNR  ... ZS_hate_score  ZS_neutral_score  ZS_counterspeech  \\\n",
       "0     1311570613  ...      0.034136          0.333605                no   \n",
       "1            NaN  ...      0.019291          0.029320               yes   \n",
       "2     1405772015  ...      0.016395          0.666571                no   \n",
       "3            NaN  ...      0.883837          0.020297                no   \n",
       "4     0908801199  ...      0.016685          0.119886               yes   \n",
       "...          ...  ...           ...               ...               ...   \n",
       "1995         NaN  ...      0.012006          0.219561                no   \n",
       "1996  1508892043  ...      0.018060          0.064617               yes   \n",
       "1997         NaN  ...      0.078995          0.091306               yes   \n",
       "1998         NaN  ...      0.091175          0.074269               yes   \n",
       "1999         NaN  ...      0.009041          0.067639               yes   \n",
       "\n",
       "      ZS_counterspeech_score_dan  ZS_hate_score_dan ZS_neutral_score_dan  \\\n",
       "0                       0.765376           0.008536             0.226088   \n",
       "1                       0.853204           0.006963             0.139833   \n",
       "2                       0.575550           0.030307             0.394142   \n",
       "3                       0.616760           0.015232             0.368008   \n",
       "4                       0.815085           0.017978             0.166937   \n",
       "...                          ...                ...                  ...   \n",
       "1995                    0.770013           0.019735             0.210252   \n",
       "1996                    0.759511           0.142903             0.097587   \n",
       "1997                    0.654120           0.126598             0.219282   \n",
       "1998                    0.713310           0.019431             0.267258   \n",
       "1999                    0.851687           0.055234             0.093079   \n",
       "\n",
       "      ZS_counterspeech_dan  ZS_counterspeech_score_new_labels  \\\n",
       "0                       no                           0.926184   \n",
       "1                      yes                           0.976817   \n",
       "2                       no                           0.852871   \n",
       "3                       no                           0.911839   \n",
       "4                      yes                           0.962703   \n",
       "...                    ...                                ...   \n",
       "1995                    no                           0.790419   \n",
       "1996                    no                           0.938951   \n",
       "1997                    no                           0.964718   \n",
       "1998                    no                           0.935881   \n",
       "1999                   yes                           0.972140   \n",
       "\n",
       "     ZS_no_counterspeech_score_new_labels ZS_counterspeech_new_labels  \n",
       "0                                0.073816                         yes  \n",
       "1                                0.023183                         yes  \n",
       "2                                0.147129                         yes  \n",
       "3                                0.088161                         yes  \n",
       "4                                0.037297                         yes  \n",
       "...                                   ...                         ...  \n",
       "1995                             0.209581                          no  \n",
       "1996                             0.061049                         yes  \n",
       "1997                             0.035282                         yes  \n",
       "1998                             0.064119                         yes  \n",
       "1999                             0.027860                         yes  \n",
       "\n",
       "[2000 rows x 37 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test: model with counterspeech/non-counterspeech labels \n",
    "\n",
    "# Candidate labels\n",
    "candidate_labels = ['counterspeech', 'no counterspeech']\n",
    "\n",
    "# List to store the scores\n",
    "counterspeech_scores = []\n",
    "no_counterspeech_scores = []\n",
    "\n",
    "\n",
    "# Iterate over each text\n",
    "for text in (tqdm(pairs_small['translated'], desc= \"Extracting scores\")) :\n",
    "    result = pipe_1(text, candidate_labels)\n",
    "    # Extract the scores\n",
    "    counterspeech_score = dict(zip(result['labels'], result['scores']))['counterspeech']\n",
    "    no_counterspeech_score = dict(zip(result['labels'], result['scores']))['no counterspeech']\n",
    "    # Append the scores to the lists\n",
    "    counterspeech_scores.append(counterspeech_score)\n",
    "    no_counterspeech_scores.append(no_counterspeech_score)\n",
    "\n",
    "# Add the scores as a new column in the DataFrame\n",
    "pairs_small['ZS_counterspeech_score_new_labels'] = counterspeech_scores\n",
    "pairs_small['ZS_no_counterspeech_score_new_labels'] = no_counterspeech_scores\n",
    "\n",
    "\n",
    "# Initialize the 'counterspeech' column with 'NA'\n",
    "pairs_small['ZS_counterspeech_new_labels'] = 'NA'\n",
    "\n",
    "# Update the 'counterspeech' column based on the 'counterspeech_score'\n",
    "for index, row in pairs_small.iterrows():\n",
    "    if row['ZS_counterspeech_score_new_labels'] > 0.8:\n",
    "        pairs_small.at[index, 'ZS_counterspeech_new_labels'] = 'yes'\n",
    "    else:\n",
    "        pairs_small.at[index, 'ZS_counterspeech_new_labels'] = 'no'    \n",
    "\n",
    "\n",
    "pairs_small\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80e07b81-aa32-4215-a95b-7b7755cb61d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZS_counterspeech_new_labels\n",
       "yes    1775\n",
       "no      225\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_small['ZS_counterspeech_new_labels'].value_counts(dropna=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20d36533-4895-49f1-b41d-e191a0aea8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@peterbrothersen Exactly... So thin post from @AnneFrostJepsen... \"Don\\'t beat the politicians even if they beat on a daily basis\" Adult communication requires a desire from the politicians to act adultly and we still need to see',\n",
       " \"@Nikolaj32LFC @EsbenSuurballe @ClarkJamesYNWA @larsmathiasen It sums everything up well. Just call us old angry men, I'll call it due diligence. Hope sincerely, you're right, but I would call our sporting management outright naive if they plan on such hopes. There's too much likelihood of it going wrong.\",\n",
       " \"@BrianArlyJac @politiken There is no contradiction between what you say here and what I say above. But for me it is not the moralist's problem, but ours. If man can only follow entertainment but not morals or self-preservation, then it (we) may not be able to save himself.\",\n",
       " '@MagnusPharao @politiken I completely disagree with that - the moralists do not win this case. That is exactly what election after election shows.',\n",
       " '@mfsvendsen It was certainly not. I have covered AGF since 1996',\n",
       " \"@quitte74 @pferdinandsen Thank you so much, so we have a little to look at. I would have loved the same options myself, but Basic on a Commodore 64 wasn't out of the way either.\",\n",
       " '@Cihat_Bardak The only thing I have said is that you have no evidence. Has written that I am not defending the electorate of the convicted racist, because I see absolutely no reason for that. And no longer is it. We have been here before, Cihat. Word matters is my point. https://t.co/nToQwpEIj2',\n",
       " \"@HenrikDyhHansen You're working on this with the fact that it's a job without either dealing with my arguments or arguing for your cause. How do you think you're NOT a racist when you want to be represented by a man who's highly racist in all his work?\",\n",
       " \"@MichaelHoumann @teodora_hansen I will not talk the matter down, because equality is important. However, we need to relate to today's exam assignments if it is to make sense. (Synthesis I) 🙂\",\n",
       " '@larskohler @DanskDf1995 We just leave it there... bad with the political reality, you think it is absurd. Strange approach to the green transition. Also good day from here.',\n",
       " '@KKMailand @DanskDf1995 No. A reduction in the number of wind turbines is not relevant. Neither if you want a green future or if you want welfare and growth. So no. When the premise for dialogue is an absurd idea like that, then I am not interested. Go day.',\n",
       " \"@MonbergSF @Alrekr @jacobmark_sf @sophieloehde @Spoltik When you want to talk around you must be given you are the persistence of your apology for it.... no matter how miserable it is. We're not getting any further. You can't justify the 70% nonsense. Nothing new under the sun there.\",\n",
       " \"@brianweichardt @SorenPape Have you read the article? It's a chronicle - not a political play.\",\n",
       " \"@MathiasRath @pmk8080 @pferdinandsen In the same moment as you wrote, my wife called and told me. I don't know, because you can say for and against. We do our training if there isn't a counter order, but that being said, I will understand a temporary lock down\",\n",
       " \"@pmk8080 @MThoregaard @pferdinandsen There is only a Leisure Scheme, so you'll assume that they don't...\",\n",
       " '@ebsandbye Jo, it does. My point is banal, I think you have better thoughts yourself. It is hard to create global respect - as you want - for our European perception of fair competition when we ourselves do not create (essentially) companies based in that culture.',\n",
       " '@DonDueholm Well as black and white you can not look at it - many new dancers are 1 go business + multi &amp; multi get it! #dkpol',\n",
       " '@larskohler @anderthomsen20 @jesbc @SorenHave @DanskErhverv @ulrichbang I am not asking for metaphors but for a source. If you do not have it, then fair enough. But then your thesis is only a thesis - not something you can shoot down our scientifically supported analysis with. Good Friday!',\n",
       " 'I have a text in English that I want a native-speaking to read up and record as an MP3. Where do I find the right person?',\n",
       " \"@Chrimajaki @BosseStine @RasmusJarlov No he hasn't and you should learn your history. The only thing that consistently forms the basis for this type of events is fascist nationalism. You make the statement so you have to argue for that attitude and support it with facts.\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pull up text examples\n",
    "new_label_no = pairs_small[pairs_small['ZS_counterspeech_new_labels'] == 'no']\n",
    "\n",
    "# can print the whole text using\n",
    "text_to_print_1 = new_label_no['translated'].head(20).tolist()\n",
    "text_to_print_1\n",
    "\n",
    "# the new labels doesnt change much, still alot of obvious examples of counterspeech is classified as not counterspeech\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bae2b9-af2c-412c-a3f4-354c50e2d4bd",
   "metadata": {},
   "source": [
    "### cross-encoder/nli-deberta-base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c886e215-449b-4120-a1a5-b0fc74a836bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipe_2 = pipeline(\"zero-shot-classification\", model=\"cross-encoder/nli-deberta-base\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d5ce268-9020-445c-8187-112f616f4dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'i see your point but i dont think it is very constructive',\n",
       " 'labels': ['counterspeech', 'neutral tone', 'hate'],\n",
       " 'scores': [0.5037503242492676, 0.4367963671684265, 0.05945330858230591]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_labels = ['counterspeech', 'hate', 'neutral tone']\n",
    "\n",
    "sequence_to_classify_1 = \"i see your point but i dont think it is very constructive\"\n",
    "sequence_to_classify_2 = \"jeg forstår hvad du mener, men din kommentar er ikke særlig konstruktiv\"\n",
    "\n",
    "\n",
    "pipe_2(sequence_to_classify_1, candidate_labels)\n",
    "\n",
    "# doesnt seem very good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f334dd-9dc0-4f54-8421-8e2af64c862f",
   "metadata": {},
   "source": [
    "### TarsClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b52b574f-177a-4f4c-91c8-0a66e30dea2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Flair in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.14.0)\n",
      "Requirement already satisfied: boto3>=1.20.27 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (1.34.151)\n",
      "Requirement already satisfied: conllu<5.0.0,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (4.5.3)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (1.2.14)\n",
      "Requirement already satisfied: ftfy>=6.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (6.2.0)\n",
      "Requirement already satisfied: gdown>=4.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (5.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (0.24.3)\n",
      "Requirement already satisfied: langdetect>=1.0.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (1.0.9)\n",
      "Requirement already satisfied: lxml>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (5.2.2)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (3.8.0)\n",
      "Requirement already satisfied: more-itertools>=8.13.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (10.3.0)\n",
      "Requirement already satisfied: mpld3>=0.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (0.5.10)\n",
      "Requirement already satisfied: pptree>=3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (2.8.2)\n",
      "Requirement already satisfied: pytorch-revgrad>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (0.2.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (2023.10.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (1.3.2)\n",
      "Requirement already satisfied: segtok>=1.5.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (1.5.11)\n",
      "Requirement already satisfied: sqlitedict>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (2.1.0)\n",
      "Requirement already satisfied: tabulate>=0.8.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (0.9.0)\n",
      "Requirement already satisfied: torch!=1.8,>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (2.1.0)\n",
      "Requirement already satisfied: tqdm>=4.63.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (4.66.5)\n",
      "Requirement already satisfied: transformer-smaller-training-vocab>=0.2.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (0.4.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.18.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->Flair) (4.44.0)\n",
      "Requirement already satisfied: wikipedia-api>=0.5.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (0.6.0)\n",
      "Requirement already satisfied: semver<4.0.0,>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (3.0.2)\n",
      "Requirement already satisfied: bioc<3.0.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (2.1)\n",
      "Requirement already satisfied: jsonlines>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from bioc<3.0.0,>=2.0.0->Flair) (4.0.0)\n",
      "Requirement already satisfied: intervaltree in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from bioc<3.0.0,>=2.0.0->Flair) (3.1.0)\n",
      "Requirement already satisfied: docopt in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from bioc<3.0.0,>=2.0.0->Flair) (0.6.2)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.151 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from boto3>=1.20.27->Flair) (1.34.151)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from boto3>=1.20.27->Flair) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from boto3>=1.20.27->Flair) (0.10.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from deprecated>=1.2.13->Flair) (1.16.0)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ftfy>=6.1.0->Flair) (0.2.13)\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gdown>=4.4.0->Flair) (4.12.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gdown>=4.4.0->Flair) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gdown>=4.4.0->Flair) (2.31.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.10.0->Flair) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.10.0->Flair) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.10.0->Flair) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.10.0->Flair) (4.8.0)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langdetect>=1.0.9->Flair) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=2.2.3->Flair) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=2.2.3->Flair) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=2.2.3->Flair) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=2.2.3->Flair) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=2.2.3->Flair) (1.23.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=2.2.3->Flair) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=2.2.3->Flair) (3.1.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from mpld3>=0.3->Flair) (3.1.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn>=1.0.2->Flair) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn>=1.0.2->Flair) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn>=1.0.2->Flair) (3.2.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch!=1.8,>=1.5.0->Flair) (1.12)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch!=1.8,>=1.5.0->Flair) (3.2.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers<5.0.0,>=4.18.0->transformers[sentencepiece]<5.0.0,>=4.18.0->Flair) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers<5.0.0,>=4.18.0->transformers[sentencepiece]<5.0.0,>=4.18.0->Flair) (0.19.1)\n",
      "Requirement already satisfied: protobuf in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->Flair) (4.25.3)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->Flair) (0.1.99)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.151->boto3>=1.20.27->Flair) (2.0.5)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonlines>=1.2.0->bioc<3.0.0,>=2.0.0->Flair) (23.1.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->Flair) (0.32.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from beautifulsoup4->gdown>=4.4.0->Flair) (2.5)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from intervaltree->bioc<3.0.0,>=2.0.0->Flair) (2.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->mpld3>=0.3->Flair) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests[socks]->gdown>=4.4.0->Flair) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests[socks]->gdown>=4.4.0->Flair) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests[socks]->gdown>=4.4.0->Flair) (2024.2.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests[socks]->gdown>=4.4.0->Flair) (1.7.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->torch!=1.8,>=1.5.0->Flair) (1.3.0)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate>=0.21.0->transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->Flair) (5.9.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3c44a42-ad48-4130-aded-23c3d4d9ffd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-08 13:47:34,778 TARS initialized without a task. You need to call .add_and_switch_to_new_task() before training this model\n",
      "2024-08-08 13:47:34,870 Provided `None` does not exist in the model. Consider calling `add_and_switch_to_new_task` first.\n",
      "2024-08-08 13:47:34,871 `ZeroShot` is the current task. Switch to some other task before dropping this.\n",
      "Sentence[7]: \"i understand, but i dont agree\"\n"
     ]
    }
   ],
   "source": [
    "from flair.models import TARSClassifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "\n",
    "tars = TARSClassifier.load('tars-base')\n",
    "\n",
    "\n",
    "sentence = Sentence(\"jeg forstår hvad du mener, men din kommentar er ikke særlig konstruktiv\")\n",
    "sentence_2 = Sentence(\"i understand, but i dont agree\")\n",
    "\n",
    "\n",
    "classes = [\"counterspeech\", \"hate\"]\n",
    "\n",
    "tars.predict_zero_shot(sentence_2, classes)\n",
    "\n",
    "print(sentence_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5472605a-9dc3-43a5-8c48-c7dbaf588d4d",
   "metadata": {},
   "source": [
    "## Applying classification models (2 different models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41001fb-a2c0-4f50-bdef-6e73c907af93",
   "metadata": {},
   "source": [
    "#### Counterargument classifier (from huggingface)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d91fc1c-1de3-4701-ae3a-f4ba59f0fd72",
   "metadata": {},
   "source": [
    "https://huggingface.co/ThinkCERCA/counterargument_hugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ae78d56-c215-42b2-adc9-68a4f0850516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipe_3 = pipeline(\"text-classification\", model=\"ThinkCERCA/counterargument_hugging\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2364ef87-95ef-4594-8841-894519cef7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'Not Counterargument', 'score': 0.6886796355247498}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gives labels: Not Counterargument or Counterargument with a score\n",
    "\n",
    "text = \"I understand, but actually you are incorrect. Science show that the earth is round\"\n",
    "text_2 = \"Jeg forstår din pointe, men den er ikke korrekt. Videnskaben viser at jorden er rund\"\n",
    "text_3 = \"your a fool\"\n",
    "text_4 = \"du er bare dum\"\n",
    "text_5 = \"i like dogs, but also cats\"\n",
    "\n",
    "# Apply the pipeline to the text\n",
    "result = pipe_3(text_5)\n",
    "result\n",
    "\n",
    "#seems a little too generous with the counterargument label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "108cc141-52d6-4a85-a435-e2c731da4455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting scores: 100%|████████████████████| 2000/2000 [03:50<00:00,  8.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>replied_to_reply_count</th>\n",
       "      <th>referenced_tweets_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>PNR</th>\n",
       "      <th>...</th>\n",
       "      <th>ZS_counterspeech</th>\n",
       "      <th>ZS_counterspeech_score_dan</th>\n",
       "      <th>ZS_hate_score_dan</th>\n",
       "      <th>ZS_neutral_score_dan</th>\n",
       "      <th>ZS_counterspeech_dan</th>\n",
       "      <th>ZS_counterspeech_score_new_labels</th>\n",
       "      <th>ZS_no_counterspeech_score_new_labels</th>\n",
       "      <th>ZS_counterspeech_new_labels</th>\n",
       "      <th>coun_classifier_label_model1</th>\n",
       "      <th>coun_classifier_score_model1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1036583587242549248</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-09-03 21:04:41</td>\n",
       "      <td>1036721666628444160</td>\n",
       "      <td>@frkomo Jeg siger det vel strengt taget bare t...</td>\n",
       "      <td>1666088336</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1036721302692917250</td>\n",
       "      <td>148061237</td>\n",
       "      <td>1311570613</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>0.765376</td>\n",
       "      <td>0.008536</td>\n",
       "      <td>0.226088</td>\n",
       "      <td>no</td>\n",
       "      <td>0.926184</td>\n",
       "      <td>0.073816</td>\n",
       "      <td>yes</td>\n",
       "      <td>Not Counterargument</td>\n",
       "      <td>0.712887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1036583587242549248</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-09-03 21:03:14</td>\n",
       "      <td>1036721302692917250</td>\n",
       "      <td>@MonbergSF Sig det til spillerforeningen, som ...</td>\n",
       "      <td>148061237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1666088336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.853204</td>\n",
       "      <td>0.006963</td>\n",
       "      <td>0.139833</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.976817</td>\n",
       "      <td>0.023183</td>\n",
       "      <td>yes</td>\n",
       "      <td>Not Counterargument</td>\n",
       "      <td>0.979896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>899548260863488002</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-08-21 12:10:42</td>\n",
       "      <td>899604671375052801</td>\n",
       "      <td>@PeterHuggler Had alt det, du vil. Men du skal...</td>\n",
       "      <td>547416021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>899603561323081729</td>\n",
       "      <td>3301029597</td>\n",
       "      <td>1405772015</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>0.575550</td>\n",
       "      <td>0.030307</td>\n",
       "      <td>0.394142</td>\n",
       "      <td>no</td>\n",
       "      <td>0.852871</td>\n",
       "      <td>0.147129</td>\n",
       "      <td>yes</td>\n",
       "      <td>Counterargument</td>\n",
       "      <td>0.686435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>899548260863488002</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-08-21 12:06:17</td>\n",
       "      <td>899603561323081729</td>\n",
       "      <td>@brianweichardt Jeg hader den her slags: Du gå...</td>\n",
       "      <td>3301029597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>547416021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>0.616760</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>0.368008</td>\n",
       "      <td>no</td>\n",
       "      <td>0.911839</td>\n",
       "      <td>0.088161</td>\n",
       "      <td>yes</td>\n",
       "      <td>Counterargument</td>\n",
       "      <td>0.825158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1345496479583113217</td>\n",
       "      <td>da</td>\n",
       "      <td>2021-01-03 12:38:16</td>\n",
       "      <td>1345711074407014400</td>\n",
       "      <td>@nielscallesoe @Heunicke Din første indvending...</td>\n",
       "      <td>87923613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1345524516311748608</td>\n",
       "      <td>23341699</td>\n",
       "      <td>0908801199</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.815085</td>\n",
       "      <td>0.017978</td>\n",
       "      <td>0.166937</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.962703</td>\n",
       "      <td>0.037297</td>\n",
       "      <td>yes</td>\n",
       "      <td>Counterargument</td>\n",
       "      <td>0.995546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1285495153202024448</td>\n",
       "      <td>da</td>\n",
       "      <td>2020-07-21 10:22:06</td>\n",
       "      <td>1285520419529863168</td>\n",
       "      <td>@SimonStoerup @perlysholt Hm. Man ville som ud...</td>\n",
       "      <td>27626050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>383396359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>0.770013</td>\n",
       "      <td>0.019735</td>\n",
       "      <td>0.210252</td>\n",
       "      <td>no</td>\n",
       "      <td>0.790419</td>\n",
       "      <td>0.209581</td>\n",
       "      <td>no</td>\n",
       "      <td>Counterargument</td>\n",
       "      <td>0.851246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>da</td>\n",
       "      <td>2019-09-18 19:10:18</td>\n",
       "      <td>1174400270710820870</td>\n",
       "      <td>@R4nd4hl @khoenge Sjovt du synes netop Hønge b...</td>\n",
       "      <td>861057936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>72823792</td>\n",
       "      <td>1508892043</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.759511</td>\n",
       "      <td>0.142903</td>\n",
       "      <td>0.097587</td>\n",
       "      <td>no</td>\n",
       "      <td>0.938951</td>\n",
       "      <td>0.061049</td>\n",
       "      <td>yes</td>\n",
       "      <td>Not Counterargument</td>\n",
       "      <td>0.564339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>da</td>\n",
       "      <td>2019-09-18 18:50:58</td>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>Detektor har undersøgt det: @khoenge talte usa...</td>\n",
       "      <td>72823792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.654120</td>\n",
       "      <td>0.126598</td>\n",
       "      <td>0.219282</td>\n",
       "      <td>no</td>\n",
       "      <td>0.964718</td>\n",
       "      <td>0.035282</td>\n",
       "      <td>yes</td>\n",
       "      <td>Not Counterargument</td>\n",
       "      <td>0.975029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1481298462238982144</td>\n",
       "      <td>da</td>\n",
       "      <td>2022-01-12 19:25:54</td>\n",
       "      <td>1481346717513662464</td>\n",
       "      <td>@ReneAndersenDK Forskellen er, at ham her også...</td>\n",
       "      <td>805874425988087811</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1481345545721495554</td>\n",
       "      <td>4776986009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.713310</td>\n",
       "      <td>0.019431</td>\n",
       "      <td>0.267258</td>\n",
       "      <td>no</td>\n",
       "      <td>0.935881</td>\n",
       "      <td>0.064119</td>\n",
       "      <td>yes</td>\n",
       "      <td>Counterargument</td>\n",
       "      <td>0.767544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1481298462238982144</td>\n",
       "      <td>da</td>\n",
       "      <td>2022-01-12 19:21:14</td>\n",
       "      <td>1481345545721495554</td>\n",
       "      <td>@baretraet Sådan et mål har vi sgu da alle sam...</td>\n",
       "      <td>4776986009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>805874425988087811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.851687</td>\n",
       "      <td>0.055234</td>\n",
       "      <td>0.093079</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.972140</td>\n",
       "      <td>0.027860</td>\n",
       "      <td>yes</td>\n",
       "      <td>Not Counterargument</td>\n",
       "      <td>0.661699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          conversation_id lang           created_at                   id  \\\n",
       "0     1036583587242549248   da  2018-09-03 21:04:41  1036721666628444160   \n",
       "1     1036583587242549248   da  2018-09-03 21:03:14  1036721302692917250   \n",
       "2      899548260863488002   da  2017-08-21 12:10:42   899604671375052801   \n",
       "3      899548260863488002   da  2017-08-21 12:06:17   899603561323081729   \n",
       "4     1345496479583113217   da  2021-01-03 12:38:16  1345711074407014400   \n",
       "...                   ...  ...                  ...                  ...   \n",
       "1995  1285495153202024448   da  2020-07-21 10:22:06  1285520419529863168   \n",
       "1996  1174395406719102976   da  2019-09-18 19:10:18  1174400270710820870   \n",
       "1997  1174395406719102976   da  2019-09-18 18:50:58  1174395406719102976   \n",
       "1998  1481298462238982144   da  2022-01-12 19:25:54  1481346717513662464   \n",
       "1999  1481298462238982144   da  2022-01-12 19:21:14  1481345545721495554   \n",
       "\n",
       "                                                   text           author_id  \\\n",
       "0     @frkomo Jeg siger det vel strengt taget bare t...          1666088336   \n",
       "1     @MonbergSF Sig det til spillerforeningen, som ...           148061237   \n",
       "2     @PeterHuggler Had alt det, du vil. Men du skal...           547416021   \n",
       "3     @brianweichardt Jeg hader den her slags: Du gå...          3301029597   \n",
       "4     @nielscallesoe @Heunicke Din første indvending...            87923613   \n",
       "...                                                 ...                 ...   \n",
       "1995  @SimonStoerup @perlysholt Hm. Man ville som ud...            27626050   \n",
       "1996  @R4nd4hl @khoenge Sjovt du synes netop Hønge b...           861057936   \n",
       "1997  Detektor har undersøgt det: @khoenge talte usa...            72823792   \n",
       "1998  @ReneAndersenDK Forskellen er, at ham her også...  805874425988087811   \n",
       "1999  @baretraet Sådan et mål har vi sgu da alle sam...          4776986009   \n",
       "\n",
       "      replied_to_reply_count referenced_tweets_id in_reply_to_user_id  \\\n",
       "0                        1.0  1036721302692917250           148061237   \n",
       "1                        NaN                  NaN          1666088336   \n",
       "2                        1.0   899603561323081729          3301029597   \n",
       "3                        NaN                  NaN           547416021   \n",
       "4                        1.0  1345524516311748608            23341699   \n",
       "...                      ...                  ...                 ...   \n",
       "1995                     NaN                  NaN           383396359   \n",
       "1996                     0.0  1174395406719102976            72823792   \n",
       "1997                     NaN                  NaN                 NaN   \n",
       "1998                     1.0  1481345545721495554          4776986009   \n",
       "1999                     NaN                  NaN  805874425988087811   \n",
       "\n",
       "             PNR  ... ZS_counterspeech  ZS_counterspeech_score_dan  \\\n",
       "0     1311570613  ...               no                    0.765376   \n",
       "1            NaN  ...              yes                    0.853204   \n",
       "2     1405772015  ...               no                    0.575550   \n",
       "3            NaN  ...               no                    0.616760   \n",
       "4     0908801199  ...              yes                    0.815085   \n",
       "...          ...  ...              ...                         ...   \n",
       "1995         NaN  ...               no                    0.770013   \n",
       "1996  1508892043  ...              yes                    0.759511   \n",
       "1997         NaN  ...              yes                    0.654120   \n",
       "1998         NaN  ...              yes                    0.713310   \n",
       "1999         NaN  ...              yes                    0.851687   \n",
       "\n",
       "      ZS_hate_score_dan  ZS_neutral_score_dan  ZS_counterspeech_dan  \\\n",
       "0              0.008536              0.226088                    no   \n",
       "1              0.006963              0.139833                   yes   \n",
       "2              0.030307              0.394142                    no   \n",
       "3              0.015232              0.368008                    no   \n",
       "4              0.017978              0.166937                   yes   \n",
       "...                 ...                   ...                   ...   \n",
       "1995           0.019735              0.210252                    no   \n",
       "1996           0.142903              0.097587                    no   \n",
       "1997           0.126598              0.219282                    no   \n",
       "1998           0.019431              0.267258                    no   \n",
       "1999           0.055234              0.093079                   yes   \n",
       "\n",
       "     ZS_counterspeech_score_new_labels  ZS_no_counterspeech_score_new_labels  \\\n",
       "0                             0.926184                              0.073816   \n",
       "1                             0.976817                              0.023183   \n",
       "2                             0.852871                              0.147129   \n",
       "3                             0.911839                              0.088161   \n",
       "4                             0.962703                              0.037297   \n",
       "...                                ...                                   ...   \n",
       "1995                          0.790419                              0.209581   \n",
       "1996                          0.938951                              0.061049   \n",
       "1997                          0.964718                              0.035282   \n",
       "1998                          0.935881                              0.064119   \n",
       "1999                          0.972140                              0.027860   \n",
       "\n",
       "      ZS_counterspeech_new_labels coun_classifier_label_model1  \\\n",
       "0                             yes          Not Counterargument   \n",
       "1                             yes          Not Counterargument   \n",
       "2                             yes              Counterargument   \n",
       "3                             yes              Counterargument   \n",
       "4                             yes              Counterargument   \n",
       "...                           ...                          ...   \n",
       "1995                           no              Counterargument   \n",
       "1996                          yes          Not Counterargument   \n",
       "1997                          yes          Not Counterargument   \n",
       "1998                          yes              Counterargument   \n",
       "1999                          yes          Not Counterargument   \n",
       "\n",
       "     coun_classifier_score_model1  \n",
       "0                        0.712887  \n",
       "1                        0.979896  \n",
       "2                        0.686435  \n",
       "3                        0.825158  \n",
       "4                        0.995546  \n",
       "...                           ...  \n",
       "1995                     0.851246  \n",
       "1996                     0.564339  \n",
       "1997                     0.975029  \n",
       "1998                     0.767544  \n",
       "1999                     0.661699  \n",
       "\n",
       "[2000 rows x 39 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test on small df (translated)\n",
    "\n",
    "# List to store the scores\n",
    "labels = []\n",
    "scores = []\n",
    "\n",
    "# Iterate over each text\n",
    "for text in (tqdm(pairs_small['translated'], desc= \"Extracting scores\")) :\n",
    "    result = pipe_3(text)\n",
    "    # Extract the scores\n",
    "    label = result[0]['label']\n",
    "    score = result[0]['score']\n",
    "    # Append the scores to the lists\n",
    "    labels.append(label)\n",
    "    scores.append(score)\n",
    "\n",
    "# Add the scores as a new column in the DataFrame\n",
    "pairs_small['coun_classifier_label_model1'] = labels\n",
    "pairs_small['coun_classifier_score_model1'] = scores\n",
    "\n",
    "pairs_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a04caad7-c05e-4034-8e7f-a2950ec8bace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coun_classifier_label_model1\n",
       "Counterargument        1276\n",
       "Not Counterargument     724\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check value counts\n",
    "pairs_small['coun_classifier_label_model1'].value_counts(dropna=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b4d4e25-378c-4d14-8d0d-ea1a38a98c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counterarguments:\n",
      "[\"@PeterHuggler Had everything you want. But don't judge what I think is a natural reaction. I'm not covering that case at all.\", '@brianweichardt I hate this kind of thing: You go in and make yourself a judge, based on a photo. Let the court do its job, and seek only to communicate the case.', '@nielsallesoe @Heunicke Your first objection may be correct. It must be assessed. The second I do not understand. What other vaccines do we offer off-label?', '@stinuslindgreen @Heunicke In my optics, it is not a relevant concern. Several reasons. Main: First, because we do not have scale to make a difference. IF it gives increased selection in that direction, it happens no matter what we do. Second, we do not neglect other vaccines on that basis.', \"@RasmusMalver @radical I'm sorry. I want to understand your concern - that's why I answer you - but unfortunately I have a little difficulty following your reasoning. It sounds like we're talking past each other. Maybe it's Twitter? I don't know, but I always want to have a serious dialogue.\", \"@larskohler @BEsbensen @PiaOlsen A little, but I would really like to understand your criticism!:) We don't hit broad enough do you write how?\", '@gastronautdk @peterbrothersen We probably just perceive the debate differently. I just think you underline my point, even though that is hardly your intention', \"@quitte74 @BrondbyIF Should I bring yours when I'm down there? I respect you disagree with me. But not your tone. It's unnecessary.\", '@JanniMT @BrondbyIF Please turn yourself down and pick up your suck, please.', '@HenrikDyhHansen @dksvin @KopenhagenFurDK @spisekammeren @MFVMin @MogensJensenS Hmm, now our views on the justification of the industry are different. For me, this corresponds to compensation for running a slave farm. My view of ethics is not yet supported by the current system, I am well aware of that, but it is difficult for me to understand the attitudes towards animals.', \"@KWEkristian Ah, that's a rather thin answer when you have started the debate yourself - as you know, we have a board meeting, so I don't think there will be much regional participation in the first part of your meeting. @SigneLoentoft\", \"@Knud_brix @mortenskaerbaek Serious journalism, agree. The claim is just crazy, as it is a claim. Among too many others. Well, the infantile behavior is challenged. But let's bear it out. Have read that she likes Brøndby.\", '@EsbenSuurballe @ChrLundHansen @ClarkJamesYNWA @larsmathiasen Hehe you describe the difference between us perfectly. I will not add anything', \"@AllonHSorensen @AnAngelOfDeath I sincerely didn't understand what your attitude is if it wasn't just that measles infection according to you gives some even quite large potential benefits. Is that wrong?\", \"@AnAnAngelOfDeath I felt that I was being imposed on some attitudes I didn't have at all, and that's almost what makes me most sad. But then I learned that's how the machine works when the press and other parties smell blood. I want to thank people who kept a factual tone along the way.\", '@anneloppe @Kmoztar It certainly expects it, but that part you decide after all.:D I hope your neighbor is cat-knowing enough not to be against you about it?', \"@HorvatPedersen @twhjerne Seems in return it sounds great that it affects your behavior as a friend. But again, too bad if it is driven by an unhealthy basic feeling. I don't know. Impossible talk we've initiated here;-)\", '@RolfBjerre @alternative_@uffeelbaek Would you like to refer me to research that supports your statements? As long as I do not see any concrete research that agrees with you, I feel it is a debate between my sources, and your gut feeling. This should not be taken as an attack, but rather as a desire to know more', '@JonasKGaba @alternative_@uffeelbaek Of the 7 assertions, I would say that 5 and 6 are wrong claims 100%, but the other 5 have something (sometimes very little) truth in them. Ask me sharply •', \"@valglaks @CasparDyb You buy Madrid the President's story. Fair enough. It doesn't change for me anything compared to what I've written. Rather, on the contrary. Because it deliberately reduces football fans to simple consumers where truth should be another. The truth is then just slowly boiled away.\"]\n",
      "no counterarguments:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"@frkomo I guess I'm saying it strictly just to those who follow me;) But if you follow the subsequent discussion, then I'm just not impressed by the approach the players have:)\",\n",
       " '@MonbergSF Tell it to the gaming association, which is just fighting for DBU to have employer responsibility. Both with the gentlemen and the ladies',\n",
       " \"Until an hour ago, @stinuslindgreen was on my top 5 over members of parliament. He is new in politics, but has really learned to bullshit. @Radio claimed that there was court control with access to private homes. There isn't. See how he tries to change direction. #dkpol https://t.co/37odfP9Y3O\",\n",
       " \"@ThomasMonbergSF I think we're running in a circle!... Have a good day and a go Pride!! • @BEsbensen @PiaOlsen\",\n",
       " '@peterbrothersen Exactly... So thin post from @AnneFrostJepsen... \"Don\\'t beat the politicians even if they beat on a daily basis\" Adult communication requires a desire from the politicians to act adultly and we still need to see',\n",
       " '@HellaSchulin @dksvin @KopenhagenFurDK @disekammeren @MfVMin @MogensJensenS Well, I understand your opinions in the area qua your attachment. And that is absolutely fair enough. But democratically adopted laws should not be followed if we \"just feel\" something else? Is d the kind of politician you want to be if you get a mandate? (Both written with respect)',\n",
       " \"@adamwolfregion @SigneLoentoft I didn't know that, what I'm saying is just that quite important topic for that type of twitter dispute. Isn't the direct way to more coherence/cooperation either. And the answer to your question we've long since given?\",\n",
       " 'When @mortenskaerbaek is in top shape, it is far from the sock holders. There should just be sound at this interview https://t.co/yHk4vB74m9',\n",
       " \"@Nikolaj32LFC @EsbenSuurballe @ClarkJamesYNWA @larsmathiasen It sums everything up well. Just call us old angry men, I'll call it due diligence. Hope sincerely, you're right, but I would call our sporting management outright naive if they plan on such hopes. There's too much likelihood of it going wrong.\",\n",
       " \"@PruPruPruh @Kmoztar Haha, you've been catted. • It's also all right that it comes here and hangs out. As long as it doesn't move in and expects cat tray and wet broom.\",\n",
       " \"@HorvatPedersen @twhjerne Ha ha. Don't apologize. Cool when people want to share their emotional lives. Know what you mean. But you also have to stop and take a little critical of the performance urge... especially in terms of career. Because is it really good to take those hours extra?\",\n",
       " '@larsloekke Enig. Let us never forget. But that is not enough, Lars. You must both as prime minister and as prime minister candidate make it clear that a party with precisely Nazi ideology can never become parliamentary basis for your government. We as a country need the announcement from your side #dkpol',\n",
       " \"And cities blossomed in red and white, and it was spring and Denmark free... Let's never forget... https://t.co/m2IU5wJztL\",\n",
       " '@KHegaard How will you ever achieve a fair and fair definition of the acceptable to say in society if you decide in advance that something is wrong to say? Do you really claim that you know that some statements are completely crazy without hearing them?',\n",
       " 'New C-leader Søren Pape has been allied with S/SF in Viborg since 2010. New line? Or just emphasis on the post rather than the policy..? #dkmedier',\n",
       " \"@KFrydensbjerg @Mikkelnw @laianders @LKarstenberg I think it's a long time before we can't use a player like him. But when that's said, I don't know much about his skills, i.e. besides the wildness - and as mentioned, I love those types.\",\n",
       " '@FCKBuzz @football major I completely agree. We can do much better. Good with your son:)',\n",
       " \"@quitte74 @football major It makes me fucking happy to hear. My son is a good place now. It's just so sad that it should take so many years, especially when you've found out that this is happening systematically because of savings considerations in the municipalities. We can't be familiar with our kids.\",\n",
       " 'The good @OleRyborg says it best: Consider it a gl.Day Sunday Berlinger, where you are not forced to read it all, but can browse, rewind, skip and tap as needed. That being said, feedback is always appreciated. We never get better without it. Thank you!',\n",
       " \"And yes, in the week's broadcast CL and VAR will also fill, because it is clearly the feeling that it also fills the canteen, the studio, the changing room etc. We do not have the formats to make REVIEW of the midweek events, but we try to get it in as a natural part.\"]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at performance\n",
    "\n",
    "#pull up text examples\n",
    "Counterargument = pairs_small[pairs_small['coun_classifier_label_model1'] == 'Counterargument']\n",
    "no_Counterargument = pairs_small[pairs_small['coun_classifier_label_model1'] == 'Not Counterargument']\n",
    "\n",
    "# can print the whole text using\n",
    "print('counterarguments:')\n",
    "text_to_print_1 = Counterargument['translated'].head(20).tolist()\n",
    "print(text_to_print_1)\n",
    "\n",
    "print('no counterarguments:')\n",
    "text_to_print_2 = no_Counterargument['translated'].head(20).tolist()\n",
    "text_to_print_2\n",
    "\n",
    "# Seems to work actually really good on the english tranlated text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "016aa23e-ff6c-4d15-817b-ddd198a0ccf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@mbulskov @vesterby @tveskov @R4nd4hl On the other hand, we have retained the foolish etats structure unchanged since Evevælden, including the idea that a minister cannot fire an idiotic department chief. And two or three people in a Danish party decide who we can vote for. So we are actually worse off as Danes, right?',\n",
       " '@baretraet @PabloBresciani One might take the view that just this year you may not have missed so much...',\n",
       " \"@Larsnoe @KraulDR Is that wrong? You may very much disagree with me. I just don't understand your criticism?\",\n",
       " \"@PruPruPruh You may be right about that. I see so much every day so I'll be happy when I meet a good person\",\n",
       " 'On the contrary @ACHorsensGULE has played some of the most entertaining games this year, along with #FCN and #BIF. Always garbage on. #AAB, #OB and #SIF have in turn been boring. #sldk #achsje https://t.co/jju6WVT9Vg',\n",
       " \"@mollerjensen @Vestergaard_KB You may be right, my point is as long as she had actually thought the idea and we shouldn't hang anyone out for half stories •\",\n",
       " \"@SimonEmilAmmitz Completely disagree. Then they wouldn't have gotten the attention that it takes when we have #dkpol who doesn't always listen to the population.\",\n",
       " \"@Lemberg @TheDorteOlsen @R4nd4hl @PSkipperEL @ChristinaEgelun I honestly don't think that it will be healthy for a collaboration. Not if you mean more demands ala what we have made with the cash aid ceiling. I myself am in some way inclined to do so, but I don't think it will be profitable. Clear framework in relation to the direction on the other hand.\",\n",
       " '@nielsallesoe @Heunicke Your first objection may be correct. It must be assessed. The second I do not understand. What other vaccines do we offer off-label?',\n",
       " '@baretraet It may just be that they are saved to the league • knowing that EL2 is the bottom of the seventeenth power...',\n",
       " '@alfe_j @BosseStine @regulateDK (May just elaborate for my own sake: So, unfortunately, we will not agree because I assume that you will have tax relief instead of free language show that can benefit everyone. Of course, priority must be given to the resources we have. Solidarity suits everyone.)',\n",
       " \"It's wild - people don't infect each other with #COVID19dk if we keep one meter distance. Mink, on the other hand, according to the government can infect up to 7.8 km away - and therefore a lot of healthy mink must now be killed - the owners get only 20% of the loss replaced. @KopenhagenFurDK #dkpol\",\n",
       " '@Qualgeisten @cekicozlem @ClaesAmundsen you may think so, but your lack of acceptance does not prevent the right-wing - that is the reality.',\n",
       " \"@fiwa Probably not. Of course you can't judge that yourself, others might say otherwise, but I'm inclined to believe you\",\n",
       " '@NazilaKivi You may think so. But the fact is that extremist violence can occur on both left and right sides. And if the situation escalates it is unfortunately an option. And probably the situation Paludan is working towards. Which of course makes them protest against him, his tools.',\n",
       " \"@PruPruPruh How cool - I live about 20 minutes from Roskilde, so it wouldn't be completely unrealistic. And it may well be that I keep you up on your offer - your things look really exciting\",\n",
       " \"@Cpatmanias I never actually fight with anyone on Twitter and we may argue a little - I don't think we disagree - I just got a little bit puffed over your answer and misunderstood it more than intended - so I guess that's what SoMe is quite often. Let's deal we haven't quarreled Good weekend •\",\n",
       " \"@MrDanielPoulsen I'm not so fond of that culture. There are so many people on this platform who are fucking other people's work. But it may be that I make an exception when the money's back on my account •\",\n",
       " \"@kasperpeders I think so, and maybe I'm reading your analysis wrong. My point may also be a bit to the philosophical side. When you stress quality in a close fight, it's self. correct, but it's at the same time an attempt to make sense in something that may not have any greater meaning.\",\n",
       " '@MagnusPharao @politiken I completely disagree with that - the moralists do not win this case. That is exactly what election after election shows.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by 'score' in descending order\n",
    "sorted_df = Counterargument.sort_values('coun_classifier_score_model1', ascending=False)\n",
    "\n",
    "#print \n",
    "sorted_df['translated'].head(20).tolist()\n",
    "\n",
    "# it's very obvious that lines like: 'On the other hand', 'One might take the view', 'You may very much disagree with me','in turn','You may be right, my point is','Your first objection may be correct', etc. gives high scores  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bc1c96-dd20-4118-bba8-79a6ce1edb46",
   "metadata": {},
   "source": [
    "#### Bert counterspeech classifier (from huggingface)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1efc216-4bc8-477c-adf7-d37d756af0f8",
   "metadata": {},
   "source": [
    "Bert finetuned on the CONAN dataset\n",
    "\n",
    "https://huggingface.co/tum-nlp/bert-counterspeech-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95b7641a-5898-4ead-b4bf-80446c9dc7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_4 = pipeline(\"text-classification\", model=\"tum-nlp/bert-counterspeech-classifier\",device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b39c35d9-cc2c-47ed-8ed1-7e28a757290b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'counter-argument', 'score': 0.9996057152748108}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I understand, but actually you are incorrect. Science show that the earth is round\"\n",
    "text_2 = \"Jeg forstår din pointe, men den er ikke korrekt. Videnskaben viser at jorden er rund\"\n",
    "text_3 = \"you are a fool\"\n",
    "\n",
    "# Apply the pipeline to the text\n",
    "result = pipe_4(text)\n",
    "result\n",
    "\n",
    "#Seems to work well on english data, not so good on danish data.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24030e52-c6b5-4d7b-9b2b-d3844bcb7ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting scores: 100%|████████████████████| 2000/2000 [03:53<00:00,  8.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>replied_to_reply_count</th>\n",
       "      <th>referenced_tweets_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>PNR</th>\n",
       "      <th>...</th>\n",
       "      <th>ZS_hate_score_dan</th>\n",
       "      <th>ZS_neutral_score_dan</th>\n",
       "      <th>ZS_counterspeech_dan</th>\n",
       "      <th>ZS_counterspeech_score_new_labels</th>\n",
       "      <th>ZS_no_counterspeech_score_new_labels</th>\n",
       "      <th>ZS_counterspeech_new_labels</th>\n",
       "      <th>coun_classifier_label_model1</th>\n",
       "      <th>coun_classifier_score_model1</th>\n",
       "      <th>coun_classifier_label_model2</th>\n",
       "      <th>coun_classifier_score_model2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1036583587242549248</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-09-03 21:04:41</td>\n",
       "      <td>1036721666628444160</td>\n",
       "      <td>@frkomo Jeg siger det vel strengt taget bare t...</td>\n",
       "      <td>1666088336</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1036721302692917250</td>\n",
       "      <td>148061237</td>\n",
       "      <td>1311570613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008536</td>\n",
       "      <td>0.226088</td>\n",
       "      <td>no</td>\n",
       "      <td>0.926184</td>\n",
       "      <td>0.073816</td>\n",
       "      <td>yes</td>\n",
       "      <td>Not Counterargument</td>\n",
       "      <td>0.712887</td>\n",
       "      <td>counter-argument</td>\n",
       "      <td>0.999477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1036583587242549248</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-09-03 21:03:14</td>\n",
       "      <td>1036721302692917250</td>\n",
       "      <td>@MonbergSF Sig det til spillerforeningen, som ...</td>\n",
       "      <td>148061237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1666088336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006963</td>\n",
       "      <td>0.139833</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.976817</td>\n",
       "      <td>0.023183</td>\n",
       "      <td>yes</td>\n",
       "      <td>Not Counterargument</td>\n",
       "      <td>0.979896</td>\n",
       "      <td>non-counter-argument</td>\n",
       "      <td>0.962320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>899548260863488002</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-08-21 12:10:42</td>\n",
       "      <td>899604671375052801</td>\n",
       "      <td>@PeterHuggler Had alt det, du vil. Men du skal...</td>\n",
       "      <td>547416021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>899603561323081729</td>\n",
       "      <td>3301029597</td>\n",
       "      <td>1405772015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030307</td>\n",
       "      <td>0.394142</td>\n",
       "      <td>no</td>\n",
       "      <td>0.852871</td>\n",
       "      <td>0.147129</td>\n",
       "      <td>yes</td>\n",
       "      <td>Counterargument</td>\n",
       "      <td>0.686435</td>\n",
       "      <td>counter-argument</td>\n",
       "      <td>0.999193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>899548260863488002</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-08-21 12:06:17</td>\n",
       "      <td>899603561323081729</td>\n",
       "      <td>@brianweichardt Jeg hader den her slags: Du gå...</td>\n",
       "      <td>3301029597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>547416021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>0.368008</td>\n",
       "      <td>no</td>\n",
       "      <td>0.911839</td>\n",
       "      <td>0.088161</td>\n",
       "      <td>yes</td>\n",
       "      <td>Counterargument</td>\n",
       "      <td>0.825158</td>\n",
       "      <td>counter-argument</td>\n",
       "      <td>0.720713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1345496479583113217</td>\n",
       "      <td>da</td>\n",
       "      <td>2021-01-03 12:38:16</td>\n",
       "      <td>1345711074407014400</td>\n",
       "      <td>@nielscallesoe @Heunicke Din første indvending...</td>\n",
       "      <td>87923613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1345524516311748608</td>\n",
       "      <td>23341699</td>\n",
       "      <td>0908801199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017978</td>\n",
       "      <td>0.166937</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.962703</td>\n",
       "      <td>0.037297</td>\n",
       "      <td>yes</td>\n",
       "      <td>Counterargument</td>\n",
       "      <td>0.995546</td>\n",
       "      <td>counter-argument</td>\n",
       "      <td>0.999616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1285495153202024448</td>\n",
       "      <td>da</td>\n",
       "      <td>2020-07-21 10:22:06</td>\n",
       "      <td>1285520419529863168</td>\n",
       "      <td>@SimonStoerup @perlysholt Hm. Man ville som ud...</td>\n",
       "      <td>27626050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>383396359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019735</td>\n",
       "      <td>0.210252</td>\n",
       "      <td>no</td>\n",
       "      <td>0.790419</td>\n",
       "      <td>0.209581</td>\n",
       "      <td>no</td>\n",
       "      <td>Counterargument</td>\n",
       "      <td>0.851246</td>\n",
       "      <td>counter-argument</td>\n",
       "      <td>0.998487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>da</td>\n",
       "      <td>2019-09-18 19:10:18</td>\n",
       "      <td>1174400270710820870</td>\n",
       "      <td>@R4nd4hl @khoenge Sjovt du synes netop Hønge b...</td>\n",
       "      <td>861057936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>72823792</td>\n",
       "      <td>1508892043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142903</td>\n",
       "      <td>0.097587</td>\n",
       "      <td>no</td>\n",
       "      <td>0.938951</td>\n",
       "      <td>0.061049</td>\n",
       "      <td>yes</td>\n",
       "      <td>Not Counterargument</td>\n",
       "      <td>0.564339</td>\n",
       "      <td>counter-argument</td>\n",
       "      <td>0.995113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>da</td>\n",
       "      <td>2019-09-18 18:50:58</td>\n",
       "      <td>1174395406719102976</td>\n",
       "      <td>Detektor har undersøgt det: @khoenge talte usa...</td>\n",
       "      <td>72823792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126598</td>\n",
       "      <td>0.219282</td>\n",
       "      <td>no</td>\n",
       "      <td>0.964718</td>\n",
       "      <td>0.035282</td>\n",
       "      <td>yes</td>\n",
       "      <td>Not Counterargument</td>\n",
       "      <td>0.975029</td>\n",
       "      <td>counter-argument</td>\n",
       "      <td>0.960987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1481298462238982144</td>\n",
       "      <td>da</td>\n",
       "      <td>2022-01-12 19:25:54</td>\n",
       "      <td>1481346717513662464</td>\n",
       "      <td>@ReneAndersenDK Forskellen er, at ham her også...</td>\n",
       "      <td>805874425988087811</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1481345545721495554</td>\n",
       "      <td>4776986009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019431</td>\n",
       "      <td>0.267258</td>\n",
       "      <td>no</td>\n",
       "      <td>0.935881</td>\n",
       "      <td>0.064119</td>\n",
       "      <td>yes</td>\n",
       "      <td>Counterargument</td>\n",
       "      <td>0.767544</td>\n",
       "      <td>counter-argument</td>\n",
       "      <td>0.699459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1481298462238982144</td>\n",
       "      <td>da</td>\n",
       "      <td>2022-01-12 19:21:14</td>\n",
       "      <td>1481345545721495554</td>\n",
       "      <td>@baretraet Sådan et mål har vi sgu da alle sam...</td>\n",
       "      <td>4776986009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>805874425988087811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055234</td>\n",
       "      <td>0.093079</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.972140</td>\n",
       "      <td>0.027860</td>\n",
       "      <td>yes</td>\n",
       "      <td>Not Counterargument</td>\n",
       "      <td>0.661699</td>\n",
       "      <td>counter-argument</td>\n",
       "      <td>0.984968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          conversation_id lang           created_at                   id  \\\n",
       "0     1036583587242549248   da  2018-09-03 21:04:41  1036721666628444160   \n",
       "1     1036583587242549248   da  2018-09-03 21:03:14  1036721302692917250   \n",
       "2      899548260863488002   da  2017-08-21 12:10:42   899604671375052801   \n",
       "3      899548260863488002   da  2017-08-21 12:06:17   899603561323081729   \n",
       "4     1345496479583113217   da  2021-01-03 12:38:16  1345711074407014400   \n",
       "...                   ...  ...                  ...                  ...   \n",
       "1995  1285495153202024448   da  2020-07-21 10:22:06  1285520419529863168   \n",
       "1996  1174395406719102976   da  2019-09-18 19:10:18  1174400270710820870   \n",
       "1997  1174395406719102976   da  2019-09-18 18:50:58  1174395406719102976   \n",
       "1998  1481298462238982144   da  2022-01-12 19:25:54  1481346717513662464   \n",
       "1999  1481298462238982144   da  2022-01-12 19:21:14  1481345545721495554   \n",
       "\n",
       "                                                   text           author_id  \\\n",
       "0     @frkomo Jeg siger det vel strengt taget bare t...          1666088336   \n",
       "1     @MonbergSF Sig det til spillerforeningen, som ...           148061237   \n",
       "2     @PeterHuggler Had alt det, du vil. Men du skal...           547416021   \n",
       "3     @brianweichardt Jeg hader den her slags: Du gå...          3301029597   \n",
       "4     @nielscallesoe @Heunicke Din første indvending...            87923613   \n",
       "...                                                 ...                 ...   \n",
       "1995  @SimonStoerup @perlysholt Hm. Man ville som ud...            27626050   \n",
       "1996  @R4nd4hl @khoenge Sjovt du synes netop Hønge b...           861057936   \n",
       "1997  Detektor har undersøgt det: @khoenge talte usa...            72823792   \n",
       "1998  @ReneAndersenDK Forskellen er, at ham her også...  805874425988087811   \n",
       "1999  @baretraet Sådan et mål har vi sgu da alle sam...          4776986009   \n",
       "\n",
       "      replied_to_reply_count referenced_tweets_id in_reply_to_user_id  \\\n",
       "0                        1.0  1036721302692917250           148061237   \n",
       "1                        NaN                  NaN          1666088336   \n",
       "2                        1.0   899603561323081729          3301029597   \n",
       "3                        NaN                  NaN           547416021   \n",
       "4                        1.0  1345524516311748608            23341699   \n",
       "...                      ...                  ...                 ...   \n",
       "1995                     NaN                  NaN           383396359   \n",
       "1996                     0.0  1174395406719102976            72823792   \n",
       "1997                     NaN                  NaN                 NaN   \n",
       "1998                     1.0  1481345545721495554          4776986009   \n",
       "1999                     NaN                  NaN  805874425988087811   \n",
       "\n",
       "             PNR  ... ZS_hate_score_dan  ZS_neutral_score_dan  \\\n",
       "0     1311570613  ...          0.008536              0.226088   \n",
       "1            NaN  ...          0.006963              0.139833   \n",
       "2     1405772015  ...          0.030307              0.394142   \n",
       "3            NaN  ...          0.015232              0.368008   \n",
       "4     0908801199  ...          0.017978              0.166937   \n",
       "...          ...  ...               ...                   ...   \n",
       "1995         NaN  ...          0.019735              0.210252   \n",
       "1996  1508892043  ...          0.142903              0.097587   \n",
       "1997         NaN  ...          0.126598              0.219282   \n",
       "1998         NaN  ...          0.019431              0.267258   \n",
       "1999         NaN  ...          0.055234              0.093079   \n",
       "\n",
       "      ZS_counterspeech_dan  ZS_counterspeech_score_new_labels  \\\n",
       "0                       no                           0.926184   \n",
       "1                      yes                           0.976817   \n",
       "2                       no                           0.852871   \n",
       "3                       no                           0.911839   \n",
       "4                      yes                           0.962703   \n",
       "...                    ...                                ...   \n",
       "1995                    no                           0.790419   \n",
       "1996                    no                           0.938951   \n",
       "1997                    no                           0.964718   \n",
       "1998                    no                           0.935881   \n",
       "1999                   yes                           0.972140   \n",
       "\n",
       "      ZS_no_counterspeech_score_new_labels ZS_counterspeech_new_labels  \\\n",
       "0                                 0.073816                         yes   \n",
       "1                                 0.023183                         yes   \n",
       "2                                 0.147129                         yes   \n",
       "3                                 0.088161                         yes   \n",
       "4                                 0.037297                         yes   \n",
       "...                                    ...                         ...   \n",
       "1995                              0.209581                          no   \n",
       "1996                              0.061049                         yes   \n",
       "1997                              0.035282                         yes   \n",
       "1998                              0.064119                         yes   \n",
       "1999                              0.027860                         yes   \n",
       "\n",
       "      coun_classifier_label_model1  coun_classifier_score_model1  \\\n",
       "0              Not Counterargument                      0.712887   \n",
       "1              Not Counterargument                      0.979896   \n",
       "2                  Counterargument                      0.686435   \n",
       "3                  Counterargument                      0.825158   \n",
       "4                  Counterargument                      0.995546   \n",
       "...                            ...                           ...   \n",
       "1995               Counterargument                      0.851246   \n",
       "1996           Not Counterargument                      0.564339   \n",
       "1997           Not Counterargument                      0.975029   \n",
       "1998               Counterargument                      0.767544   \n",
       "1999           Not Counterargument                      0.661699   \n",
       "\n",
       "     coun_classifier_label_model2 coun_classifier_score_model2  \n",
       "0                counter-argument                     0.999477  \n",
       "1            non-counter-argument                     0.962320  \n",
       "2                counter-argument                     0.999193  \n",
       "3                counter-argument                     0.720713  \n",
       "4                counter-argument                     0.999616  \n",
       "...                           ...                          ...  \n",
       "1995             counter-argument                     0.998487  \n",
       "1996             counter-argument                     0.995113  \n",
       "1997             counter-argument                     0.960987  \n",
       "1998             counter-argument                     0.699459  \n",
       "1999             counter-argument                     0.984968  \n",
       "\n",
       "[2000 rows x 41 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on small df (translated)\n",
    "\n",
    "# List to store the scores\n",
    "labels = []\n",
    "scores = []\n",
    "\n",
    "# Iterate over each text\n",
    "for text in (tqdm(pairs_small['translated'], desc= \"Extracting scores\")) :\n",
    "    result = pipe_4(text)\n",
    "    # Extract the scores\n",
    "    label = result[0]['label']\n",
    "    score = result[0]['score']\n",
    "    # Append the scores to the lists\n",
    "    labels.append(label)\n",
    "    scores.append(score)\n",
    "\n",
    "# Add the scores as a new column in the DataFrame\n",
    "pairs_small['coun_classifier_label_model2'] = labels\n",
    "pairs_small['coun_classifier_score_model2'] = scores\n",
    "\n",
    "pairs_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b632b1cb-e739-4a1c-b1e5-d587e4ad1087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coun_classifier_label_model2\n",
       "counter-argument        1822\n",
       "non-counter-argument     178\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check value counts\n",
    "pairs_small['coun_classifier_label_model2'].value_counts(dropna=False) \n",
    "\n",
    "#more generous in assigning counter-argument than the first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a2ebd29-db89-45d8-bdbc-6f1cbb7d0044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counterarguments:\n",
      "[\"@frkomo I guess I'm saying it strictly just to those who follow me;) But if you follow the subsequent discussion, then I'm just not impressed by the approach the players have:)\", \"@PeterHuggler Had everything you want. But don't judge what I think is a natural reaction. I'm not covering that case at all.\", '@brianweichardt I hate this kind of thing: You go in and make yourself a judge, based on a photo. Let the court do its job, and seek only to communicate the case.', '@nielsallesoe @Heunicke Your first objection may be correct. It must be assessed. The second I do not understand. What other vaccines do we offer off-label?', '@stinuslindgreen @Heunicke In my optics, it is not a relevant concern. Several reasons. Main: First, because we do not have scale to make a difference. IF it gives increased selection in that direction, it happens no matter what we do. Second, we do not neglect other vaccines on that basis.', \"@RasmusMalver @radical I'm sorry. I want to understand your concern - that's why I answer you - but unfortunately I have a little difficulty following your reasoning. It sounds like we're talking past each other. Maybe it's Twitter? I don't know, but I always want to have a serious dialogue.\", \"Until an hour ago, @stinuslindgreen was on my top 5 over members of parliament. He is new in politics, but has really learned to bullshit. @Radio claimed that there was court control with access to private homes. There isn't. See how he tries to change direction. #dkpol https://t.co/37odfP9Y3O\", \"@larskohler @BEsbensen @PiaOlsen A little, but I would really like to understand your criticism!:) We don't hit broad enough do you write how?\", \"@ThomasMonbergSF I think we're running in a circle!... Have a good day and a go Pride!! • @BEsbensen @PiaOlsen\", '@gastronautdk @peterbrothersen We probably just perceive the debate differently. I just think you underline my point, even though that is hardly your intention', '@peterbrothersen Exactly... So thin post from @AnneFrostJepsen... \"Don\\'t beat the politicians even if they beat on a daily basis\" Adult communication requires a desire from the politicians to act adultly and we still need to see', \"@quitte74 @BrondbyIF Should I bring yours when I'm down there? I respect you disagree with me. But not your tone. It's unnecessary.\", '@JanniMT @BrondbyIF Please turn yourself down and pick up your suck, please.', '@HellaSchulin @dksvin @KopenhagenFurDK @disekammeren @MfVMin @MogensJensenS Well, I understand your opinions in the area qua your attachment. And that is absolutely fair enough. But democratically adopted laws should not be followed if we \"just feel\" something else? Is d the kind of politician you want to be if you get a mandate? (Both written with respect)', '@HenrikDyhHansen @dksvin @KopenhagenFurDK @spisekammeren @MFVMin @MogensJensenS Hmm, now our views on the justification of the industry are different. For me, this corresponds to compensation for running a slave farm. My view of ethics is not yet supported by the current system, I am well aware of that, but it is difficult for me to understand the attitudes towards animals.', \"@adamwolfregion @SigneLoentoft I didn't know that, what I'm saying is just that quite important topic for that type of twitter dispute. Isn't the direct way to more coherence/cooperation either. And the answer to your question we've long since given?\", \"@KWEkristian Ah, that's a rather thin answer when you have started the debate yourself - as you know, we have a board meeting, so I don't think there will be much regional participation in the first part of your meeting. @SigneLoentoft\", \"@Knud_brix @mortenskaerbaek Serious journalism, agree. The claim is just crazy, as it is a claim. Among too many others. Well, the infantile behavior is challenged. But let's bear it out. Have read that she likes Brøndby.\", 'When @mortenskaerbaek is in top shape, it is far from the sock holders. There should just be sound at this interview https://t.co/yHk4vB74m9', \"@Nikolaj32LFC @EsbenSuurballe @ClarkJamesYNWA @larsmathiasen It sums everything up well. Just call us old angry men, I'll call it due diligence. Hope sincerely, you're right, but I would call our sporting management outright naive if they plan on such hopes. There's too much likelihood of it going wrong.\"]\n",
      "no counterarguments:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['@MonbergSF Tell it to the gaming association, which is just fighting for DBU to have employer responsibility. Both with the gentlemen and the ladies',\n",
       " '@MonbergSF @CasparDyb Some of them cheered over ESL and they will probably also prefer an English league with 10-12 teams 2/2',\n",
       " '@larsloekke Enig. Let us never forget. But that is not enough, Lars. You must both as prime minister and as prime minister candidate make it clear that a party with precisely Nazi ideology can never become parliamentary basis for your government. We as a country need the announcement from your side #dkpol',\n",
       " \"@quitte74 @football major It makes me fucking happy to hear. My son is a good place now. It's just so sad that it should take so many years, especially when you've found out that this is happening systematically because of savings considerations in the municipalities. We can't be familiar with our kids.\",\n",
       " 'Too bad to be you, young man who lost in the lottery and therefore has to go to a skedgymnasium far from your residence and your friends. Unfortunately, you are just one of the eggs we have to smash in order to make the Social Democratic Omelette.',\n",
       " 'Just to get it right, we should get to the Tivoli game for Europe through 7th place, I hope we lose it!',\n",
       " 'Hey, I just caught Jens Hjortskov. The Disciplinary Board is looking at Santander: https://t.co/OxEYhGMHtR',\n",
       " \"@Monica36671619 Why should we absolutely be part of a community that accepts the xenophobic and homophobic priests. As well as all the male priests who won't shake hands with female priests. Personally, I resigned because I'm not a Christian.\",\n",
       " 'But fuck it! #metoo https://t.co/SPYtjrQW6H',\n",
       " \"I've never tasted sushi, have I missed anything?\",\n",
       " \"Left makes a mistake if they choose Løjberg. Danes, but also parts of the Left's hinterland are tired of her hard rhetoric and cake celebrations #besserwissians\",\n",
       " '1/3 Ten years ago, no one would have believed that the next great cultural struggle would not be against the Islamists who would turn the West, but against privileged and spoiled young women and their allies in our midst.',\n",
       " \"@BoKarlChrist @LiseMarieA @hohwy You can't be familiar @BoKarlChrist! I loved grilled octopus arms at Mastro - now I can never eat them again..... And it's all your fault!\",\n",
       " 'Despite the fall, I sit and think: Every five 11-year-old boy has been drinking • They are children. There is a need for a change in culture and it starts with us. • You must be responsible for yourself - not your daughter • as @SSTbrostrom has just said to the chairman.',\n",
       " '@mbulskov @DRNyheder Ok, so: - Putin helped Trump. - Trump accepted the help. - The Mueller study with 500 searches missed it. - But now it\\'s still \"stripped.\" - No one is punished because Trump won. All while the FBI attorney confesses to falsifying evidence to spy on Trump.',\n",
       " 'All of you who mock parents for their curling children: I think that you are the types that keep mocking others alive. If children are brought up with mockery, ridicule and intolerance, that is how they behave as adults. Curling children as adults I have more scam for. And pineapple on pizza is ok..',\n",
       " \"@pferdinandsen @HCB Magic @LarsRonbog Enig. He just hasn't shown it with us. And when the other one makes it significantly better when he gets the chance, that's how it goes.\",\n",
       " 'I have a text in English that I want a native-speaking to read up and record as an MP3. Where do I find the right person?',\n",
       " 'Cancer medicine is becoming more expensive and expensive. #sundpol https://t.co/0joCh7rqm2',\n",
       " '@enriksen78 @MortenFrederik6 I miss adults, preferably with an IQ of over 14, who take some responsibility now. It hurts the club that the fan chairman stands and takes them in defense.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at performance\n",
    "\n",
    "#pull up text examples\n",
    "Counterargument = pairs_small[pairs_small['coun_classifier_label_model2'] == 'counter-argument']\n",
    "no_Counterargument = pairs_small[pairs_small['coun_classifier_label_model2'] == 'non-counter-argument']\n",
    "\n",
    "# can print the whole text using\n",
    "print('counterarguments:')\n",
    "text_to_print_1 = Counterargument['translated'].head(20).tolist()\n",
    "print(text_to_print_1)\n",
    "\n",
    "print('no counterarguments:')\n",
    "text_to_print_2 = no_Counterargument['translated'].head(20).tolist()\n",
    "text_to_print_2\n",
    "\n",
    "# Seems to also work actually really good on the english tranlated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ed2e03a-c1a5-4731-83b0-0bfed5d68aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"@fiwa Probably not. Of course you can't judge that yourself, others might say otherwise, but I'm inclined to believe you\",\n",
       " \"@MMolsted So put a little bit on the tip one can say Brøndby lacks a lucky chance to score on the relatively high chances FCM has opposed the good luck score to score on something that at first wasn't really a chance. Does that make sense? Do I think it appeared from the analysis.\",\n",
       " '@olebirkolessen That was not a point against you. If that is how I regret it. That was certainly not my opinion. It was just to underline your point. That one can continue indefinitely...0',\n",
       " '@Qualgeisten @cekicozlem @ClaesAmundsen you may think so, but your lack of acceptance does not prevent the right-wing - that is the reality.',\n",
       " 'In other words, regardless of whether wage differences between men and women are due to biological preferences, a gender-separated labour market, or otherwise, the difference in pay between men and women is a causal relationship. Not just a correlation. This would be a misunderstanding to spread @lassehmadsen',\n",
       " 'What you write in @Politiken today is not true, @MartinVoergaard •A plant-based diet does not necessarily mean a low emission, as it is also necessary to avoid avocados and the rewards for climate reasons. • https://t.co/vuXa7N5qP1 https://t.co/BYXCHIELyl',\n",
       " 'On the contrary @ACHorsensGULE has played some of the most entertaining games this year, along with #FCN and #BIF. Always garbage on. #AAB, #OB and #SIF have in turn been boring. #sldk #achsje https://t.co/jju6WVT9Vg',\n",
       " '@SebastianPehn Thank you for your comment. As you can guess, I am not entirely in agreement. Based on that logic, all gender differences would be causal.',\n",
       " '@Lindhacker @Kristianthdahl Without fact checking your claim; it happens quite often. And the frequency is not downward. As I read the last graph it supports quite well that we get a lot of our energy from wind. Thus, not saying that we are free of fossil fuels but it goes the right way.',\n",
       " \"@ejrn_s @TokePanduro That's not what I think you hear from the artists, on the contrary. Your point is good, but the analogy doesn't work.\",\n",
       " \"@sebberman The problem? I myself am very divided. Only IF it's only bad results I think it's a bad and as you say a little embarrassing decision. Therefore, I choose to believe there's a little more behind it. And on the other hand, the results have not been there.\",\n",
       " '@ALangballe Interesting feature and important pointer you have. However, I think most people have it with politicians and journalists a bit like used car dealers. You may mean what you say sometimes. But who is it that has the power? Who is it that needs to spin?',\n",
       " \"@Hestefanden My point is that what you mention under 1 as a shared economy is the little man's ability to interest his capital when he doesn't use it himself. 2 is the same just on a large scale. Same-same, you can't say that one is more real sharing economy than the other.\",\n",
       " '@NazilaKivi You may think so. But the fact is that extremist violence can occur on both left and right sides. And if the situation escalates it is unfortunately an option. And probably the situation Paludan is working towards. Which of course makes them protest against him, his tools.',\n",
       " \"I'm sure it's true, but it's also more the idea behind than the real technology that's gonna turn something on in me.\",\n",
       " \"@baltazardyd That's the kind we have wise legal judges to take a position on:-), but understands your point and it's of course not entirely straightforward.\",\n",
       " \"@MortenElsoe @Bibliotricen I don't agree with that, but for the sake of order, it's only food you're referring to? Correct me if I'm wrong, but all the sugar that's being talked about in the thread has been processed and added. No, a small amount isn't shit, but no amount can't do harm?!\",\n",
       " '@MortenRugager @eakloster @Joymogensen Seems your comment clearly shows that it is not you - and priests in general - who have to make that decision. https://t.co/6SPpG3ybMz',\n",
       " \"@arolsting @PaulaLarrain1 I can't find a common thread in your argument. Why mention Danes from the 18th century if there is no correlation with future quota refugees? And what is your evidence to believe that I believe that Denmark is being taken over by strangers and Islamized?\",\n",
       " \"@kasperpeders I think so, and maybe I'm reading your analysis wrong. My point may also be a bit to the philosophical side. When you stress quality in a close fight, it's self. correct, but it's at the same time an attempt to make sense in something that may not have any greater meaning.\"]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by 'score' in descending order\n",
    "sorted_df = Counterargument.sort_values('coun_classifier_score_model2', ascending=False)\n",
    "\n",
    "#print \n",
    "sorted_df['translated'].head(20).tolist()\n",
    "\n",
    "#phrases like 'others might say otherwise', 'opposed', 'That was not a point against you', 'you may think so, but','In other words, regardless of','On the contrary' will give high scorea  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec4c5004-8a9d-4300-9955-b1598959d7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coun_classifier_label_model1\n",
      "counter-argument        1276\n",
      "non-counter-argument     724\n",
      "Name: count, dtype: int64\n",
      "coun_classifier_label_model2\n",
      "counter-argument        1822\n",
      "non-counter-argument     178\n",
      "Name: count, dtype: int64\n",
      "Cohen's Kappa: 0.12821680239235922\n",
      "Simple Agreement: 0.663\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Measure agreement of the 2 models\n",
    "\n",
    "# change labels in coun_classifier_label to be instead 'counter-argument' and 'non-counter-argument' instead of 'Counterargument' and 'Not Counterargument'\n",
    "pairs_small['coun_classifier_label_model1'] = pairs_small['coun_classifier_label_model1'].replace({\n",
    "    'Counterargument': 'counter-argument',\n",
    "    'Not Counterargument': 'non-counter-argument'})\n",
    "\n",
    "print(pairs_small['coun_classifier_label_model1'].value_counts(dropna=False))\n",
    "print(pairs_small['coun_classifier_label_model2'].value_counts(dropna=False))\n",
    "\n",
    "kappa = cohen_kappa_score(pairs_small['coun_classifier_label_model1'], pairs_small['coun_classifier_label_model2'])\n",
    "print(f\"Cohen's Kappa: {kappa}\")\n",
    "\n",
    "agreement = (pairs_small['coun_classifier_label_model1'] == pairs_small['coun_classifier_label_model2']).mean()\n",
    "print(f\"Simple Agreement: {agreement}\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(pairs_small['coun_classifier_label_model1'], pairs_small['coun_classifier_label_model2'],\n",
    "                               labels=['non-counter-argument', 'counter-argument'])\n",
    "\n",
    "# Calculate TP, FP, TN, FN\n",
    "TP = conf_matrix[1, 1]  # True Positives\n",
    "TN = conf_matrix[0, 0]  # True Negatives\n",
    "FP = conf_matrix[0, 1]  # False Positives\n",
    "FN = conf_matrix[1, 0]  # False Negatives\n",
    "\n",
    "# Create a heatmap with additional annotations\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Create heatmap\n",
    "ax = sns.heatmap(conf_matrix, annot=False, fmt='d', cmap='Blues', xticklabels=['non-counter-argument', 'counter-argument'], yticklabels=['non-counter-argument', 'counter-argument'])\n",
    "\n",
    "# Add additional annotations (TP, FP, TN, FN) under the numbers\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        value = conf_matrix[i, j]\n",
    "        if i == 1 and j == 1:\n",
    "            annotation = f'{value}\\nTP: {TP}'\n",
    "        elif i == 0 and j == 1:\n",
    "            annotation = f'{value}\\nFP: {FP}'\n",
    "        elif i == 1 and j == 0:\n",
    "            annotation = f'{value}\\nFN: {FN}'\n",
    "        elif i == 0 and j == 0:\n",
    "            annotation = f'{value}\\nTN: {TN}'\n",
    "        else:\n",
    "            annotation = f'{value}'\n",
    "        ax.text(j + 0.5, i + 0.5, annotation, ha='center', va='center', color='black')\n",
    "\n",
    "# Add labels, title, and display the plot\n",
    "plt.ylabel('Model 1 Label')\n",
    "plt.xlabel('Model 2 Label')\n",
    "plt.title('Confusion Matrix with TP, FP, TN, FN')\n",
    "plt.show()\n",
    "\n",
    "#shows that it is mostly FP thats the problem here: model 1 labeled something as non-counter where model 2 label many of those as counter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1942d0b8-ddbb-4ce3-adea-84268ef2d9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conversation_id                          object\n",
       "lang                                     object\n",
       "created_at                               object\n",
       "id                                       object\n",
       "text                                     object\n",
       "author_id                                object\n",
       "replied_to_reply_count                  float64\n",
       "referenced_tweets_id                     object\n",
       "in_reply_to_user_id                      object\n",
       "PNR                                      object\n",
       "surveyXact_externke                      object\n",
       "non_unique_twitter_author_id            float64\n",
       "started_survey                          float64\n",
       "rec-nition                              float64\n",
       "attack                                  float64\n",
       "A/R                                      object\n",
       "fasttext_cos_sim_hate_sentence          float64\n",
       "fasttext_cos_sim_prosocial_sentence     float64\n",
       "tweeter_username                         object\n",
       "tweeter_name                             object\n",
       "pair_num                                  int64\n",
       "type                                     object\n",
       "like_n                                    int64\n",
       "retweet_n                                 int64\n",
       "quote_n                                   int64\n",
       "translated                               object\n",
       "ZS_counterspeech_score                  float64\n",
       "ZS_hate_score                           float64\n",
       "ZS_neutral_score                        float64\n",
       "ZS_counterspeech                         object\n",
       "ZS_counterspeech_score_dan              float64\n",
       "ZS_hate_score_dan                       float64\n",
       "ZS_neutral_score_dan                    float64\n",
       "ZS_counterspeech_dan                     object\n",
       "ZS_counterspeech_score_new_labels       float64\n",
       "ZS_no_counterspeech_score_new_labels    float64\n",
       "ZS_counterspeech_new_labels              object\n",
       "coun_classifier_label_model1             object\n",
       "coun_classifier_score_model1            float64\n",
       "coun_classifier_label_model2             object\n",
       "coun_classifier_score_model2            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_small.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4237244a-540c-463a-972e-b37dd6da3e0e",
   "metadata": {},
   "source": [
    "## Applying hate classification model(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50b6a99-6187-4378-8b6c-fc8dbca69248",
   "metadata": {},
   "source": [
    "### HateXplain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e88d9e1-4292-4885-b8f7-71a645a18b84",
   "metadata": {},
   "source": [
    "Gives hate, offensive and normal \n",
    "\n",
    "https://huggingface.co/Hate-speech-CNERG/bert-base-uncased-hatexplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3df8650f-08cd-4392-abbf-f4dcb17e8b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "pipe_5 = pipeline(\"text-classification\", model=\"Hate-speech-CNERG/bert-base-uncased-hatexplain\", device= 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f266e10-0f01-4338-88da-ec917c5bda01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'offensive', 'score': 0.6110802292823792}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I understand, but actually you are incorrect. Science show that the earth is round\"\n",
    "text_2 = \"Jeg forstår din pointe, men den er ikke korrekt. Videnskaben viser at jorden er rund\"\n",
    "text_3 = \"you fat jewish nigga, i hate you\"\n",
    "text_4 = 'du er så tyk og grim'\n",
    "\n",
    "# Apply the pipeline to the text\n",
    "result = pipe_5(text_3)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a45538c6-c1c2-459e-8ddd-83fd633c14a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting scores: 100%|████████████████████| 2000/2000 [01:33<00:00, 21.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# Test on small df\n",
    "\n",
    "# List to store the scores\n",
    "labels_hate = []\n",
    "scores_hate = []\n",
    "\n",
    "# Iterate over each text\n",
    "for text in (tqdm(pairs_small['translated'], desc= \"Extracting scores\")) :\n",
    "    result = pipe_5(text)\n",
    "    # Extract the scores\n",
    "    label = result[0]['label']\n",
    "    score = result[0]['score']\n",
    "    # Append the scores to the lists\n",
    "    labels_hate.append(label)\n",
    "    scores_hate.append(score)\n",
    "\n",
    "# Add the scores as a new column in the DataFrame\n",
    "pairs_small['label_hatexplain'] = labels_hate\n",
    "pairs_small['score_hatexplain'] = scores_hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae6ee13d-7055-4efe-be34-43bb9d31fdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: translated, dtype: object)\n",
      "hate:\n",
      "[]\n",
      "offensive:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['@BosseStine @RasmusJarlov Jarlov is quite right. However, politically correct halal radicals are willing to deny the truth.',\n",
       " '@MivJensen @provinsmor @Kong_Kret My family uses it intensively. I have told them that if they want me something important, then it is called messenger. Snapchat is the worst scum app ever, I can almost burn together over the shit •',\n",
       " '@Dittemedmening It\\'s not \"to talk to racists\" who have right-turned the community. It\\'s the racists who have done it. Because they want to be heard. And besides, I don\\'t do that shit with \"we who stand up to racism\" I fucking do that too, even though I might do it differently than you do',\n",
       " '@lauravilsbaek I simply think it\\'s part of the gamer culture. I can read elsewhere that it\\'s nothing new. Discover it to football or wherever else they go - fortunately. But \"fucking creepy faggot\", \"suck my... your whore\" etc. - then I see red.',\n",
       " '@HoghSorensen @Wirlander @Cihat_Bardak @a_esbech @DanskDf1995 Learn a new word? I do not claim I am educated in the United States! I do not claim anything contrary to established research! It is you Erik. Do you have documentation that supports your claims? You are the one who projects your mistakes onto ALL others, as many racists do.',\n",
       " '@tHOMSEEEE @mortennHS @hoeirupCSGO @CS_Freeze I have nothing against a scumbag, but what I thought was a little out of line. Hopefully not the mentality in general is that one should just accept when one goes personally against a:) But I can see it from your perspective:)',\n",
       " '@mortennHS @hoeirupCSGO @CS_Freeze @OfficialGleerup No one dies of a little scumbag. If you take it in and get offended, you can start as a mime - there is no talk at all:)']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at performance\n",
    "\n",
    "#pull up text examples\n",
    "hate = pairs_small[pairs_small['label_hatexplain'] == 'hate']\n",
    "offensive = pairs_small[pairs_small['label_hatexplain'] == 'offensive']\n",
    "normal = pairs_small[pairs_small['label_hatexplain'] == 'normal']\n",
    "\n",
    "\n",
    "print(hate['translated'][:100])\n",
    "\n",
    "# can print the whole text using\n",
    "print('hate:')\n",
    "text_to_print = hate['translated'].head(20).tolist()\n",
    "print(text_to_print)\n",
    "\n",
    "print('offensive:')\n",
    "text_to_print = offensive['translated'].head(20).tolist()\n",
    "text_to_print\n",
    "\n",
    "# Seems allright"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e4c71c-4fb8-47f3-96da-0ca84646b549",
   "metadata": {},
   "source": [
    "### Hate roberta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1158c0f-bd6b-4d3c-b259-8ebe733d4643",
   "metadata": {},
   "source": [
    "Gives no hate/hate\n",
    "\n",
    "https://huggingface.co/facebook/roberta-hate-speech-dynabench-r4-target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec0b477e-a705-4166-92ad-661cc8ea237a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2c806d0e314723b2a5008daca988bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/816 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d8df69cf764802adf1868221d56e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e268c929507041cebcb1dcca8f493d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401fb98a1d6b4dc2b9707bb65cfdc55a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb469d162df4e13a87831106ad1cf39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a03041e2980843d480dadda0b47e46d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipe_6 = pipeline(\"text-classification\", model=\"facebook/roberta-hate-speech-dynabench-r4-target\", device= 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1008e3de-05a4-4bd9-ba83-46ce7e088f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'hate', 'score': 0.99265456199646}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I understand, but actually you are incorrect. Science show that the earth is round\"\n",
    "text_2 = \"Jeg forstår din pointe, men den er ikke korrekt. Videnskaben viser at jorden er rund\"\n",
    "text_3 = \"you are a fool\"\n",
    "text_4 = \"you are an idiot, i despise you\"\n",
    "\n",
    "\n",
    "# Apply the pipeline to the text\n",
    "result = pipe_6(text_4)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "77a49b42-66b7-4b73-a0dd-614e3762de6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting scores: 100%|████████████████████| 2000/2000 [01:37<00:00, 20.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# Test on small df\n",
    "\n",
    "# List to store the scores\n",
    "labels_hate = []\n",
    "scores_hate = []\n",
    "\n",
    "# Iterate over each text\n",
    "for text in (tqdm(pairs_small['translated'], desc= \"Extracting scores\")) :\n",
    "    result = pipe_6(text)\n",
    "    # Extract the scores\n",
    "    label = result[0]['label']\n",
    "    score = result[0]['score']\n",
    "    # Append the scores to the lists\n",
    "    labels_hate.append(label)\n",
    "    scores_hate.append(score)\n",
    "\n",
    "# Add the scores as a new column in the DataFrame\n",
    "pairs_small['label_hateroberta'] = labels_hate\n",
    "pairs_small['score_hateroberta'] = scores_hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "65d61707-d53d-4a57-ad91-f55d57a04ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hate:\n",
      "['@JanniMT @BrondbyIF Please turn yourself down and pick up your suck, please.', '@tcjakobsen @RunestenConsult You misinterpret what I write, Troels. I try again; my point is that it is not unique to poverty. Everyone is allowed their opinion and everyone can express it.', 'Too bad to be you, young man who lost in the lottery and therefore has to go to a skedgymnasium far from your residence and your friends. Unfortunately, you are just one of the eggs we have to smash in order to make the Social Democratic Omelette.', \"@kbo1978 I simply don't think people can understand the feeling of discomfort it gives when you autist experience something that upsets your senses. People can't mentalize the situation properly - which is ironic, because it's we it's said has no empathy and mentalization ability\", \"@teodora_hansen The industry needs all the hands they can get right now, so it's scary that you're only 2 in the class, and be hampered by the fact that not professional knowledge is needed to get the right grades. It's students like you who have to tell other women that everyone can learn to code\", '1/3 Ten years ago, no one would have believed that the next great cultural struggle would not be against the Islamists who would turn the West, but against privileged and spoiled young women and their allies in our midst.', \"@JesperSimoni @lethan87 Eyy! It's fucking delicious to see @lethan87 •\", '@BosseStine @RasmusJarlov Jarlov is quite right. However, politically correct halal radicals are willing to deny the truth.', '@quitte74 @GRaavig But damn it quitte, they made fun of how easy it is to get people to shout heil Hitler. They rebuilt the schet to prove the point. What exactly is the problem?', '@t_norup @ngklausen The 5-10% you mention are the circumcisions that go as with the Danish Jews, where a doctor is present and who perish where all recommendations from the SST are followed, or those that go unsupervised?', '@MMolsted @dortetoft And I ask - quite banal - whether you have set any targets for what someone (probably nicely expensive) cutely disguised Chinese machines should achieve for the elderly?', '@larskohler @SteffenFrolund @jonasholmdk Exactly. I personally am not against A power either, but this is just not the best solution for the challenge we face.', '@GitteKJP @schacks Exactly, You learned how to deal with nature, but the Wolf is new, so no one has experience with how to deal with it. No matter what the experts say, I would never dare take the chance with my children. Is it reasonable that others should do so?', '@Hagbard_Dane @MLundCramer @AndersFKnudsen @HORNNISSEN I went to church at one of the black priests, even my Grundtvigian mother could not restore the damage created by salt. Then, at 45 years of atheist, although I must then be present for rest outside the wall......', '@HansenKenn @svendbrinkmann I was 100% sure that it was me you wanted to nominate. Asshole.', \"@dahyernst In 50 years, people don't give a shit. Probably already in 5.\", \"@dkNeumann @peterbrothersen @stinelinnemann No I can't. For your arguments are carried by your male white privilege. Do you say from opposite slumpy men/friends? Do you say from when there goes gay in manly barbecue the evening? That's not what you do, because it could ruin the mood. Women live it PIS every day!\", '@mbulskov @peterbrothersen @stinelinemann Can you see how illogical you argue because you are a little pissed off?', '@SrenKVillemoes Has read Spiegel. I am tired of jounists who have transformed from being hindsight autodidact virological Monday trainers to being Monday-trained autodidact vaccine researchers on foot on the terms of marketing vaccine on the world market in competition with the USA mfl', '@CatLebowski @FabulesFilajs @Hargir @traetungdame_ @HistorierTill500 @Hva_saa And again: I am not the one who claims that strangers like tweets make fun of rape. On the contrary, @Hargir. Therefore, I ask for proof of the claim made, because it is quite violent.']\n"
     ]
    }
   ],
   "source": [
    "# look at performance\n",
    "\n",
    "#pull up text examples\n",
    "hate = pairs_small[pairs_small['label_hateroberta'] == 'hate']\n",
    "nothate = pairs_small[pairs_small['label_hateroberta'] == 'nothate']\n",
    "\n",
    "\n",
    "# can print the whole text using\n",
    "print('hate:')\n",
    "text_to_print = hate['translated'].head(20).tolist()\n",
    "print(text_to_print)\n",
    "\n",
    "# Does catch some hate, but probably a little too generous. Classify something as hate that is moreso offensive/harsh, or tweets talking about hate etc.\n",
    "# An idea could be to limit hate labels to be when the hate-score is above 0.8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f0341a-91e8-4b81-84c8-ab7c7810d338",
   "metadata": {},
   "source": [
    "## Finetuning a model on labeled counterspeech data (CONAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927b5846-f259-440b-a3f4-f9d74968b35a",
   "metadata": {},
   "source": [
    "CONAN (COunter NArratives through Nichesourcing): A dataset containing counterspeech responses to hate speech. Data is French, italian and English\n",
    "\n",
    "https://github.com/marcoguerini/CONAN\n",
    "\n",
    "https://aclanthology.org/P19-1271.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "921d8282-fbce-4b6d-a908-3ab144085ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "249d3c2a-8f33-4e6a-b0a7-c985fcfa5fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect CONAN data\n",
    "conan = pd.read_csv('/Users/idahelenedencker/Desktop/CONAN.csv')\n",
    "\n",
    "#14988 pairs of hate/counterspeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b4c1d29-0fc5-4de2-b127-9a6a3c04128e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cn_id</th>\n",
       "      <th>hateSpeech</th>\n",
       "      <th>counterSpeech</th>\n",
       "      <th>hsType</th>\n",
       "      <th>hsSubType</th>\n",
       "      <th>cnType</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>educationLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENT1ST0001HS0033CN000021</td>\n",
       "      <td>According to a recent OFSTED report, a school ...</td>\n",
       "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
       "      <td>Islamophobia</td>\n",
       "      <td>crimes</td>\n",
       "      <td>facts</td>\n",
       "      <td>61.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Bachelor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENT1ST0001HS0033CN000021P1</td>\n",
       "      <td>In Birmingham there is a school where girls an...</td>\n",
       "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
       "      <td>Islamophobia</td>\n",
       "      <td>crimes</td>\n",
       "      <td>facts</td>\n",
       "      <td>61.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Bachelor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENT1ST0001HS0033CN000021P2</td>\n",
       "      <td>A school in Birningham is still separating gir...</td>\n",
       "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
       "      <td>Islamophobia</td>\n",
       "      <td>crimes</td>\n",
       "      <td>facts</td>\n",
       "      <td>61.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Bachelor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENT1ST0001HS0033CN000022</td>\n",
       "      <td>According to a recent OFSTED report, a school ...</td>\n",
       "      <td>While this story is presented as an 'Islamic i...</td>\n",
       "      <td>Islamophobia</td>\n",
       "      <td>crimes</td>\n",
       "      <td>facts</td>\n",
       "      <td>61.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Bachelor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENT1ST0001HS0033CN000022P1</td>\n",
       "      <td>In Birmingham there is a school where girls an...</td>\n",
       "      <td>While this story is presented as an 'Islamic i...</td>\n",
       "      <td>Islamophobia</td>\n",
       "      <td>crimes</td>\n",
       "      <td>facts</td>\n",
       "      <td>61.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Bachelor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14983</th>\n",
       "      <td>ITT1ST0023HS0055CN001068T1</td>\n",
       "      <td>A woman who accepts to live hidden under a vei...</td>\n",
       "      <td>No woman agrees to be beaten, be unable to bre...</td>\n",
       "      <td>Islamophobia</td>\n",
       "      <td>women</td>\n",
       "      <td>facts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14984</th>\n",
       "      <td>ITT1ST0023HS0055CN001069</td>\n",
       "      <td>Una donna che accetta di vivere nascosta sotto...</td>\n",
       "      <td>Leggere commenti di donne capaci di scrivere t...</td>\n",
       "      <td>Islamophobia</td>\n",
       "      <td>women</td>\n",
       "      <td>hypocrisy</td>\n",
       "      <td>41.0</td>\n",
       "      <td>female</td>\n",
       "      <td>High school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14985</th>\n",
       "      <td>ITT1ST0023HS0055CN001069P1</td>\n",
       "      <td>Una donna che permette di farsi coprire con un...</td>\n",
       "      <td>Leggere commenti di donne capaci di scrivere t...</td>\n",
       "      <td>Islamophobia</td>\n",
       "      <td>women</td>\n",
       "      <td>hypocrisy</td>\n",
       "      <td>41.0</td>\n",
       "      <td>female</td>\n",
       "      <td>High school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14986</th>\n",
       "      <td>ITT1ST0023HS0055CN001069P2</td>\n",
       "      <td>In Italia non possiamo accogliere donne che de...</td>\n",
       "      <td>Leggere commenti di donne capaci di scrivere t...</td>\n",
       "      <td>Islamophobia</td>\n",
       "      <td>women</td>\n",
       "      <td>hypocrisy</td>\n",
       "      <td>41.0</td>\n",
       "      <td>female</td>\n",
       "      <td>High school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14987</th>\n",
       "      <td>ITT1ST0023HS0055CN001069T1</td>\n",
       "      <td>A woman who accepts to live hidden under a vei...</td>\n",
       "      <td>Reading comments of women who can write such n...</td>\n",
       "      <td>Islamophobia</td>\n",
       "      <td>women</td>\n",
       "      <td>hypocrisy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14988 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            cn_id  \\\n",
       "0        ENT1ST0001HS0033CN000021   \n",
       "1      ENT1ST0001HS0033CN000021P1   \n",
       "2      ENT1ST0001HS0033CN000021P2   \n",
       "3        ENT1ST0001HS0033CN000022   \n",
       "4      ENT1ST0001HS0033CN000022P1   \n",
       "...                           ...   \n",
       "14983  ITT1ST0023HS0055CN001068T1   \n",
       "14984    ITT1ST0023HS0055CN001069   \n",
       "14985  ITT1ST0023HS0055CN001069P1   \n",
       "14986  ITT1ST0023HS0055CN001069P2   \n",
       "14987  ITT1ST0023HS0055CN001069T1   \n",
       "\n",
       "                                              hateSpeech  \\\n",
       "0      According to a recent OFSTED report, a school ...   \n",
       "1      In Birmingham there is a school where girls an...   \n",
       "2      A school in Birningham is still separating gir...   \n",
       "3      According to a recent OFSTED report, a school ...   \n",
       "4      In Birmingham there is a school where girls an...   \n",
       "...                                                  ...   \n",
       "14983  A woman who accepts to live hidden under a vei...   \n",
       "14984  Una donna che accetta di vivere nascosta sotto...   \n",
       "14985  Una donna che permette di farsi coprire con un...   \n",
       "14986  In Italia non possiamo accogliere donne che de...   \n",
       "14987  A woman who accepts to live hidden under a vei...   \n",
       "\n",
       "                                           counterSpeech        hsType  \\\n",
       "0      To be fair, the OFSTED report is more concerne...  Islamophobia   \n",
       "1      To be fair, the OFSTED report is more concerne...  Islamophobia   \n",
       "2      To be fair, the OFSTED report is more concerne...  Islamophobia   \n",
       "3      While this story is presented as an 'Islamic i...  Islamophobia   \n",
       "4      While this story is presented as an 'Islamic i...  Islamophobia   \n",
       "...                                                  ...           ...   \n",
       "14983  No woman agrees to be beaten, be unable to bre...  Islamophobia   \n",
       "14984  Leggere commenti di donne capaci di scrivere t...  Islamophobia   \n",
       "14985  Leggere commenti di donne capaci di scrivere t...  Islamophobia   \n",
       "14986  Leggere commenti di donne capaci di scrivere t...  Islamophobia   \n",
       "14987  Reading comments of women who can write such n...  Islamophobia   \n",
       "\n",
       "      hsSubType     cnType   age  gender educationLevel  \n",
       "0        crimes      facts  61.0    male       Bachelor  \n",
       "1        crimes      facts  61.0    male       Bachelor  \n",
       "2        crimes      facts  61.0    male       Bachelor  \n",
       "3        crimes      facts  61.0    male       Bachelor  \n",
       "4        crimes      facts  61.0    male       Bachelor  \n",
       "...         ...        ...   ...     ...            ...  \n",
       "14983     women      facts   NaN     NaN            NaN  \n",
       "14984     women  hypocrisy  41.0  female    High school  \n",
       "14985     women  hypocrisy  41.0  female    High school  \n",
       "14986     women  hypocrisy  41.0  female    High school  \n",
       "14987     women  hypocrisy   NaN     NaN            NaN  \n",
       "\n",
       "[14988 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "734453cb-5542-4fc7-8630-d6aef23175db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6803"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conan['counterSpeech'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe8fbc3b-6ac4-40fd-ae33-06f5b0c20206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only columns with unique values \n",
    "\n",
    "# Drop duplicate rows based on counterSpeech\n",
    "conan.drop_duplicates(subset=['counterSpeech'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26042b3e-005a-4494-9c4f-f14795b049c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.44.0)\n",
      "Requirement already satisfied: datasets in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.20.0)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.3.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.24.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (3.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db54a7d2-a39e-454e-8103-0074a41e4f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "\n",
    "# Create a binary label column: 1 for counter speech, 0 for hate speech\n",
    "conan['label'] = 1  # since we are only interested in counter speech\n",
    "\n",
    "# Select relevant columns\n",
    "conan = conan[['counterSpeech', 'label']]\n",
    "conan = conan.rename(columns={'counterSpeech': 'text'})\n",
    "\n",
    "# Split into train and validation sets\n",
    "train_data, val_data = train_test_split(conan, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b27de1c2-6e10-45ca-9c54-4906c20fd2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "val_dataset = Dataset.from_pandas(val_data)\n",
    "datasets = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d53281f3-9488-4a36-b7bf-0f5bd848c960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc02e29f67584bfe9332f2d7c897c240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb93546940574006b3cf6cd71935926a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43d208760c4a47539267e8340148569a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2911f118a54235a111bed5e3d913e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbd7010174a48408f0faa13a3e7c573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5442 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53608780a094541a31d61f1248e9b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1361 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True)\n",
    "\n",
    "tokenized_datasets = datasets.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d4d0fe6d-3223-48d9-bda9-2586460e55fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "fp16 mixed precision requires a GPU (not 'mps').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 17\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistilbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      5\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      6\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     fp16\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# Enable mixed precision training\u001b[39;00m\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenized_datasets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenized_datasets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py:410\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_in_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 410\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_accelerator_and_postprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;66;03m# memory metrics - must set up as early as possible\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_memory_tracker \u001b[38;5;241m=\u001b[39m TrainerMemoryTracker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mskip_memory_metrics)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py:4658\u001b[0m, in \u001b[0;36mTrainer.create_accelerator_and_postprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4655\u001b[0m     args\u001b[38;5;241m.\u001b[39mupdate(accelerator_config)\n\u001b[1;32m   4657\u001b[0m \u001b[38;5;66;03m# create accelerator object\u001b[39;00m\n\u001b[0;32m-> 4658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;241m=\u001b[39m \u001b[43mAccelerator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4659\u001b[0m \u001b[38;5;66;03m# some Trainer classes need to use `gather` instead of `gather_for_metrics`, thus we store a flag\u001b[39;00m\n\u001b[1;32m   4660\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather_for_metrics\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/accelerate/accelerator.py:467\u001b[0m, in \u001b[0;36mAccelerator.__init__\u001b[0;34m(self, device_placement, split_batches, mixed_precision, gradient_accumulation_steps, cpu, dataloader_config, deepspeed_plugin, fsdp_plugin, megatron_lm_plugin, rng_types, log_with, project_dir, project_config, gradient_accumulation_plugin, dispatch_batches, even_batches, use_seedable_sampler, step_scheduler_with_optimizer, kwargs_handlers, dynamo_backend)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnative_amp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlu\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_xla_available(\n\u001b[1;32m    465\u001b[0m     check_is_tpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    466\u001b[0m ):\n\u001b[0;32m--> 467\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16 mixed precision requires a GPU (not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    468\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler_handler\u001b[38;5;241m.\u001b[39mto_kwargs() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mFSDP:\n",
      "\u001b[0;31mValueError\u001b[0m: fp16 mixed precision requires a GPU (not 'mps')."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    fp16=True,  # Enable mixed precision training\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3df85fb-7d0a-4c5f-a8a5-664fe51dc32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import  AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\" # Define which pre-trained model we will be using\n",
    "classifier = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2) # Get the classifier\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint) # Get the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6ca1089-40e5-4dd5-b251-63174c6a03b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "conan = conan.rename(columns={'label': 'target'})\n",
    "df_train, df_eval = train_test_split(conan, train_size=0.8,stratify=conan.target, random_state=42) # Stratified splitting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38686f2d-0473-4932-8004-afcf1563e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "raw_datasets = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(df_train),\n",
    "    \"eval\": Dataset.from_pandas(df_eval)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7fa6a73-2e59-4507-9d49-81dbabb41077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Dict:\n",
      " DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'target', '__index_level_0__'],\n",
      "        num_rows: 5442\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['text', 'target', '__index_level_0__'],\n",
      "        num_rows: 1361\n",
      "    })\n",
      "})\n",
      "\n",
      "\n",
      "Train's features:\n",
      " {'text': Value(dtype='string', id=None), 'target': Value(dtype='int64', id=None), '__index_level_0__': Value(dtype='int64', id=None)}\n",
      "\n",
      "\n",
      "First row of Train:\n",
      " {'text': 'Non credo che la religione sia una questione di concorrenza.', 'target': 1, '__index_level_0__': 13420}\n"
     ]
    }
   ],
   "source": [
    "# Check the datasets\n",
    "print(\"Dataset Dict:\\n\", raw_datasets)\n",
    "print(\"\\n\\nTrain's features:\\n\", raw_datasets[\"train\"].features)\n",
    "print(\"\\n\\nFirst row of Train:\\n\", raw_datasets[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2289ff6-2d40-48d7-9a34-103437ac7265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5e14b92f3143ba860790c812e7f0e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5442 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a254ac7bbd47209d12dff3ded850c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1361 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'target', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 5442\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['text', 'target', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1361\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text, and truncate the text if it exceed the tokenizer maximum length. Batched=True to tokenize multiple texts at the same time.\n",
    "tokenized_datasets = raw_datasets.map(lambda dataset: tokenizer(dataset['text'], truncation=True), batched=True)\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "450360cd-50e6-421f-adaa-3c796f0c0aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Non credo che la religione sia una questione di concorrenza.', 'target': 1, '__index_level_0__': 13420, 'input_ids': [101, 2512, 13675, 26010, 18178, 2474, 4676, 2063, 9033, 2050, 14477, 3160, 2063, 4487, 9530, 27108, 7389, 4143, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# Check the first row\n",
    "print(tokenized_datasets[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17ee55a2-14a6-4e04-a623-7d50097a665e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 5442\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1361\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\", \"__index_level_0__\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"target\", \"labels\")\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7653244b-9ac2-4267-8b66-830aa78aac9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip -q install evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5e42cfb-aef4-441b-8f04-266286278eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "# Padding for batch of data that will be fed into model for training\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Training args \n",
    "training_args = TrainingArguments(\"test-trainer\", num_train_epochs=1, evaluation_strategy=\"epoch\", \n",
    "                                  weight_decay=5e-4, save_strategy=\"no\", report_to=\"none\")\n",
    "\n",
    "# Metric for validation error\n",
    "def compute_metrics(eval_preds):\n",
    "    metric = evaluate.load(\"glue\", \"mrpc\") # F1 and Accuracy\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Define trainer\n",
    "trainer = Trainer(\n",
    "    classifier,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"eval\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics)\n",
    "\n",
    "#If this gives an error like fp16 mixed precision requires a GPU (not 'mps')., restart kernel and run again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfaba1d9-6d99-4632-8811-29b7724e8c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='207' max='681' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [207/681 01:05 < 02:31, 3.12 it/s, Epoch 0.30/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 1.05 GB, other allocations: 7.95 GB, max allowed: 9.07 GB). Tried to allocate 89.42 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Start the fine-tuning \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py:1948\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1946\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1949\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1953\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py:2351\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2348\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2349\u001b[0m         grad_norm \u001b[38;5;241m=\u001b[39m _grad_norm\n\u001b[0;32m-> 2351\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_optimizer_step(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2355\u001b[0m optimizer_was_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39moptimizer_step_was_skipped\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/accelerate/optimizer.py:170\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator_state\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mXLA:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_state\u001b[38;5;241m.\u001b[39mis_xla_gradients_synced \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:68\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     67\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/adamw.py:184\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    171\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    174\u001b[0m         group,\n\u001b[1;32m    175\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m         state_steps,\n\u001b[1;32m    182\u001b[0m     )\n\u001b[0;32m--> 184\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/adamw.py:335\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 335\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/adamw.py:464\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    462\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    466\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 1.05 GB, other allocations: 7.95 GB, max allowed: 9.07 GB). Tried to allocate 89.42 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "# Start the fine-tuning \n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4fdbbd-7069-45a3-b329-0a13d54c454b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fe932a8-93c6-44f4-80c5-77116faf5fa1",
   "metadata": {},
   "source": [
    "## (maybe) Finetuning the bestperforming huggingface counterspeech classifier model on a labeled danish dataset (i can label some?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3071614-06c4-4689-89ca-59e2e910a27a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "599292e4-61f8-4d1f-a6b0-8c5ebc2176fd",
   "metadata": {},
   "source": [
    "## Applying the jigsaw perspective API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519940ee-ca09-441f-a5f7-d5285f56d2aa",
   "metadata": {},
   "source": [
    "1) TOXICITY = rude, disrespectful, or unreasonable comment \n",
    "2) SEVERE_TOXICITY = A very hateful, aggressive, disrespectful comment \n",
    "3) IDENTITY_ATTACK = Negative or hateful comments targeting someone because of their identity.\n",
    "4) INSULT = Insulting, inflammatory, or negative comment towards a person or a group of people.\n",
    "5) PROFANITY = Swear words, curse words, or other obscene or profane language.\n",
    "6) THREAT = Describes an intention to inflict pain, injury, or violence against an individual or group.\n",
    "\n",
    "Available languages for these attributes include sweedish, test that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a11d2c7-1cc9-406a-9c3b-6d119b3edf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade googleapiclient\n",
    "!pip install --upgrade json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659529df-cfd0-4189-98fc-c46b644a7368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b08412-4d7f-4c48-972d-767483e8054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_key= 0000\n",
    "\n",
    "#Generates API client object dynamically based on service name and version\n",
    "service= discovery.build('commentanalyzer', 'v1alpha1', developerKey= API_key)\n",
    "\n",
    "analyze_request = {\n",
    "    'comment': {'text': 'i like your shirt'},\n",
    "    'requestedAttributes': {'TOXICITY':{}}\n",
    "}\n",
    "\n",
    "response = service.comments().analyze(body= analyze_request).execute()\n",
    "\n",
    "print json.dumps(response, indent= 2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
