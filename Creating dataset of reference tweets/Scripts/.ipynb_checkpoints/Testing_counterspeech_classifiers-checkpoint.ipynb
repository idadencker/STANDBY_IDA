{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b7e62b0-9f07-4839-8543-3691f9f7b10a",
   "metadata": {},
   "source": [
    "# Testing classfiers on the 10k pairs dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477b01f2-c45f-4f84-a823-e03bffd42f8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Loading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "102009ac-072c-4bbb-a53b-24be2a65f8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas \n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "588870b4-7f13-457f-90c6-11c553e018d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>replied_to_reply_count</th>\n",
       "      <th>referenced_tweets_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>PNR</th>\n",
       "      <th>...</th>\n",
       "      <th>A/R</th>\n",
       "      <th>fasttext_cos_sim_hate_sentence</th>\n",
       "      <th>fasttext_cos_sim_prosocial_sentence</th>\n",
       "      <th>tweeter_username</th>\n",
       "      <th>tweeter_name</th>\n",
       "      <th>pair_num</th>\n",
       "      <th>type</th>\n",
       "      <th>like_n</th>\n",
       "      <th>retweet_n</th>\n",
       "      <th>quote_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1036583587242549248</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-09-03 21:04:41</td>\n",
       "      <td>1036721666628444160</td>\n",
       "      <td>@frkomo Jeg siger det vel strengt taget bare t...</td>\n",
       "      <td>1666088336</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1036721302692917250</td>\n",
       "      <td>148061237</td>\n",
       "      <td>1311570613</td>\n",
       "      <td>...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0.762309</td>\n",
       "      <td>0.959726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>reply</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1036583587242549248</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-09-03 21:03:14</td>\n",
       "      <td>1036721302692917250</td>\n",
       "      <td>@MonbergSF Sig det til spillerforeningen, som ...</td>\n",
       "      <td>148061237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1666088336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>frkomo</td>\n",
       "      <td>Sarah Agerklint</td>\n",
       "      <td>1</td>\n",
       "      <td>tweet</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>899548260863488002</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-08-21 12:10:42</td>\n",
       "      <td>899604671375052801</td>\n",
       "      <td>@PeterHuggler Had alt det, du vil. Men du skal...</td>\n",
       "      <td>547416021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>899603561323081729</td>\n",
       "      <td>3301029597</td>\n",
       "      <td>1405772015</td>\n",
       "      <td>...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0.836744</td>\n",
       "      <td>0.958750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>reply</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>899548260863488002</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-08-21 12:06:17</td>\n",
       "      <td>899603561323081729</td>\n",
       "      <td>@brianweichardt Jeg hader den her slags: Du gå...</td>\n",
       "      <td>3301029597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>547416021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PeterHuggler</td>\n",
       "      <td>Peter Huggler</td>\n",
       "      <td>2</td>\n",
       "      <td>tweet</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1345496479583113217</td>\n",
       "      <td>da</td>\n",
       "      <td>2021-01-03 12:38:16</td>\n",
       "      <td>1345711074407014400</td>\n",
       "      <td>@nielscallesoe @Heunicke Din første indvending...</td>\n",
       "      <td>87923613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1345524516311748608</td>\n",
       "      <td>23341699</td>\n",
       "      <td>0908801199</td>\n",
       "      <td>...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0.746267</td>\n",
       "      <td>0.957824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>reply</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>1430605648878784513</td>\n",
       "      <td>da</td>\n",
       "      <td>2021-08-25 19:00:13</td>\n",
       "      <td>1430605952722604045</td>\n",
       "      <td>@PSkipperEL Træk den røde linje nu.\\n\\n#VæltMe...</td>\n",
       "      <td>2345329126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>611076925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M_K_Petersen</td>\n",
       "      <td>Michael K. Petersen</td>\n",
       "      <td>9998</td>\n",
       "      <td>tweet</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>822180433681088513</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-01-19 20:55:03</td>\n",
       "      <td>822185628620226560</td>\n",
       "      <td>@sllaursen har svært ved at afgøre om jeg ægte...</td>\n",
       "      <td>546738902</td>\n",
       "      <td>1.0</td>\n",
       "      <td>822180433681088513</td>\n",
       "      <td>43529378</td>\n",
       "      <td>1007802400</td>\n",
       "      <td>...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0.886249</td>\n",
       "      <td>0.839126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9999</td>\n",
       "      <td>reply</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>822180433681088513</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-01-19 20:34:25</td>\n",
       "      <td>822180433681088513</td>\n",
       "      <td>Når et sponsorat rammer ESPN, er man kommet ok...</td>\n",
       "      <td>43529378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>steen</td>\n",
       "      <td>Steen Laursen</td>\n",
       "      <td>9999</td>\n",
       "      <td>tweet</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>953648851721826304</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-01-17 18:22:52</td>\n",
       "      <td>953694124049420288</td>\n",
       "      <td>@emilnielsen @pelledragsted Tak skal du have. ...</td>\n",
       "      <td>26210681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>953655858675757057</td>\n",
       "      <td>19391295</td>\n",
       "      <td>2010772527</td>\n",
       "      <td>...</td>\n",
       "      <td>0-1</td>\n",
       "      <td>0.886244</td>\n",
       "      <td>0.897734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>reply</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>953648851721826304</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-01-17 15:50:49</td>\n",
       "      <td>953655858675757057</td>\n",
       "      <td>Der findes ikke nogen mere irriterende politis...</td>\n",
       "      <td>19391295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19391295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>emilnielsen</td>\n",
       "      <td>Emil Nielsen</td>\n",
       "      <td>10000</td>\n",
       "      <td>tweet</td>\n",
       "      <td>115</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           conversation_id lang           created_at                   id  \\\n",
       "0      1036583587242549248   da  2018-09-03 21:04:41  1036721666628444160   \n",
       "1      1036583587242549248   da  2018-09-03 21:03:14  1036721302692917250   \n",
       "2       899548260863488002   da  2017-08-21 12:10:42   899604671375052801   \n",
       "3       899548260863488002   da  2017-08-21 12:06:17   899603561323081729   \n",
       "4      1345496479583113217   da  2021-01-03 12:38:16  1345711074407014400   \n",
       "...                    ...  ...                  ...                  ...   \n",
       "19995  1430605648878784513   da  2021-08-25 19:00:13  1430605952722604045   \n",
       "19996   822180433681088513   da  2017-01-19 20:55:03   822185628620226560   \n",
       "19997   822180433681088513   da  2017-01-19 20:34:25   822180433681088513   \n",
       "19998   953648851721826304   da  2018-01-17 18:22:52   953694124049420288   \n",
       "19999   953648851721826304   da  2018-01-17 15:50:49   953655858675757057   \n",
       "\n",
       "                                                    text   author_id  \\\n",
       "0      @frkomo Jeg siger det vel strengt taget bare t...  1666088336   \n",
       "1      @MonbergSF Sig det til spillerforeningen, som ...   148061237   \n",
       "2      @PeterHuggler Had alt det, du vil. Men du skal...   547416021   \n",
       "3      @brianweichardt Jeg hader den her slags: Du gå...  3301029597   \n",
       "4      @nielscallesoe @Heunicke Din første indvending...    87923613   \n",
       "...                                                  ...         ...   \n",
       "19995  @PSkipperEL Træk den røde linje nu.\\n\\n#VæltMe...  2345329126   \n",
       "19996  @sllaursen har svært ved at afgøre om jeg ægte...   546738902   \n",
       "19997  Når et sponsorat rammer ESPN, er man kommet ok...    43529378   \n",
       "19998  @emilnielsen @pelledragsted Tak skal du have. ...    26210681   \n",
       "19999  Der findes ikke nogen mere irriterende politis...    19391295   \n",
       "\n",
       "       replied_to_reply_count referenced_tweets_id in_reply_to_user_id  \\\n",
       "0                         1.0  1036721302692917250           148061237   \n",
       "1                         NaN                  NaN          1666088336   \n",
       "2                         1.0   899603561323081729          3301029597   \n",
       "3                         NaN                  NaN           547416021   \n",
       "4                         1.0  1345524516311748608            23341699   \n",
       "...                       ...                  ...                 ...   \n",
       "19995                     NaN                  NaN           611076925   \n",
       "19996                     1.0   822180433681088513            43529378   \n",
       "19997                     NaN                  NaN                 NaN   \n",
       "19998                     0.0   953655858675757057            19391295   \n",
       "19999                     NaN                  NaN            19391295   \n",
       "\n",
       "              PNR  ...  A/R  fasttext_cos_sim_hate_sentence  \\\n",
       "0      1311570613  ...  0-0                        0.762309   \n",
       "1             NaN  ...  NaN                             NaN   \n",
       "2      1405772015  ...  0-0                        0.836744   \n",
       "3             NaN  ...  NaN                             NaN   \n",
       "4      0908801199  ...  0-0                        0.746267   \n",
       "...           ...  ...  ...                             ...   \n",
       "19995         NaN  ...  NaN                             NaN   \n",
       "19996  1007802400  ...  0-0                        0.886249   \n",
       "19997         NaN  ...  NaN                             NaN   \n",
       "19998  2010772527  ...  0-1                        0.886244   \n",
       "19999         NaN  ...  NaN                             NaN   \n",
       "\n",
       "       fasttext_cos_sim_prosocial_sentence  tweeter_username  \\\n",
       "0                                 0.959726               NaN   \n",
       "1                                      NaN            frkomo   \n",
       "2                                 0.958750               NaN   \n",
       "3                                      NaN      PeterHuggler   \n",
       "4                                 0.957824               NaN   \n",
       "...                                    ...               ...   \n",
       "19995                                  NaN      M_K_Petersen   \n",
       "19996                             0.839126               NaN   \n",
       "19997                                  NaN             steen   \n",
       "19998                             0.897734               NaN   \n",
       "19999                                  NaN       emilnielsen   \n",
       "\n",
       "              tweeter_name pair_num   type  like_n retweet_n quote_n  \n",
       "0                      NaN        1  reply       1         0       0  \n",
       "1          Sarah Agerklint        1  tweet       1         0       0  \n",
       "2                      NaN        2  reply       0         0       0  \n",
       "3            Peter Huggler        2  tweet       1         0       0  \n",
       "4                      NaN        3  reply       1         0       0  \n",
       "...                    ...      ...    ...     ...       ...     ...  \n",
       "19995  Michael K. Petersen     9998  tweet      16         0       0  \n",
       "19996                  NaN     9999  reply       3         0       0  \n",
       "19997        Steen Laursen     9999  tweet      13         1       0  \n",
       "19998                  NaN    10000  reply      10         0       0  \n",
       "19999         Emil Nielsen    10000  tweet     115         3       3  \n",
       "\n",
       "[20000 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in data\n",
    "\n",
    "dtype_dict_all = {\n",
    "    'conversation_id': 'object',\n",
    "    'id': 'object',\n",
    "    'author_id': 'object',\n",
    "    'referenced_tweets_id': 'object',\n",
    "    'in_reply_to_user_id': 'object',\n",
    "    'PNR': 'object'\n",
    "}\n",
    "\n",
    "pairs = pd.read_csv('/Users/idahelenedencker/Desktop/STANDBY_Ida/Creating dataset of reference tweets/10k_twitter_pairs.csv', dtype=dtype_dict_all )\n",
    "\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3511ea3-2784-4114-9c4d-3535cb3abdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conversation_id                         object\n",
       "lang                                    object\n",
       "created_at                              object\n",
       "id                                      object\n",
       "text                                    object\n",
       "author_id                               object\n",
       "replied_to_reply_count                 float64\n",
       "referenced_tweets_id                    object\n",
       "in_reply_to_user_id                     object\n",
       "PNR                                     object\n",
       "surveyXact_externke                     object\n",
       "non_unique_twitter_author_id           float64\n",
       "started_survey                         float64\n",
       "rec-nition                             float64\n",
       "attack                                 float64\n",
       "A/R                                     object\n",
       "fasttext_cos_sim_hate_sentence         float64\n",
       "fasttext_cos_sim_prosocial_sentence    float64\n",
       "tweeter_username                        object\n",
       "tweeter_name                            object\n",
       "pair_num                                 int64\n",
       "type                                    object\n",
       "like_n                                   int64\n",
       "retweet_n                                int64\n",
       "quote_n                                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e850ced-e35b-4727-8db4-9e71a68906be",
   "metadata": {},
   "source": [
    "## Zero shot learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3487e1cf-d647-47ba-abc7-3db19cea186e",
   "metadata": {},
   "source": [
    "In zero shot learning a pre-trained model is used to predict the give a probability on any given label using embeddings, even though the label(s) has not been part of the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21fe73e-2e59-44f2-b28c-3f8f5c83fc45",
   "metadata": {},
   "source": [
    "### facebook/bart-large-mnli model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ef5f2ca-d746-480b-8291-39b8023d2ca7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.43.3)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.24.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eb75d4a-d914-435c-a124-ab99a294d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_1 = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52ab3a1a-22e1-4d81-8745-be41f6f7fe54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'jeg forstår hvad du mener, men din kommentar er ikke særlig konstruktiv',\n",
       " 'labels': ['counterspeech', 'neutral tone', 'hate'],\n",
       " 'scores': [0.819023072719574, 0.17399725317955017, 0.006979694124311209]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_labels = ['counterspeech', 'hate', 'neutral tone']\n",
    "\n",
    "sequence_to_classify_1 = \"i see your point but i dont think it is very constructive\"\n",
    "sequence_to_classify_2 = \"jeg forstår hvad du mener, men din kommentar er ikke særlig konstruktiv\"\n",
    "sequence_to_classify_3 = pairs['text'][3]\n",
    "sequence_to_classify_4 = \"today i went for a walk outside with my dog, nice sunny weather\"\n",
    "\n",
    "pipe_1(sequence_to_classify_2, candidate_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f667e41f-f40a-4414-9375-503b33ac64ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting scores: 100%|██████████████████████| 300/300 [01:36<00:00,  3.09it/s]\n",
      "/var/folders/ds/0d9wxy210kx_fvknqn3hcg_h0000gn/T/ipykernel_15413/2575739544.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pairs_test['counterspeech_score'] = counterspeech_scores\n",
      "/var/folders/ds/0d9wxy210kx_fvknqn3hcg_h0000gn/T/ipykernel_15413/2575739544.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pairs_test['hate_score'] = hate_scores\n",
      "/var/folders/ds/0d9wxy210kx_fvknqn3hcg_h0000gn/T/ipykernel_15413/2575739544.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pairs_test['neutral_score'] = neutral_scores\n",
      "/var/folders/ds/0d9wxy210kx_fvknqn3hcg_h0000gn/T/ipykernel_15413/2575739544.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pairs_test['counterspeech'] = 'NA'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>replied_to_reply_count</th>\n",
       "      <th>referenced_tweets_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>PNR</th>\n",
       "      <th>...</th>\n",
       "      <th>tweeter_name</th>\n",
       "      <th>pair_num</th>\n",
       "      <th>type</th>\n",
       "      <th>like_n</th>\n",
       "      <th>retweet_n</th>\n",
       "      <th>quote_n</th>\n",
       "      <th>counterspeech_score</th>\n",
       "      <th>hate_score</th>\n",
       "      <th>neutral_score</th>\n",
       "      <th>counterspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1036583587242549248</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-09-03 21:04:41</td>\n",
       "      <td>1036721666628444160</td>\n",
       "      <td>@frkomo Jeg siger det vel strengt taget bare t...</td>\n",
       "      <td>1666088336</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1036721302692917250</td>\n",
       "      <td>148061237</td>\n",
       "      <td>1311570613</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>reply</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.765376</td>\n",
       "      <td>0.008536</td>\n",
       "      <td>0.226088</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1036583587242549248</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-09-03 21:03:14</td>\n",
       "      <td>1036721302692917250</td>\n",
       "      <td>@MonbergSF Sig det til spillerforeningen, som ...</td>\n",
       "      <td>148061237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1666088336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Sarah Agerklint</td>\n",
       "      <td>1</td>\n",
       "      <td>tweet</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.853204</td>\n",
       "      <td>0.006963</td>\n",
       "      <td>0.139833</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>899548260863488002</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-08-21 12:10:42</td>\n",
       "      <td>899604671375052801</td>\n",
       "      <td>@PeterHuggler Had alt det, du vil. Men du skal...</td>\n",
       "      <td>547416021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>899603561323081729</td>\n",
       "      <td>3301029597</td>\n",
       "      <td>1405772015</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>reply</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.575550</td>\n",
       "      <td>0.030307</td>\n",
       "      <td>0.394142</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>899548260863488002</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-08-21 12:06:17</td>\n",
       "      <td>899603561323081729</td>\n",
       "      <td>@brianweichardt Jeg hader den her slags: Du gå...</td>\n",
       "      <td>3301029597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>547416021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Peter Huggler</td>\n",
       "      <td>2</td>\n",
       "      <td>tweet</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.616760</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>0.368008</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1345496479583113217</td>\n",
       "      <td>da</td>\n",
       "      <td>2021-01-03 12:38:16</td>\n",
       "      <td>1345711074407014400</td>\n",
       "      <td>@nielscallesoe @Heunicke Din første indvending...</td>\n",
       "      <td>87923613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1345524516311748608</td>\n",
       "      <td>23341699</td>\n",
       "      <td>0908801199</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>reply</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.815085</td>\n",
       "      <td>0.017978</td>\n",
       "      <td>0.166937</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1231494237130280966</td>\n",
       "      <td>da</td>\n",
       "      <td>2020-02-23 08:50:33</td>\n",
       "      <td>1231501587534827520</td>\n",
       "      <td>@SteffenFrolund @MonbergSF @jonasholmdk Og præ...</td>\n",
       "      <td>97198778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33859175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Lars Køhler</td>\n",
       "      <td>148</td>\n",
       "      <td>tweet</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.608624</td>\n",
       "      <td>0.046957</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1414594602275901443</td>\n",
       "      <td>da</td>\n",
       "      <td>2021-07-12 14:39:33</td>\n",
       "      <td>1414595287532834818</td>\n",
       "      <td>@MVangby Er det for grundspillet, eller hele s...</td>\n",
       "      <td>805874425988087811</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1414594602275901443</td>\n",
       "      <td>835144095165202433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149</td>\n",
       "      <td>reply</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812016</td>\n",
       "      <td>0.027733</td>\n",
       "      <td>0.160252</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1414594602275901443</td>\n",
       "      <td>da</td>\n",
       "      <td>2021-07-12 14:36:49</td>\n",
       "      <td>1414594602275901443</td>\n",
       "      <td>Min Superliga forudsigelse, her 1,5 måned inde...</td>\n",
       "      <td>835144095165202433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Mikkel Vangby</td>\n",
       "      <td>149</td>\n",
       "      <td>tweet</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.868525</td>\n",
       "      <td>0.042197</td>\n",
       "      <td>0.089278</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1198177606077734913</td>\n",
       "      <td>da</td>\n",
       "      <td>2019-11-23 10:25:50</td>\n",
       "      <td>1198185883821846530</td>\n",
       "      <td>@steenHiversen @R4nd4hl @uffeelbaek @naserkhad...</td>\n",
       "      <td>26210681</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1198185017312186368</td>\n",
       "      <td>2554415384</td>\n",
       "      <td>2010772527</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150</td>\n",
       "      <td>reply</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.710413</td>\n",
       "      <td>0.024398</td>\n",
       "      <td>0.265189</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1198177606077734913</td>\n",
       "      <td>da</td>\n",
       "      <td>2019-11-23 10:22:23</td>\n",
       "      <td>1198185017312186368</td>\n",
       "      <td>@ammitzbollbille @R4nd4hl @uffeelbaek @naserkh...</td>\n",
       "      <td>2554415384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26210681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Steen Holm Iversen</td>\n",
       "      <td>150</td>\n",
       "      <td>tweet</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.904418</td>\n",
       "      <td>0.030710</td>\n",
       "      <td>0.064872</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         conversation_id lang           created_at                   id  \\\n",
       "0    1036583587242549248   da  2018-09-03 21:04:41  1036721666628444160   \n",
       "1    1036583587242549248   da  2018-09-03 21:03:14  1036721302692917250   \n",
       "2     899548260863488002   da  2017-08-21 12:10:42   899604671375052801   \n",
       "3     899548260863488002   da  2017-08-21 12:06:17   899603561323081729   \n",
       "4    1345496479583113217   da  2021-01-03 12:38:16  1345711074407014400   \n",
       "..                   ...  ...                  ...                  ...   \n",
       "295  1231494237130280966   da  2020-02-23 08:50:33  1231501587534827520   \n",
       "296  1414594602275901443   da  2021-07-12 14:39:33  1414595287532834818   \n",
       "297  1414594602275901443   da  2021-07-12 14:36:49  1414594602275901443   \n",
       "298  1198177606077734913   da  2019-11-23 10:25:50  1198185883821846530   \n",
       "299  1198177606077734913   da  2019-11-23 10:22:23  1198185017312186368   \n",
       "\n",
       "                                                  text           author_id  \\\n",
       "0    @frkomo Jeg siger det vel strengt taget bare t...          1666088336   \n",
       "1    @MonbergSF Sig det til spillerforeningen, som ...           148061237   \n",
       "2    @PeterHuggler Had alt det, du vil. Men du skal...           547416021   \n",
       "3    @brianweichardt Jeg hader den her slags: Du gå...          3301029597   \n",
       "4    @nielscallesoe @Heunicke Din første indvending...            87923613   \n",
       "..                                                 ...                 ...   \n",
       "295  @SteffenFrolund @MonbergSF @jonasholmdk Og præ...            97198778   \n",
       "296  @MVangby Er det for grundspillet, eller hele s...  805874425988087811   \n",
       "297  Min Superliga forudsigelse, her 1,5 måned inde...  835144095165202433   \n",
       "298  @steenHiversen @R4nd4hl @uffeelbaek @naserkhad...            26210681   \n",
       "299  @ammitzbollbille @R4nd4hl @uffeelbaek @naserkh...          2554415384   \n",
       "\n",
       "     replied_to_reply_count referenced_tweets_id in_reply_to_user_id  \\\n",
       "0                       1.0  1036721302692917250           148061237   \n",
       "1                       NaN                  NaN          1666088336   \n",
       "2                       1.0   899603561323081729          3301029597   \n",
       "3                       NaN                  NaN           547416021   \n",
       "4                       1.0  1345524516311748608            23341699   \n",
       "..                      ...                  ...                 ...   \n",
       "295                     NaN                  NaN            33859175   \n",
       "296                     2.0  1414594602275901443  835144095165202433   \n",
       "297                     NaN                  NaN                 NaN   \n",
       "298                     2.0  1198185017312186368          2554415384   \n",
       "299                     NaN                  NaN            26210681   \n",
       "\n",
       "            PNR  ...        tweeter_name  pair_num   type  like_n  retweet_n  \\\n",
       "0    1311570613  ...                 NaN         1  reply       1          0   \n",
       "1           NaN  ...     Sarah Agerklint         1  tweet       1          0   \n",
       "2    1405772015  ...                 NaN         2  reply       0          0   \n",
       "3           NaN  ...       Peter Huggler         2  tweet       1          0   \n",
       "4    0908801199  ...                 NaN         3  reply       1          0   \n",
       "..          ...  ...                 ...       ...    ...     ...        ...   \n",
       "295         NaN  ...         Lars Køhler       148  tweet       5          0   \n",
       "296         NaN  ...                 NaN       149  reply       1          0   \n",
       "297         NaN  ...       Mikkel Vangby       149  tweet      37          0   \n",
       "298  2010772527  ...                 NaN       150  reply       4          0   \n",
       "299         NaN  ...  Steen Holm Iversen       150  tweet       1          0   \n",
       "\n",
       "    quote_n  counterspeech_score  hate_score neutral_score counterspeech  \n",
       "0         0             0.765376    0.008536      0.226088            no  \n",
       "1         0             0.853204    0.006963      0.139833           yes  \n",
       "2         0             0.575550    0.030307      0.394142            no  \n",
       "3         0             0.616760    0.015232      0.368008            no  \n",
       "4         0             0.815085    0.017978      0.166937           yes  \n",
       "..      ...                  ...         ...           ...           ...  \n",
       "295       0             0.608624    0.046957      0.344419            no  \n",
       "296       0             0.812016    0.027733      0.160252           yes  \n",
       "297       0             0.868525    0.042197      0.089278           yes  \n",
       "298       0             0.710413    0.024398      0.265189            no  \n",
       "299       0             0.904418    0.030710      0.064872           yes  \n",
       "\n",
       "[300 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on test data\n",
    "\n",
    "from tqdm import tqdm\n",
    "pairs_test= pairs.head(300)\n",
    "\n",
    "# Candidate labels\n",
    "candidate_labels = ['counterspeech', 'hate', 'neutral tone']\n",
    "\n",
    "# List to store the scores\n",
    "counterspeech_scores = []\n",
    "hate_scores = []\n",
    "neutral_scores = []\n",
    "\n",
    "# Iterate over each text\n",
    "for text in (tqdm(pairs_test['text'], desc= \"Extracting scores\")) :\n",
    "    result = pipe_1(text, candidate_labels)\n",
    "    # Extract the scores\n",
    "    counterspeech_score = dict(zip(result['labels'], result['scores']))['counterspeech']\n",
    "    hate_score = dict(zip(result['labels'], result['scores']))['hate']\n",
    "    neutral_score = dict(zip(result['labels'], result['scores']))['neutral tone']\n",
    "    # Append the scores to the lists\n",
    "    counterspeech_scores.append(counterspeech_score)\n",
    "    hate_scores.append(hate_score)\n",
    "    neutral_scores.append(neutral_score)\n",
    "\n",
    "# Add the scores as a new column in the DataFrame\n",
    "pairs_test['counterspeech_score'] = counterspeech_scores\n",
    "pairs_test['hate_score'] = hate_scores\n",
    "pairs_test['neutral_score'] = neutral_scores\n",
    "\n",
    "\n",
    "# Initialize the 'counterspeech' column with 'NA'\n",
    "pairs_test['counterspeech'] = 'NA'\n",
    "\n",
    "# Update the 'counterspeech' column based on the 'counterspeech_score'\n",
    "for index, row in pairs_test.iterrows():\n",
    "    if row['counterspeech_score'] > 0.8:\n",
    "        pairs_test.at[index, 'counterspeech'] = 'yes'\n",
    "    else:\n",
    "        pairs_test.at[index, 'counterspeech'] = 'no'    \n",
    "\n",
    "\n",
    "pairs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21e4d2f9-a129-450d-9bee-2373d973c8f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting scores:   4%|▋                 | 797/20000 [07:40<3:05:01,  1.73it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Iterate over each text\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m (tqdm(pairs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m], desc\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting scores\u001b[39m\u001b[38;5;124m\"\u001b[39m)) :\n\u001b[0;32m---> 13\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Extract the scores\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     counterspeech_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m], result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m'\u001b[39m]))[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcounterspeech\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/zero_shot_classification.py:206\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline.__call__\u001b[0;34m(self, sequences, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to understand extra arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/base.py:1132\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ChunkPipeline):\n\u001b[0;32m-> 1132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1134\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   1135\u001b[0m                 [inputs], num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1136\u001b[0m             )\n\u001b[1;32m   1137\u001b[0m         )\n\u001b[1;32m   1138\u001b[0m     )\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:266\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[0;32m--> 266\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/base.py:1046\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1045\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1046\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1047\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/zero_shot_classification.py:229\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline._forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(model_forward)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    228\u001b[0m     model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcandidate_label\u001b[39m\u001b[38;5;124m\"\u001b[39m: candidate_label,\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m\"\u001b[39m: sequence,\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_last\u001b[39m\u001b[38;5;124m\"\u001b[39m: inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_last\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moutputs,\n\u001b[1;32m    236\u001b[0m }\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_outputs\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1539\u001b[0m, in \u001b[0;36mBartForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1535\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1536\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing input embeddings is currently not supported for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1537\u001b[0m     )\n\u001b[0;32m-> 1539\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1550\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1555\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# last hidden state\u001b[39;00m\n\u001b[1;32m   1557\u001b[0m eos_mask \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39meq(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39meos_token_id)\u001b[38;5;241m.\u001b[39mto(hidden_states\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1274\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1267\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1268\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1269\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1270\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1271\u001b[0m     )\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1274\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1132\u001b[0m, in \u001b[0;36mBartDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1121\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m   1122\u001b[0m         create_custom_forward(decoder_layer),\n\u001b[1;32m   1123\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1130\u001b[0m     )\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1145\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:427\u001b[0m, in \u001b[0;36mBartDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    425\u001b[0m self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;66;03m# add present self-attn cache to positions 1,2 of present_key_value tuple\u001b[39;00m\n\u001b[0;32m--> 427\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    435\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:291\u001b[0m, in \u001b[0;36mBartAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# Use the `embed_dim` from the config (stored in the class) rather than `hidden_state` because `attn_output` can be\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# partitioned across GPUs when using tensor-parallelism.\u001b[39;00m\n\u001b[1;32m    289\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(bsz, tgt_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim)\n\u001b[0;32m--> 291\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, attn_weights_reshaped, past_key_value\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#On full dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Candidate labels\n",
    "candidate_labels = ['counterspeech', 'hate', 'neutral tone']\n",
    "\n",
    "# List to store the scores\n",
    "counterspeech_scores = []\n",
    "hate_scores = []\n",
    "neutral_scores = []\n",
    "\n",
    "# Iterate over each text\n",
    "for text in (tqdm(pairs['text'], desc= \"Extracting scores\")) :\n",
    "    result = pipe_1(text, candidate_labels)\n",
    "    # Extract the scores\n",
    "    counterspeech_score = dict(zip(result['labels'], result['scores']))['counterspeech']\n",
    "    hate_score = dict(zip(result['labels'], result['scores']))['hate']\n",
    "    neutral_score = dict(zip(result['labels'], result['scores']))['neutral tone']\n",
    "    # Append the scores to the lists\n",
    "    counterspeech_scores.append(counterspeech_score)\n",
    "    hate_scores.append(hate_score)\n",
    "    neutral_scores.append(neutral_score)\n",
    "\n",
    "# Add the scores as a new column in the DataFrame\n",
    "pairs['counterspeech_score'] = counterspeech_scores\n",
    "pairs['hate_score'] = hate_scores\n",
    "pairs['neutral_score'] = neutral_scores\n",
    "\n",
    "\n",
    "# Initialize the 'counterspeech' column with 'NA'\n",
    "pairs['counterspeech'] = 'NA'\n",
    "\n",
    "# Update the 'counterspeech' column based on the 'counterspeech_score'\n",
    "for index, row in pairs.iterrows():\n",
    "    if row['counterspeech_score'] > 0.8:\n",
    "        pairs.at[index, 'counterspeech'] = 'yes'\n",
    "    else:\n",
    "        pairs.at[index, 'counterspeech'] = 'no'    \n",
    "\n",
    "\n",
    "pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bae2b9-af2c-412c-a3f4-354c50e2d4bd",
   "metadata": {},
   "source": [
    "### cross-encoder/nli-deberta-base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c886e215-449b-4120-a1a5-b0fc74a836bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "pipe_2 = pipeline(\"zero-shot-classification\", model=\"cross-encoder/nli-deberta-base\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d5ce268-9020-445c-8187-112f616f4dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'i see your point but i dont think it is very constructive',\n",
       " 'labels': ['counterspeech', 'neutral tone', 'hate'],\n",
       " 'scores': [0.5037503242492676, 0.4367963671684265, 0.05945330858230591]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_labels = ['counterspeech', 'hate', 'neutral tone']\n",
    "\n",
    "sequence_to_classify_1 = \"i see your point but i dont think it is very constructive\"\n",
    "sequence_to_classify_2 = \"jeg forstår hvad du mener, men din kommentar er ikke særlig konstruktiv\"\n",
    "\n",
    "\n",
    "pipe_2(sequence_to_classify_1, candidate_labels)\n",
    "\n",
    "#doesnt seem very good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f334dd-9dc0-4f54-8421-8e2af64c862f",
   "metadata": {},
   "source": [
    "### TarsClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b52b574f-177a-4f4c-91c8-0a66e30dea2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Flair in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.14.0)\n",
      "Requirement already satisfied: boto3>=1.20.27 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (1.34.151)\n",
      "Requirement already satisfied: conllu<5.0.0,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (4.5.3)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (1.2.14)\n",
      "Requirement already satisfied: ftfy>=6.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (6.2.0)\n",
      "Requirement already satisfied: gdown>=4.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (5.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (0.24.3)\n",
      "Requirement already satisfied: langdetect>=1.0.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (1.0.9)\n",
      "Requirement already satisfied: lxml>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (5.2.2)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (3.8.0)\n",
      "Requirement already satisfied: more-itertools>=8.13.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (10.3.0)\n",
      "Requirement already satisfied: mpld3>=0.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (0.5.10)\n",
      "Requirement already satisfied: pptree>=3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (2.8.2)\n",
      "Requirement already satisfied: pytorch-revgrad>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (0.2.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (2023.10.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (1.3.2)\n",
      "Requirement already satisfied: segtok>=1.5.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (1.5.11)\n",
      "Requirement already satisfied: sqlitedict>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (2.1.0)\n",
      "Requirement already satisfied: tabulate>=0.8.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (0.9.0)\n",
      "Requirement already satisfied: torch!=1.8,>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (2.1.0)\n",
      "Requirement already satisfied: tqdm>=4.63.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (4.66.1)\n",
      "Requirement already satisfied: transformer-smaller-training-vocab>=0.2.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (0.4.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.18.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->Flair) (4.43.3)\n",
      "Requirement already satisfied: wikipedia-api>=0.5.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (0.6.0)\n",
      "Requirement already satisfied: semver<4.0.0,>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (3.0.2)\n",
      "Requirement already satisfied: bioc<3.0.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Flair) (2.1)\n",
      "Requirement already satisfied: jsonlines>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from bioc<3.0.0,>=2.0.0->Flair) (4.0.0)\n",
      "Requirement already satisfied: intervaltree in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from bioc<3.0.0,>=2.0.0->Flair) (3.1.0)\n",
      "Requirement already satisfied: docopt in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from bioc<3.0.0,>=2.0.0->Flair) (0.6.2)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.151 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from boto3>=1.20.27->Flair) (1.34.151)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from boto3>=1.20.27->Flair) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from boto3>=1.20.27->Flair) (0.10.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from deprecated>=1.2.13->Flair) (1.16.0)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ftfy>=6.1.0->Flair) (0.2.13)\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gdown>=4.4.0->Flair) (4.12.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gdown>=4.4.0->Flair) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gdown>=4.4.0->Flair) (2.31.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.10.0->Flair) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.10.0->Flair) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.10.0->Flair) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.10.0->Flair) (4.8.0)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langdetect>=1.0.9->Flair) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=2.2.3->Flair) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=2.2.3->Flair) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=2.2.3->Flair) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=2.2.3->Flair) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=2.2.3->Flair) (1.23.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=2.2.3->Flair) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=2.2.3->Flair) (3.1.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from mpld3>=0.3->Flair) (3.1.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn>=1.0.2->Flair) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn>=1.0.2->Flair) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn>=1.0.2->Flair) (3.2.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch!=1.8,>=1.5.0->Flair) (1.12)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch!=1.8,>=1.5.0->Flair) (3.2.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers<5.0.0,>=4.18.0->transformers[sentencepiece]<5.0.0,>=4.18.0->Flair) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers<5.0.0,>=4.18.0->transformers[sentencepiece]<5.0.0,>=4.18.0->Flair) (0.19.1)\n",
      "Requirement already satisfied: protobuf in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->Flair) (4.25.3)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->Flair) (0.1.99)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.151->boto3>=1.20.27->Flair) (2.0.5)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonlines>=1.2.0->bioc<3.0.0,>=2.0.0->Flair) (23.1.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->Flair) (0.32.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from beautifulsoup4->gdown>=4.4.0->Flair) (2.5)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from intervaltree->bioc<3.0.0,>=2.0.0->Flair) (2.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->mpld3>=0.3->Flair) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests[socks]->gdown>=4.4.0->Flair) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests[socks]->gdown>=4.4.0->Flair) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests[socks]->gdown>=4.4.0->Flair) (2024.2.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests[socks]->gdown>=4.4.0->Flair) (1.7.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->torch!=1.8,>=1.5.0->Flair) (1.3.0)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate>=0.21.0->transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->Flair) (5.9.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3c44a42-ad48-4130-aded-23c3d4d9ffd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-31 11:17:34,459 TARS initialized without a task. You need to call .add_and_switch_to_new_task() before training this model\n",
      "2024-07-31 11:17:34,571 Provided `None` does not exist in the model. Consider calling `add_and_switch_to_new_task` first.\n",
      "2024-07-31 11:17:34,571 `ZeroShot` is the current task. Switch to some other task before dropping this.\n",
      "Sentence[7]: \"i understand, but i dont agree\"\n"
     ]
    }
   ],
   "source": [
    "from flair.models import TARSClassifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "\n",
    "tars = TARSClassifier.load('tars-base')\n",
    "\n",
    "\n",
    "sentence = Sentence(\"jeg forstår hvad du mener, men din kommentar er ikke særlig konstruktiv\")\n",
    "sentence_2 = Sentence(\"i understand, but i dont agree\")\n",
    "\n",
    "\n",
    "classes = [\"counterspeech\", \"hate\"]\n",
    "\n",
    "tars.predict_zero_shot(sentence_2, classes)\n",
    "\n",
    "print(sentence_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5472605a-9dc3-43a5-8c48-c7dbaf588d4d",
   "metadata": {},
   "source": [
    "## Applying classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41001fb-a2c0-4f50-bdef-6e73c907af93",
   "metadata": {},
   "source": [
    "#### Counterargument classifier (from huggingface)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d91fc1c-1de3-4701-ae3a-f4ba59f0fd72",
   "metadata": {},
   "source": [
    "https://huggingface.co/ThinkCERCA/counterargument_hugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ae78d56-c215-42b2-adc9-68a4f0850516",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_3 = pipeline(\"text-classification\", model=\"ThinkCERCA/counterargument_hugging\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2364ef87-95ef-4594-8841-894519cef7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'Not Counterargument', 'score': 0.6886796355247498}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gives labels: Not Counterargument or Counterargument with a score\n",
    "\n",
    "text = \"I understand, but actually you are incorrect. Science show that the earth is round\"\n",
    "text_2 = \"Jeg forstår din pointe, men den er ikke korrekt. Videnskaben viser at jorden er rund\"\n",
    "text_3 = \"your a fool\"\n",
    "text_4 = \"i like dogs, but also cats\"\n",
    "\n",
    "# Apply the pipeline to the text\n",
    "result = pipe_3(text_4)\n",
    "result\n",
    "\n",
    "#allright?\n",
    "#maybe test this on the test df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "108cc141-52d6-4a85-a435-e2c731da4455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting scores: 100%|██████████████████████| 300/300 [00:42<00:00,  7.03it/s]\n",
      "/var/folders/ds/0d9wxy210kx_fvknqn3hcg_h0000gn/T/ipykernel_15413/454167464.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pairs_test['label'] = labels\n",
      "/var/folders/ds/0d9wxy210kx_fvknqn3hcg_h0000gn/T/ipykernel_15413/454167464.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pairs_test['score'] = scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>replied_to_reply_count</th>\n",
       "      <th>referenced_tweets_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>PNR</th>\n",
       "      <th>...</th>\n",
       "      <th>type</th>\n",
       "      <th>like_n</th>\n",
       "      <th>retweet_n</th>\n",
       "      <th>quote_n</th>\n",
       "      <th>counterspeech_score</th>\n",
       "      <th>hate_score</th>\n",
       "      <th>neutral_score</th>\n",
       "      <th>counterspeech</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1036583587242549248</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-09-03 21:04:41</td>\n",
       "      <td>1036721666628444160</td>\n",
       "      <td>@frkomo Jeg siger det vel strengt taget bare t...</td>\n",
       "      <td>1666088336</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1036721302692917250</td>\n",
       "      <td>148061237</td>\n",
       "      <td>1311570613</td>\n",
       "      <td>...</td>\n",
       "      <td>reply</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.765376</td>\n",
       "      <td>0.008536</td>\n",
       "      <td>0.226088</td>\n",
       "      <td>no</td>\n",
       "      <td>Not Counterargument</td>\n",
       "      <td>0.635118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1036583587242549248</td>\n",
       "      <td>da</td>\n",
       "      <td>2018-09-03 21:03:14</td>\n",
       "      <td>1036721302692917250</td>\n",
       "      <td>@MonbergSF Sig det til spillerforeningen, som ...</td>\n",
       "      <td>148061237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1666088336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tweet</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.853204</td>\n",
       "      <td>0.006963</td>\n",
       "      <td>0.139833</td>\n",
       "      <td>yes</td>\n",
       "      <td>Counterargument</td>\n",
       "      <td>0.503948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>899548260863488002</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-08-21 12:10:42</td>\n",
       "      <td>899604671375052801</td>\n",
       "      <td>@PeterHuggler Had alt det, du vil. Men du skal...</td>\n",
       "      <td>547416021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>899603561323081729</td>\n",
       "      <td>3301029597</td>\n",
       "      <td>1405772015</td>\n",
       "      <td>...</td>\n",
       "      <td>reply</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.575550</td>\n",
       "      <td>0.030307</td>\n",
       "      <td>0.394142</td>\n",
       "      <td>no</td>\n",
       "      <td>Not Counterargument</td>\n",
       "      <td>0.648885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>899548260863488002</td>\n",
       "      <td>da</td>\n",
       "      <td>2017-08-21 12:06:17</td>\n",
       "      <td>899603561323081729</td>\n",
       "      <td>@brianweichardt Jeg hader den her slags: Du gå...</td>\n",
       "      <td>3301029597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>547416021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tweet</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.616760</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>0.368008</td>\n",
       "      <td>no</td>\n",
       "      <td>Not Counterargument</td>\n",
       "      <td>0.664990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1345496479583113217</td>\n",
       "      <td>da</td>\n",
       "      <td>2021-01-03 12:38:16</td>\n",
       "      <td>1345711074407014400</td>\n",
       "      <td>@nielscallesoe @Heunicke Din første indvending...</td>\n",
       "      <td>87923613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1345524516311748608</td>\n",
       "      <td>23341699</td>\n",
       "      <td>0908801199</td>\n",
       "      <td>...</td>\n",
       "      <td>reply</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.815085</td>\n",
       "      <td>0.017978</td>\n",
       "      <td>0.166937</td>\n",
       "      <td>yes</td>\n",
       "      <td>Not Counterargument</td>\n",
       "      <td>0.723273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1231494237130280966</td>\n",
       "      <td>da</td>\n",
       "      <td>2020-02-23 08:50:33</td>\n",
       "      <td>1231501587534827520</td>\n",
       "      <td>@SteffenFrolund @MonbergSF @jonasholmdk Og præ...</td>\n",
       "      <td>97198778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33859175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tweet</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.608624</td>\n",
       "      <td>0.046957</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>no</td>\n",
       "      <td>Not Counterargument</td>\n",
       "      <td>0.813830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1414594602275901443</td>\n",
       "      <td>da</td>\n",
       "      <td>2021-07-12 14:39:33</td>\n",
       "      <td>1414595287532834818</td>\n",
       "      <td>@MVangby Er det for grundspillet, eller hele s...</td>\n",
       "      <td>805874425988087811</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1414594602275901443</td>\n",
       "      <td>835144095165202433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>reply</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812016</td>\n",
       "      <td>0.027733</td>\n",
       "      <td>0.160252</td>\n",
       "      <td>yes</td>\n",
       "      <td>Not Counterargument</td>\n",
       "      <td>0.805045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1414594602275901443</td>\n",
       "      <td>da</td>\n",
       "      <td>2021-07-12 14:36:49</td>\n",
       "      <td>1414594602275901443</td>\n",
       "      <td>Min Superliga forudsigelse, her 1,5 måned inde...</td>\n",
       "      <td>835144095165202433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tweet</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.868525</td>\n",
       "      <td>0.042197</td>\n",
       "      <td>0.089278</td>\n",
       "      <td>yes</td>\n",
       "      <td>Not Counterargument</td>\n",
       "      <td>0.837815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1198177606077734913</td>\n",
       "      <td>da</td>\n",
       "      <td>2019-11-23 10:25:50</td>\n",
       "      <td>1198185883821846530</td>\n",
       "      <td>@steenHiversen @R4nd4hl @uffeelbaek @naserkhad...</td>\n",
       "      <td>26210681</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1198185017312186368</td>\n",
       "      <td>2554415384</td>\n",
       "      <td>2010772527</td>\n",
       "      <td>...</td>\n",
       "      <td>reply</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.710413</td>\n",
       "      <td>0.024398</td>\n",
       "      <td>0.265189</td>\n",
       "      <td>no</td>\n",
       "      <td>Not Counterargument</td>\n",
       "      <td>0.751263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1198177606077734913</td>\n",
       "      <td>da</td>\n",
       "      <td>2019-11-23 10:22:23</td>\n",
       "      <td>1198185017312186368</td>\n",
       "      <td>@ammitzbollbille @R4nd4hl @uffeelbaek @naserkh...</td>\n",
       "      <td>2554415384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26210681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tweet</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.904418</td>\n",
       "      <td>0.030710</td>\n",
       "      <td>0.064872</td>\n",
       "      <td>yes</td>\n",
       "      <td>Counterargument</td>\n",
       "      <td>0.595249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         conversation_id lang           created_at                   id  \\\n",
       "0    1036583587242549248   da  2018-09-03 21:04:41  1036721666628444160   \n",
       "1    1036583587242549248   da  2018-09-03 21:03:14  1036721302692917250   \n",
       "2     899548260863488002   da  2017-08-21 12:10:42   899604671375052801   \n",
       "3     899548260863488002   da  2017-08-21 12:06:17   899603561323081729   \n",
       "4    1345496479583113217   da  2021-01-03 12:38:16  1345711074407014400   \n",
       "..                   ...  ...                  ...                  ...   \n",
       "295  1231494237130280966   da  2020-02-23 08:50:33  1231501587534827520   \n",
       "296  1414594602275901443   da  2021-07-12 14:39:33  1414595287532834818   \n",
       "297  1414594602275901443   da  2021-07-12 14:36:49  1414594602275901443   \n",
       "298  1198177606077734913   da  2019-11-23 10:25:50  1198185883821846530   \n",
       "299  1198177606077734913   da  2019-11-23 10:22:23  1198185017312186368   \n",
       "\n",
       "                                                  text           author_id  \\\n",
       "0    @frkomo Jeg siger det vel strengt taget bare t...          1666088336   \n",
       "1    @MonbergSF Sig det til spillerforeningen, som ...           148061237   \n",
       "2    @PeterHuggler Had alt det, du vil. Men du skal...           547416021   \n",
       "3    @brianweichardt Jeg hader den her slags: Du gå...          3301029597   \n",
       "4    @nielscallesoe @Heunicke Din første indvending...            87923613   \n",
       "..                                                 ...                 ...   \n",
       "295  @SteffenFrolund @MonbergSF @jonasholmdk Og præ...            97198778   \n",
       "296  @MVangby Er det for grundspillet, eller hele s...  805874425988087811   \n",
       "297  Min Superliga forudsigelse, her 1,5 måned inde...  835144095165202433   \n",
       "298  @steenHiversen @R4nd4hl @uffeelbaek @naserkhad...            26210681   \n",
       "299  @ammitzbollbille @R4nd4hl @uffeelbaek @naserkh...          2554415384   \n",
       "\n",
       "     replied_to_reply_count referenced_tweets_id in_reply_to_user_id  \\\n",
       "0                       1.0  1036721302692917250           148061237   \n",
       "1                       NaN                  NaN          1666088336   \n",
       "2                       1.0   899603561323081729          3301029597   \n",
       "3                       NaN                  NaN           547416021   \n",
       "4                       1.0  1345524516311748608            23341699   \n",
       "..                      ...                  ...                 ...   \n",
       "295                     NaN                  NaN            33859175   \n",
       "296                     2.0  1414594602275901443  835144095165202433   \n",
       "297                     NaN                  NaN                 NaN   \n",
       "298                     2.0  1198185017312186368          2554415384   \n",
       "299                     NaN                  NaN            26210681   \n",
       "\n",
       "            PNR  ...   type  like_n  retweet_n  quote_n  counterspeech_score  \\\n",
       "0    1311570613  ...  reply       1          0        0             0.765376   \n",
       "1           NaN  ...  tweet       1          0        0             0.853204   \n",
       "2    1405772015  ...  reply       0          0        0             0.575550   \n",
       "3           NaN  ...  tweet       1          0        0             0.616760   \n",
       "4    0908801199  ...  reply       1          0        0             0.815085   \n",
       "..          ...  ...    ...     ...        ...      ...                  ...   \n",
       "295         NaN  ...  tweet       5          0        0             0.608624   \n",
       "296         NaN  ...  reply       1          0        0             0.812016   \n",
       "297         NaN  ...  tweet      37          0        0             0.868525   \n",
       "298  2010772527  ...  reply       4          0        0             0.710413   \n",
       "299         NaN  ...  tweet       1          0        0             0.904418   \n",
       "\n",
       "    hate_score  neutral_score  counterspeech                label     score  \n",
       "0     0.008536       0.226088             no  Not Counterargument  0.635118  \n",
       "1     0.006963       0.139833            yes      Counterargument  0.503948  \n",
       "2     0.030307       0.394142             no  Not Counterargument  0.648885  \n",
       "3     0.015232       0.368008             no  Not Counterargument  0.664990  \n",
       "4     0.017978       0.166937            yes  Not Counterargument  0.723273  \n",
       "..         ...            ...            ...                  ...       ...  \n",
       "295   0.046957       0.344419             no  Not Counterargument  0.813830  \n",
       "296   0.027733       0.160252            yes  Not Counterargument  0.805045  \n",
       "297   0.042197       0.089278            yes  Not Counterargument  0.837815  \n",
       "298   0.024398       0.265189             no  Not Counterargument  0.751263  \n",
       "299   0.030710       0.064872            yes      Counterargument  0.595249  \n",
       "\n",
       "[300 rows x 31 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test on small df\n",
    "\n",
    "# List to store the scores\n",
    "labels = []\n",
    "scores = []\n",
    "\n",
    "# Iterate over each text\n",
    "for text in (tqdm(pairs_test['text'], desc= \"Extracting scores\")) :\n",
    "    result = pipe_3(text)\n",
    "    # Extract the scores\n",
    "    label = result[0]['label']\n",
    "    score = result[0]['score']\n",
    "    # Append the scores to the lists\n",
    "    labels.append(label)\n",
    "    scores.append(score)\n",
    "\n",
    "# Add the scores as a new column in the DataFrame\n",
    "pairs_test['label'] = labels\n",
    "pairs_test['score'] = scores\n",
    "\n",
    "\n",
    "# Initialize the 'counterspeech' column with 'NA'\n",
    "#pairs_test['counterspeech'] = 'NA'\n",
    "\n",
    "# Update the 'counterspeech' column based on the 'counterspeech_score'\n",
    "#for index, row in pairs_test.iterrows():\n",
    "    #if row['counterspeech_score'] > 0.8:\n",
    "        #pairs_test.at[index, 'counterspeech'] = 'yes'\n",
    "    #else:\n",
    "        #pairs_test.at[index, 'counterspeech'] = 'no'    \n",
    "\n",
    "\n",
    "pairs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a04caad7-c05e-4034-8e7f-a2950ec8bace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Not Counterargument    235\n",
       "Counterargument         65\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check value counts\n",
    "pairs_test['label'].value_counts(dropna=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b4d4e25-378c-4d14-8d0d-ea1a38a98c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      @MonbergSF Sig det til spillerforeningen, som ...\n",
      "8      @larskohler @BEsbensen @PiaOlsen Lidt, men jeg...\n",
      "12     @quitte74 @BrondbyIF Skal jeg tage din med, nå...\n",
      "14     @HellaSchulin @dksvin @KopenhagenFurDK @spisek...\n",
      "17     @KWEkristian Ah, det er da et lidt tyndt svar,...\n",
      "                             ...                        \n",
      "276    @BrianMork @Noerloev @MagnusPharao @stinelinne...\n",
      "281    @MagnusPharao Min oplevelse er at disse sensat...\n",
      "285    @MonbergSF @PEF40 Øhhh derfor jeg spørger noge...\n",
      "293    Influencerne tror de har opfundet flow-TV http...\n",
      "299    @ammitzbollbille @R4nd4hl @uffeelbaek @naserkh...\n",
      "Name: text, Length: 65, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['@frkomo Jeg siger det vel strengt taget bare til dem der følger mig ;) Men hvis du følger den efterfølgende diskussion, så er jeg netop ikke imponeret over den tilgang spillerne har:)',\n",
       " '@PeterHuggler Had alt det, du vil. Men du skal ikke gøre dig til dommer over, hvad jeg mener er en naturlig reaktion. Jeg dækker overhovedet ikke den sag.',\n",
       " '@brianweichardt Jeg hader den her slags: Du går ind og gør dig selv til dommer, udfra et foto. Lad retten gøre sit arbejde, og søg alene at formidle sagen.',\n",
       " '@nielscallesoe @Heunicke Din første indvending er muligvis korrekt. Det skal vurderes. Den anden forstår jeg ikke. Hvilke andre vacciner tilbyder vi off-label?',\n",
       " '@stinuslindgreen @Heunicke I min optik, er det ikke en relevant bekymring. Flere grunde. Vigtigste: For det første, fordi vi ikke har skala til at gøre en forskel. HVIS det giver øget selektion i den retning, sker det uanset hvad vi gør. For det andet, undlader vi ikke andre vacciner med den begrundelse.',\n",
       " '@RasmusMalver @radikale Det er jeg ked af. Jeg vil gerne forstå din bekymring - det er derfor jeg svarer dig - men jeg har desværre lidt svært ved at følge dit ræsonnement. Der lyder som om, vi snakker forbi hinanden. Måske er det Twitter? Jeg ved det ikke men tager altid gerne en seriøs dialog.',\n",
       " 'Indtil for en time siden var @stinuslindgreen på min top 5 over folketingsmedlemmer. Han er ny i politik, men har virkelig lært at bullshitte. @Radikale påstod at der var domstolskontrol med adgang til private hjem. Det er der ikke. Se hvordan han prøver at skifte retning. #dkpol https://t.co/37odfP9Y3O',\n",
       " '@ThomasMonbergSF Vi løber vist i ring!... Ha en god dag og en go Pride!! ❤️💛💚💙💜 🙏 @BEsbensen @PiaOlsen',\n",
       " '@gastronautdk @peterbrodersen Vi opfatter nok bare debatten forskelligt. Jeg synes blot du understreger min pointe, selvom det næppe er din hensigt 🤷🏻\\u200d♀️',\n",
       " '@peterbrodersen Præcis ... Så tyndt indlæg fra @AnneFrostJepsen ... \"Du må ikke slå på politikerne selvom de dagligt slår\" \\nEn voksen kommunikation forudsætter et ønske fra politikerne om at agere voksent og mangler vi stadig at se 🙄',\n",
       " '@JanniMT @BrondbyIF Buk dig venligst lige ned, og saml så din sut op, tak.',\n",
       " '@HenrikDyhHansen @dksvin @KopenhagenFurDK @spisekammeret @MFVMin @MogensJensenS Hmm, nu er vores syn på branchens berettigelse jo forskellig. For mig svarer det til kompensation for at afvikle en slavefarm. Mit syn på etik understøttes endnu ikke af det nuværende system, det er jeg udmærket klar over, men det er svært for mig at forstå holdningerne til dyr.',\n",
       " '@adamwolfregion @SigneLoentoft Næææ det vidste jeg ikke, det jeg siger er bare, at lovlig vigtigt emne til dén type twitter-skænderier. Er nok heller ikke den direkte vej til mere sammenhæng/samarbejde. Og svaret på dit spørgsmål har vi vel iøvrigt forlængst givet ?🤔',\n",
       " '@Knud_brix @mortenskaerbaek Seriøs journalistik, enig. Påstanden er jo bare vanvittig, eftersom det netop er en påstand. Blandt alt for mange andre. Godt, den infantile adfærd udfordres. Men lad os bære over. Har læst, at hun kan lide Brøndby.',\n",
       " 'Når @mortenskaerbaek er i topform, er der langt til sokkeholderne. Der burde bare være lyd på dette interview \\nhttps://t.co/yHk4vB74m9',\n",
       " '@Nikolaj32LFC @EsbenSuurballe @ClarkJamesYNWA @larsmathiasen Det opsummerer det hele godt. Kald os bare gamle sure mænd, jeg vil kalde det rettidigt omhu. Håber inderligt, du får ret, men jeg ville kalde vores sportslige ledelse decideret naiv, hvis de planlægger på den slags forhåbninger. Der er alt for stor sandsynlighed for det går galt',\n",
       " '@AnAngelOfDeath Jeg følte, at jeg blev påduttet nogle holdninger jeg slet ikke havde, og det er næsten det der gør mig mest ked af det. Men så har jeg lært, at det er sådan maskinen fungerer, når pressen og andre partier lugter blod. Jeg vil gerne takke folk der holdt en saglig tone undervejs.',\n",
       " '@PruPruh @Kmoztar Haha, you’ve been catted. 😂.   Det er også helt i orden, at den kommer her og hænger ud. Bare den ikke flytter ind og forventer kattebakke og vådkost.',\n",
       " '@HorvatPedersen @twhjerne Synes til gengæld det lyder fedt, at det påvirker din adfærd som ven. Men igen, ærgerligt, hvis det drives af en usund grundfølelse. Jeg ved det ikke. Umulig snak, vi har igangsat her ;-)',\n",
       " '@HorvatPedersen @twhjerne Ha ha. Du må ikke undskylde. Fedt, når folk vil dele lidt ud af deres følelsesliv. Forstår helt, hvad du mener. Men man skal også stoppe op og forholde sig lidt kritisk til den præstationstrang... især ift. karriere. For er det egentlig “godt“ at tage de timer ekstra?']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at performance\n",
    "\n",
    "#pull up text examples\n",
    "Counterargument = pairs_test[pairs_test['label'] == 'Counterargument']\n",
    "no_Counterargument = pairs_test[pairs_test['label'] == 'Not Counterargument']\n",
    "\n",
    "\n",
    "print(Counterargument['text'][:100])\n",
    "\n",
    "# can print the whole text using\n",
    "text_to_print = Counterargument['text'].head(20).tolist()\n",
    "text_to_print\n",
    "\n",
    "text_to_print = no_Counterargument['text'].head(20).tolist()\n",
    "text_to_print\n",
    "\n",
    "#seems pretty good, not perfect though \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "016aa23e-ff6c-4d15-817b-ddd198a0ccf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@quitte74 @pferdinandsen Tusind tak, så har vi lidt at kigge på. Jeg ville selv have elsket de samme muligheder, men Basic på en Commodore 64 var nu heller ikke af vejen😉',\n",
       " '@KWEkristian Ah, det er da et lidt tyndt svar, når I selv har startet debatten - som du ved, har vi bestyrelsesmøde, så der bliver vist ikke megen regional deltagelse i den første del af jeres møde. @SigneLoentoft',\n",
       " '@quitte74 @PabloBresciani @ChrRothmann @stentoft01 @gratisbilletter @billetboers Jeg er vild med det man kan med kode, men har aldrig selv interesseret mig for hvordan det skal gøres. Så “vores” udvikler har lært at han enten skal sige “fint, det gør vi” eller “det kan du ikke få”, når jeg ønsker mig nye funktioner. Vi taler ikke længere om hvorfor 😂',\n",
       " '@Sklander89 @quitte74 Sklander for pokker. Du var selv direkte rasende over episoden, og nu beskylder du simpelthen mig for at lyve om det... 🤠 https://t.co/7GjV1bOVVO',\n",
       " '@JonasKGaba @alternativet_ @uffeelbaek Af de 7 påstande, vil jeg sige at 5 og 6 er forkerte påstande 100%, men de andre 5 har noget (nogle gange meget lidt) sandhed i sig. Spørg mig gerne skarpt 💚',\n",
       " '@lars_kunstmann @stinuslindgreen @mvinaes @maainsworth @KasperKepp @KT_Baek Men vel nemmere at forsøge at inddæmme og opspore med færre tilfælde end mange flere? Eller har vi på forhånd givet op med alt, hvad der kræver smitteopsporing?',\n",
       " '@RolfBjerre @alternativet_ @uffeelbaek Vil du henvise mig til forskning der understøtter dine udsagn? Så længe jeg ikke ser noget konkret forskning der er enig med dig, så føler jeg det er en debat mellem mine kilder, og din mavefornemmelse. Dette skal ikke tages som angreb, men nærmere som et ønske om at vide mere',\n",
       " '@quitte74 Det gør de tre nederste. I 1.Div mangler der også kun 2 kampe til alle har mødt hinanden 2 gange, 2.div er mere lakrids',\n",
       " '@JesperSimoni @lethan87 Eyy! Det er fandme lækkert at se @lethan87 😍',\n",
       " '@quitte74 @AarhusGinger Hvorfor er det til gavn for alle? Hvad gavner det? Og hvorfor er det vigtigt nu, når man kunne gå 4 uger helt uden undervisning under lockouten?',\n",
       " '@quitte74 @fodboldmajor Det gør mig sgu glad at høre. Min søn er et godt sted nu. Det er bare så trist at det skulle tage så mange år, især når man siden har fundet ud af at det sker systematisk pga sparehensyn i kommunerne. Det kan vi sgu ikke være bekendt over for vores børn',\n",
       " '@UFredsbo @benediktekiaer @Astridkrag Det gør det ikke mindre rigtigt',\n",
       " '@Sklander89 @quitte74 Jeg har ikke selv set den episode du henviser til, med vores fans. Men hvis vi har gjort noget tilsvarende, skal vi med i puljen. Det understøtter jo egentlig bare hvad jeg skriver.',\n",
       " '@quitte74 Har arvingen Brøndbykæresten med?\\n\\nVi stiller også op i stærkeste familieformation 💪🏻',\n",
       " '@quitte74 @Mikkelnw @laianders @LKarstenberg Sådan havde jeg det også FØR han kom til AGF. Men han er fed som fan.\\nDog vil jeg også mene, at et hold som AGF først har rykket sig spillemæssigt, når man kan undvære MS eller samme type.',\n",
       " '@kwillatzen @kenniamdiworm @BrondbyIF Jeg er bange for du har ret, men håber til det sidste',\n",
       " '@baretraet @OnkelCrack Rigtig tandlæge?',\n",
       " '@frausing @stinuslindgreen 3) Hvad siger de faglige selskaber til forslaget? Og hvilken læge er det som skal “godkende” evt alternativ behandling?',\n",
       " '@baretraet @PabloBresciani @ChrRothmann @stentoft01 @gratisbilletter @billetboers På job er jeg no 1 guy til at forklare IT til normale mennesker, men det kan godt være en udfordring :)',\n",
       " '@SimonSkibsted Haha kender alt for godt til den “er du blevet FCK’er” kommentar 😂 \\n\\nTænker tit, er Skov den eneste SIF’er jeg ikke er “sur” på for at skifte væk? Kan ikke huske jeg har jublet sådan over andre x-SIF’er(i superligaen vel og mærket)']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by 'score' in descending order\n",
    "sorted_df = Counterargument.sort_values('score', ascending=False)\n",
    "\n",
    "#print \n",
    "sorted_df['text'].head(20).tolist()\n",
    "#sorted_df[['text', 'score', 'label']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bc1c96-dd20-4118-bba8-79a6ce1edb46",
   "metadata": {},
   "source": [
    "#### Bert counterspeech classifier (from huggingface)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1efc216-4bc8-477c-adf7-d37d756af0f8",
   "metadata": {},
   "source": [
    "Bert finetuned on the CONAN dataset\n",
    "\n",
    "https://huggingface.co/tum-nlp/bert-counterspeech-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95b7641a-5898-4ead-b4bf-80446c9dc7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_4 = pipeline(\"text-classification\", model=\"tum-nlp/bert-counterspeech-classifier\",device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b39c35d9-cc2c-47ed-8ed1-7e28a757290b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'counter-argument', 'score': 0.8415255546569824}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I understand, but actually you are incorrect. Science show that the earth is round\"\n",
    "text_2 = \"Jeg forstår din pointe, men den er ikke korrekt. Videnskaben viser at jorden er rund\"\n",
    "text_3 = \"you are a fool\"\n",
    "\n",
    "# Apply the pipeline to the text\n",
    "result = pipe_4(text_3)\n",
    "result\n",
    "\n",
    "#Seems to work well on english data, not so good on danish data.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c931cf-1e34-4c49-a462-3fae1f9ee488",
   "metadata": {},
   "source": [
    "#### Counterspeech score classifier (from huggingface)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529a0242-35f3-4018-9732-4ccb21940773",
   "metadata": {},
   "source": [
    "https://huggingface.co/Hate-speech-CNERG/new-counterspeech-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9e5bc4e-db2d-45c5-ae50-0a8d2e036523",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_5 = pipeline(\"text-classification\", model=\"Hate-speech-CNERG/new-counterspeech-score\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9488b7ce-0d47-47ae-a7f8-c3dc2bfd4a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.7565722465515137}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I understand, but actually you are incorrect. Science show that the earth is round\"\n",
    "text_2 = \"Jeg forstår din pointe, men den er ikke korrekt. Videnskaben viser at jorden er rund\"\n",
    "text_3 = \"you are a fool\"\n",
    "\n",
    "# Apply the pipeline to the text\n",
    "result = pipe_5(text_3)\n",
    "result\n",
    "\n",
    "# What labels, and what are the scores, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "50f96c32-280c-4dd7-ab3b-cfaa29853a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting scores: 100%|██████████████████████| 300/300 [00:43<00:00,  6.84it/s]\n",
      "/var/folders/ds/0d9wxy210kx_fvknqn3hcg_h0000gn/T/ipykernel_15413/1298344427.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pairs_test['label_counter'] = labels_counter\n",
      "/var/folders/ds/0d9wxy210kx_fvknqn3hcg_h0000gn/T/ipykernel_15413/1298344427.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pairs_test['score_counter'] = scores_counter\n"
     ]
    }
   ],
   "source": [
    "# Test on small df\n",
    "\n",
    "# List to store the scores\n",
    "labels_counter = []\n",
    "scores_counter = []\n",
    "\n",
    "# Iterate over each text\n",
    "for text in (tqdm(pairs_test['text'], desc= \"Extracting scores\")) :\n",
    "    result = pipe_5(text)\n",
    "    # Extract the scores\n",
    "    label = result[0]['label']\n",
    "    score = result[0]['score']\n",
    "    # Append the scores to the lists\n",
    "    labels_counter.append(label)\n",
    "    scores_counter.append(score)\n",
    "\n",
    "# Add the scores as a new column in the DataFrame\n",
    "pairs_test['label_counter'] = labels_counter\n",
    "pairs_test['score_counter'] = scores_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "daa11c91-b830-4623-ace5-c0361bb813b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_counter\n",
       "POSITIVE    180\n",
       "NEGATIVE    120\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_test['label_counter'].value_counts(dropna=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "41b1ebd3-57a7-4ecd-b0da-552a9c0ea04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Min mors æblekage. Vi har prøvet at genlave den efter hun gik bort. Vi har hendes nedskrevne opskrift, men det smager bare ikke ens. Som hun nærmest har taget den med sig. Har I også sådan nogle retter/opskrifter i jeres familie?',\n",
       " '@olufsphere @AarhusGinger Vi som forældre har lidt hånd i hanke med hvad der er lavet / ikke er lavet + det samme med skolen. Det ser jeg som en ganske naturlig ting. \\n\\nJeg ved ikke hvorfor du vil blande den lockout ind i det her. jeg forholder mig udelukkende til den nuværende situation.',\n",
       " 'For præcis elleve år siden kom jeg til København som håbefuld studerende (og aspirerende fodboldtræner).\\n\\nMeget er sket siden, men når jeg ser det her billede fra dengang, tænker jeg stadig:\\n\\n\"Tænk, at en tysker kan have så meget charme, selvtillid og lækkert hår.\" https://t.co/aljCMBxZgu',\n",
       " '@PiaOlsen det respektere jeg 100%. Flot du tager dig tid til dialogen, politisk bliver vi nok ikke enige,men respekt for politisk engagement',\n",
       " '@lauralindahl Det er det jeg siger. Du agerer forståeligt nok offentligt i denne sag som den karrierebevidste holdspiller. Men derved blåstempler du også din partifælles generelle virke. Jeg vidste ikke at du var så uambitiøs. Historien vil understøtte min kritik den dag hun er stoppet.',\n",
       " '@BananaSven Tager du mange afslutninger med lav xG eller tager du få med høj er udtrykket for kvalitet i denne sammenhæng.\\nVil man måle kvaliteten i selve afslutningen bør man benytte xGOT.',\n",
       " '@SikandaSIDDIQUE @friegronne @MogensJensenS \"... (det kræver, red) dyb og grundlæggende forandring, hvis vi skal redde vores samfund, som vi kender det.\"\\n\\nØhhh.... hvis noget forandres grundlæggende, er det vel ikke, som vi kender det? Siger det bare 😉\\n\\nForholder mig ikke til ideologien - men blot formuleringen 😉\\n\\n#dkpol',\n",
       " '@ibeneser Fandt hende med dette.\\nVed slet ikke, om du er til den slags, men det kan jo testes!\\nJeg synes hendes energi smitter. https://t.co/IfRyxFGmsa',\n",
       " '@PaulaLarrain1 @cekicozlem Jeg er ikke vred på dig. Men jeg bliver skuffet hvis nogen begynder at belære mig om dialog når det sådan set er det jeg har lavet i mange år, jeg bruger min pen, ikke sværdet. Dét er da i den grad dialog. Men aldrig med nogen der vil udslette os, vel? Ikke mig. \\nAlt godt.',\n",
       " '@ammitzbollbille @andersdalsager @ppkzd @ammitzbollbille mener du da, at demokratiske lande er fejlfrie?\\n@ppkzd beskriver, som jeg læser det, begge vinkler. At både diktatur og den voldsomme dominanspolitik fra bl.a. USA, er det vi ser konsekvensen af.',\n",
       " '@kl_cker @twhjerne @STPS_DK Tak for svaret. Det er ikke hjemme hos os selv, men flere familier i min piges klasse, hvor børnene kommer i skole med den baggrund. Jeg har ikke tænkt mig at tage konflikten, det orker jeg ikke, men jeg var i tvivl, selvom jeg egentlig læser reglerne netop som du fortæller.',\n",
       " 'Alle jer, der håner forældre for deres “curlingbørn”: Jeg tror, at I er typerne, der holder hån mod andre i live. Bliver børn opdraget med hån, spot og intolerance, er det sådan de opfører sig som voksne. Curlingbørn som voksne har jeg mere fidus til. \\n\\nOg ananas på pizza er ok..',\n",
       " '@annette_benette @andersdalsager @ppkzd Nej, det mener jeg ikke. Demokrati er dem mindst ringe styreform. Men jeg er intolerant over for situationer, hvor man ikke entydigt tager afstand fra diktaturet og bliver ulden. Cuba er er diktatur punktum. Når folket rejser os, holder vi med folket.',\n",
       " '@MVangby Fair nok. \\nJeg kan kun sige, jeg forstår, folk reagerer, når der bliver lavet sjov på deres bekostning. Det tillader ikke urimelige reaktioner, men det er et problem, hvis vi devaluerer anken om urimelige reaktioner, når vi kalder alm. banter svar for en urimelig reaktion.',\n",
       " '@smoelle Ok det var med den undertone :-)\\nHvad angår A11, så er jeg nok ikke enig med dig, men skal vi ikke lade den ligge, og bare nyde solen 🌞\\nEnjoy!',\n",
       " '@larsloekke Enig. Lad os aldrig glemme. Men det er ikke nok, Lars. Du må både som statsminister og som statsministerkandidat slå fast at et parti med netop nazistisk ideologi aldrig kan blive parlamentarisk grundlag for din regering. Vi har som land brug for den udmelding fra din side #dkpol',\n",
       " '@GludEva @frausing Jeg forstår umiddelbart godt din betænkelighed, @GludEva, og detaljerne er ikke klar. Inspirationen er Norge, hvor en alternativ behandler ikke kan tilbyde behandling til alvorligt syge mennesker uden lægens kendskab. Det virker klogt, men vi skal lære af deres erfaringer.',\n",
       " '@SimonVind Håber det. Men jeg er fortsat forundret over, hvor hurtigt vi gik fra \"hvis ikke vi også ansætter en dygtig DoF, kan det være ligegyldigt at hente Klopp\" til \"Edwards er verdens bedste\".\\n\\nEnten var han hele tiden det og Rodgers virkelig dårlig, ellers gør Klopp alt til guld.',\n",
       " '@RasmusMalver @radikale Det er jeg ked af. Jeg vil gerne forstå din bekymring - det er derfor jeg svarer dig - men jeg har desværre lidt svært ved at følge dit ræsonnement. Der lyder som om, vi snakker forbi hinanden. Måske er det Twitter? Jeg ved det ikke men tager altid gerne en seriøs dialog.',\n",
       " '@MMolsted Handler det ikke også om konkurrencevilkår? Hvis der kommer lige bundvilkår i EU (eller, gerne globalt), vil det være en fordel for alle de mange andre virksomheder, der skal betale retmæssig skat.']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = pairs_test[pairs_test['label_counter'] == 'POSITIVE']\n",
    "\n",
    "\n",
    "# Sort by 'score' in descending order\n",
    "sorted_df = positive.sort_values('score', ascending=False)\n",
    "\n",
    "#print \n",
    "sorted_df['text'].head(20).tolist()\n",
    "#sorted_df[['text', 'score_counter', 'label_counter']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4237244a-540c-463a-972e-b37dd6da3e0e",
   "metadata": {},
   "source": [
    "## Applying hate classification model(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50b6a99-6187-4378-8b6c-fc8dbca69248",
   "metadata": {},
   "source": [
    "### HateXplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5991c64-d84d-4f6a-98aa-d9a21649f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gives hate, offensive and normal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3df8650f-08cd-4392-abbf-f4dcb17e8b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3dd8e243ff46fb9a44405367cb06f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee0b03de1a543cbb3941c8cd5bae210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b800315269d44ccb08addde85c79d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/40.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed987da953340598bb3c1084d05c245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8a6c55cb3748b0af6e6ad8f595544e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "pipe_6 = pipeline(\"text-classification\", model=\"Hate-speech-CNERG/bert-base-uncased-hatexplain\", device= 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4f266e10-0f01-4338-88da-ec917c5bda01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'normal', 'score': 0.7060950398445129}]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I understand, but actually you are incorrect. Science show that the earth is round\"\n",
    "text_2 = \"Jeg forstår din pointe, men den er ikke korrekt. Videnskaben viser at jorden er rund\"\n",
    "text_3 = \"you cute dog\"\n",
    "text_4 = 'du er så tyk og grim'\n",
    "\n",
    "# Apply the pipeline to the text\n",
    "result = pipe_6(text_4)\n",
    "result\n",
    "\n",
    "#not so good on danish data?\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45538c6-c1c2-459e-8ddd-83fd633c14a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58e4c71c-4fb8-47f3-96da-0ca84646b549",
   "metadata": {},
   "source": [
    "### Hate Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ec0b477e-a705-4166-92ad-661cc8ea237a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead19c5d4dc248b7927789262f8806a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60dd6c0dfa934439ada7488af6a1a9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fdb5bc6793744aea433a11e8e048dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/151 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c313df385f4576875b44a8a806c42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29e43c5ab104cc2a5a7ee291013dd74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe_7 = pipeline(\"fill-mask\", model=\"GroNLP/hateBERT\", device= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b53b8a20-91f2-4877-8dea-ab41e55cc7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: tensor([[0.4175, 0.5825]])\n",
      "Predicted label: 1\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/hateBERT\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"GroNLP/hateBERT\")\n",
    "\n",
    "# Example text\n",
    "text = \"i do not hate you\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get the predicted probabilities\n",
    "probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Probabilities: {probabilities}\")\n",
    "\n",
    "# Get the predicted label\n",
    "predicted_label = torch.argmax(probabilities, dim=1).item()\n",
    "print(f\"Predicted label: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "05e637a2-2dca-4003-9b23-b17fa1b8a6f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "PipelineException",
     "evalue": "No mask_token ([MASK]) found on the input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPipelineException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m text_3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou are a fool\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Apply the pipeline to the text\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpipe_6\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/fill_mask.py:270\u001b[0m, in \u001b[0;36mFillMaskPipeline.__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    249\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m    Fill the masked token in the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03m        - **token_str** (`str`) -- The predicted token (to replace the masked one).\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/base.py:1254\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1247\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1248\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1251\u001b[0m         )\n\u001b[1;32m   1252\u001b[0m     )\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/base.py:1260\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m-> 1260\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[1;32m   1262\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/fill_mask.py:123\u001b[0m, in \u001b[0;36mFillMaskPipeline.preprocess\u001b[0;34m(self, inputs, return_tensors, tokenizer_kwargs, **preprocess_parameters)\u001b[0m\n\u001b[1;32m    120\u001b[0m     tokenizer_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(inputs, return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_kwargs)\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mensure_exactly_one_mask_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_inputs\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/fill_mask.py:112\u001b[0m, in \u001b[0;36mFillMaskPipeline.ensure_exactly_one_mask_token\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m input_ids \u001b[38;5;129;01min\u001b[39;00m model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 112\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_exactly_one_mask_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/fill_mask.py:100\u001b[0m, in \u001b[0;36mFillMaskPipeline._ensure_exactly_one_mask_token\u001b[0;34m(self, input_ids)\u001b[0m\n\u001b[1;32m     98\u001b[0m numel \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mprod(masked_index\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numel \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineException(\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfill-mask\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mbase_model_prefix,\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo mask_token (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mmask_token\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) found on the input\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    104\u001b[0m     )\n",
      "\u001b[0;31mPipelineException\u001b[0m: No mask_token ([MASK]) found on the input"
     ]
    }
   ],
   "source": [
    "text = \"I understand, but actually you are incorrect. Science show that the earth is round\"\n",
    "text_2 = \"Jeg forstår din pointe, men den er ikke korrekt. Videnskaben viser at jorden er rund\"\n",
    "text_3 = \"you are a fool\"\n",
    "\n",
    "# Apply the pipeline to the text\n",
    "result = pipe_6(text_3)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f0341a-91e8-4b81-84c8-ab7c7810d338",
   "metadata": {},
   "source": [
    "## Finetuning a model on labeled counterspeech data (CONAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927b5846-f259-440b-a3f4-f9d74968b35a",
   "metadata": {},
   "source": [
    "CONAN (COunter NArratives through Nichesourcing): A dataset containing counterspeech responses to hate speech. Data is French, italian and English\n",
    "\n",
    "https://github.com/marcoguerini/CONAN\n",
    "\n",
    "https://aclanthology.org/P19-1271.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7773ee46-b175-4d8f-8a21-dced07b91308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3071614-06c4-4689-89ca-59e2e910a27a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "599292e4-61f8-4d1f-a6b0-8c5ebc2176fd",
   "metadata": {},
   "source": [
    "## Applying the jigsaw perspective API\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
