{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb5835ba-dffa-471f-b0d8-d81f0fe3027c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.8.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.23.5)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.13.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.3.2)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.1.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.66.5)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.44.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.24.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# packages needed (listed in requirenments file)\n",
    "\n",
    "!pip3 install matplotlib numpy pandas seaborn scikit-learn torch tqdm transformers"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f750c674-4b26-425f-96eb-03b2154c8000",
   "metadata": {},
   "source": [
    "Info of data: \n",
    "\n",
    "Train csv: 5184 rows (80%)\n",
    "Test csv: 1296 rows (20%)\n",
    "6480 rows in total\n",
    "\n",
    "When testing the script reduce sample: \n",
    "5184/6 = 864\n",
    "1296/6 = 216 \n",
    "\n",
    "Further tesing on main_4 and main_6 that crashes:\n",
    "5184/18=288\n",
    "1296/18= 72\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4f82d9-d1ad-4ecf-addb-dc221a7af71d",
   "metadata": {},
   "source": [
    "# Model without reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e3a9ac3-b5fd-4860-b6d0-b1524df72dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the 01_model_without_reference with the original model \n",
    "# Current code is working \n",
    "\n",
    "\"\"\"\n",
    "==============================\n",
    "Model Training - No Reference\n",
    "==============================\n",
    "This script takes our cleaned twitter data and builds a pipeline to fine-tune a BERT which can classify the tweet into its 3 labels classes. \n",
    "\n",
    "The label classes are as follows: \n",
    "Type (3 labels): Antagonizing, Other political statement, Unclassifiable\n",
    "Tone Hateful (3 labels):  Hateful, Not Hateful, Unclassifiable Hateful \n",
    "Tone Constructive (3 labels): Constructive, Not Constructive, Unclassifiable Constructive\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Data processing \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Modelling \n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    ==================\n",
    "    ----- Set Up -----\n",
    "    ==================\n",
    "    \"\"\"\n",
    "    # -- Parameters -- \n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') # Change model here if desired\n",
    "    batch_size = 16 # Small batch number for processing, can increase if using GPU\n",
    "    num_labels = 12\n",
    "\n",
    "    # Load Data \n",
    "    train_data = pd.read_csv(\"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/Data/train/train_data_no_ref.csv\").head(864) #smaller sample for testing\n",
    "    test_data = pd.read_csv(\"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/Data/test/test_data_no_ref.csv\").head(216)\n",
    "\n",
    "    # -- Classes -- \n",
    "    class TextDataset(Dataset):\n",
    "        # initialise the text, labels, the chosen tokenizer (BERT) and set the maximum length to BERT's max (512)\n",
    "        def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "            self.texts = texts\n",
    "            self.labels = labels\n",
    "            self.tokenizer = tokenizer\n",
    "            self.max_length = max_length\n",
    "\n",
    "        # Return the total number of instances in the dataset (i.e., the number of rows)\n",
    "        def __len__(self):\n",
    "            return len(self.texts)\n",
    "\n",
    "        # Take the text and labels as indexes, and return a dictonary of the tokenised text and its corresponding label \n",
    "        def __getitem__(self, idx):\n",
    "            text = self.texts[idx]\n",
    "            label = self.labels[idx]\n",
    "            encodings = self.tokenizer.encode_plus(\n",
    "                text,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            return {\"input_ids\": encodings[\"input_ids\"][0], \"attention_mask\": encodings[\"attention_mask\"][0], \"labels\": torch.tensor(label, dtype=torch.float)}\n",
    "\n",
    "    \"\"\"\n",
    "    ==================\n",
    "    ----- Model -----\n",
    "    ==================\n",
    "    \"\"\"\n",
    "    # -- Define labels -- \n",
    "    mlb = MultiLabelBinarizer(classes=['Antagonizing', 'Other political statement', 'Unclassifiable', 'Hateful', 'Not Hateful', 'Unclassifiable Hateful', 'Constructive', 'Not Constructive','Unclassifiable Constructive', 'Agree', 'Disagree', 'Unclear'])\n",
    "                                   \n",
    "    train_labels = mlb.fit_transform(train_data[['rep_type', 'rep_hateful', 'rep_constructive', 'rep_agree']].values)\n",
    "    test_labels = mlb.transform(test_data[['rep_type', 'rep_hateful', 'rep_constructive', 'rep_agree']].values)\n",
    "\n",
    "    # -- Create datasets -- \n",
    "    train_dataset = TextDataset(train_data['rep_text'].tolist(), train_labels, tokenizer, max_length=512)\n",
    "    test_dataset = TextDataset(test_data['rep_text'].tolist(), test_labels, tokenizer, max_length=512)\n",
    "\n",
    "    # create train and test dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # -- Set the optimizer, loss function and learning rate -- \n",
    "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "    # -- Training model -- \n",
    "    def train(model, dataloader, criterion, optimizer, device):\n",
    "        model.train()\n",
    "        model.to(device)\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        return avg_loss\n",
    "    \n",
    "    # -- Evaluate Function -- \n",
    "    def evaluate(model, dataloader, criterion, device):\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        total_loss = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "\n",
    "                loss = criterion(logits, labels)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                preds = (logits.sigmoid() > 0.5).cpu().numpy()\n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "        return avg_loss, np.array(all_labels), np.array(all_preds)\n",
    "\n",
    "    \"\"\"\n",
    "    ======================\n",
    "    ----- Test model -----\n",
    "    ======================\n",
    "    \"\"\"\n",
    "    #  -- Call device --\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # -- Setup saving parameters -- \n",
    "    num_epochs = 1\n",
    "    output_dir = \"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/output/model_without_reference/\"\n",
    "    epoch_no = 0 \n",
    "\n",
    "    # Define a path to save the model checkpoints\n",
    "    checkpoint_dir = \"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/output/model_without_reference/checkpoints/\"\n",
    "\n",
    "    # Define the model checkpoint file format (e.g., \"model_epoch_{epoch}.pt\")\n",
    "    checkpoint_filename = \"model_epoch_{epoch}.pt\"\n",
    "\n",
    "    # Define the label classes\n",
    "    label_classes = {\n",
    "        'rep_type': ['Antagonizing', 'Other political statement', 'Unclassifiable'],\n",
    "        'rep_constructive': ['Constructive', 'Not Constructive', 'Unclassifiable Constructive'],\n",
    "        'rep_hateful': ['Hateful', 'Not Hateful', 'Unclassifiable Hateful'],\n",
    "        'rep_agree': ['Agree', 'Disagree', 'Unclear']\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Free up memory by deleting variables\n",
    "        epoch_no = epoch_no + 1\n",
    "        print(f\"Epoch {epoch_no}:\")\n",
    "\n",
    "        # -- Train model -- \n",
    "        train_loss = train(model, train_dataloader, criterion, optimizer, device)\n",
    "        print(f\"Train Loss: {train_loss}\")\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = checkpoint_dir + checkpoint_filename.format(epoch=epoch_no)\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "        # -- Test model -- \n",
    "        test_loss, test_true_labels, test_pred_labels = evaluate(model, test_dataloader, criterion, device)\n",
    "        print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "        # Convert output from one hot encoding \n",
    "        true_labels = np.array(test_true_labels)\n",
    "        pred_labels = np.array(test_pred_labels)\n",
    "\n",
    "        # Generate confusion matrix\n",
    "        for class_name, labels in label_classes.items():\n",
    "            # Get indices corresponding to labels in this class\n",
    "            indices = [i for i, label in enumerate(mlb.classes_) if label in labels]\n",
    "            \n",
    "            # Extract true and predicted values for this class\n",
    "            class_true = np.argmax(true_labels[:, indices], axis=1)\n",
    "            class_pred = np.argmax(pred_labels[:, indices], axis=1)\n",
    "            \n",
    "            # Compute the confusion matrix\n",
    "            matrix = confusion_matrix(class_true, class_pred)\n",
    "\n",
    "            # Save or visualize the confusion matrix\n",
    "            plt.figure(figsize=(10,10))\n",
    "            sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=labels,\n",
    "                    yticklabels=labels)\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('Actual')\n",
    "            plt.title(f'Confusion Matrix for {class_name}')\n",
    "            plt.savefig(f'{output_dir}confusion_matrix_{class_name}.png')\n",
    "            plt.close()\n",
    "\n",
    "        # Generate report \n",
    "        report = classification_report(test_true_labels, test_pred_labels, target_names=mlb.classes_, output_dict=True)\n",
    "        report_name = output_dir + \"classification_report_\" + str(epoch_no) + \".txt\"\n",
    "\n",
    "        with open(report_name, \"w\") as f:\n",
    "            f.write(classification_report(test_true_labels, test_pred_labels, target_names=mlb.classes_))\n",
    "        \n",
    "        # Print results \n",
    "        #print(f\"Epoch {epoch+1}:\")\n",
    "        print(f\"  Train Loss = {train_loss:.4f}\")\n",
    "        print(f\"  Test Loss = {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050e17b0-fb00-4a3a-bf76-968212b3bed8",
   "metadata": {},
   "source": [
    "Note to self: there are 5184 texts in the training data: train_data_no_ref.csv, and depeding on the batch size, the number of batches pr epoch (number displayed in the tqdm when training the model) will change (e.g. 16 batches will be 324 because 5184/16= 324)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c249fa06-9612-44d3-82ac-c855351484b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████| 54/54 [17:19<00:00, 19.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.539757353288156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████| 14/14 [00:42<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4816723210471017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss = 0.5398\n",
      "  Test Loss = 0.4817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "main()\n",
    "\n",
    "#approx. 18 min to run (1 epoch, 1/6 of the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2294e113-0734-48fc-859e-ae0d7cfc8e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the 01_model_without_reference with a new model (XLM-Roberta)\n",
    "# Current code is working \n",
    "\n",
    "\"\"\"\n",
    "==============================\n",
    "Model Training - No Reference\n",
    "==============================\n",
    "This script takes our cleaned twitter data and builds a pipeline to fine-tune a BERT which can classify the tweet into its 3 labels classes. \n",
    "\n",
    "The label classes are as follows: \n",
    "Type (3 labels): Antagonizing, Other political statement, Unclassifiable\n",
    "Tone Hateful (3 labels):  Hateful, Not Hateful, Unclassifiable Hateful \n",
    "Tone Constructive (3 labels): Constructive, Not Constructive, Unclassifiable Constructive\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Data processing \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Modelling \n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification #new ones\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "def main_2():\n",
    "    \"\"\"\n",
    "    ==================\n",
    "    ----- Set Up -----\n",
    "    ==================\n",
    "    \"\"\"\n",
    "    # -- Parameters -- \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-large\") # Change model here if desired\n",
    "    batch_size = 16 # Small batch number for processing, can increase if using GPU\n",
    "    num_labels = 12\n",
    "\n",
    "    # Load Data \n",
    "    train_data = pd.read_csv(\"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/Data/train/train_data_no_ref.csv\").head(864) #smaller sample for testing\n",
    "    test_data = pd.read_csv(\"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/Data/test/test_data_no_ref.csv\").head(216)\n",
    "\n",
    "    # -- Classes -- \n",
    "    class TextDataset(Dataset):\n",
    "        # initialise the text, labels, the chosen tokenizer (BERT) and set the maximum length to BERT's max (512)\n",
    "        def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "            self.texts = texts\n",
    "            self.labels = labels\n",
    "            self.tokenizer = tokenizer\n",
    "            self.max_length = max_length\n",
    "\n",
    "        # Return the total number of instances in the dataset (i.e., the number of rows)\n",
    "        def __len__(self):\n",
    "            return len(self.texts)\n",
    "\n",
    "        # Take the text and labels as indexes, and return a dictonary of the tokenised text and its corresponding label \n",
    "        def __getitem__(self, idx):\n",
    "            text = self.texts[idx]\n",
    "            label = self.labels[idx]\n",
    "            encodings = self.tokenizer.encode_plus(\n",
    "                text,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            return {\"input_ids\": encodings[\"input_ids\"][0], \"attention_mask\": encodings[\"attention_mask\"][0], \"labels\": torch.tensor(label, dtype=torch.float)}\n",
    "\n",
    "    \"\"\"\n",
    "    ==================\n",
    "    ----- Model -----\n",
    "    ==================\n",
    "    \"\"\"\n",
    "    # -- Define labels -- \n",
    "    mlb = MultiLabelBinarizer(classes=['Antagonizing', 'Other political statement', 'Unclassifiable', 'Hateful', 'Not Hateful', 'Unclassifiable Hateful', 'Constructive', 'Not Constructive','Unclassifiable Constructive', 'Agree', 'Disagree', 'Unclear'])\n",
    "                                   \n",
    "    train_labels = mlb.fit_transform(train_data[['rep_type', 'rep_hateful', 'rep_constructive', 'rep_agree']].values)\n",
    "    test_labels = mlb.transform(test_data[['rep_type', 'rep_hateful', 'rep_constructive', 'rep_agree']].values)\n",
    "\n",
    "    # -- Create datasets -- \n",
    "    train_dataset = TextDataset(train_data['rep_text'].tolist(), train_labels, tokenizer, max_length=512)\n",
    "    test_dataset = TextDataset(test_data['rep_text'].tolist(), test_labels, tokenizer, max_length=512)\n",
    "\n",
    "    # create train and test dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # -- Set the optimizer, loss function and learning rate -- \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"xlm-roberta-large\", num_labels=num_labels)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "    # -- Training model -- \n",
    "    def train(model, dataloader, criterion, optimizer, device):\n",
    "        model.train()\n",
    "        model.to(device)\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        return avg_loss\n",
    "    \n",
    "    # -- Evaluate Function -- \n",
    "    def evaluate(model, dataloader, criterion, device):\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        total_loss = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "\n",
    "                loss = criterion(logits, labels)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                preds = (logits.sigmoid() > 0.5).cpu().numpy()\n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "        return avg_loss, np.array(all_labels), np.array(all_preds)\n",
    "\n",
    "    \"\"\"\n",
    "    ======================\n",
    "    ----- Test model -----\n",
    "    ======================\n",
    "    \"\"\"\n",
    "    #  -- Call device --\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # -- Setup saving parameters -- \n",
    "    num_epochs = 1\n",
    "    output_dir = \"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/output/model_without_reference_new/\"\n",
    "    epoch_no = 0 \n",
    "\n",
    "    # Define a path to save the model checkpoints\n",
    "    checkpoint_dir = \"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/output/model_without_reference_new/checkpoints/\"\n",
    "\n",
    "    # Define the model checkpoint file format (e.g., \"model_epoch_{epoch}.pt\")\n",
    "    checkpoint_filename = \"model_epoch_{epoch}.pt\"\n",
    "\n",
    "    # Define the label classes\n",
    "    label_classes = {\n",
    "        'rep_type': ['Antagonizing', 'Other political statement', 'Unclassifiable'],\n",
    "        'rep_constructive': ['Constructive', 'Not Constructive', 'Unclassifiable Constructive'],\n",
    "        'rep_hateful': ['Hateful', 'Not Hateful', 'Unclassifiable Hateful'],\n",
    "        'rep_agree': ['Agree', 'Disagree', 'Unclear']\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Free up memory by deleting variables\n",
    "        epoch_no = epoch_no + 1\n",
    "        print(f\"Epoch {epoch_no}:\")\n",
    "\n",
    "        # -- Train model -- \n",
    "        train_loss = train(model, train_dataloader, criterion, optimizer, device)\n",
    "        print(f\"Train Loss: {train_loss}\")\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = checkpoint_dir + checkpoint_filename.format(epoch=epoch_no)\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "        # -- Test model -- \n",
    "        test_loss, test_true_labels, test_pred_labels = evaluate(model, test_dataloader, criterion, device)\n",
    "        print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "        # Convert output from one hot encoding \n",
    "        true_labels = np.array(test_true_labels)\n",
    "        pred_labels = np.array(test_pred_labels)\n",
    "\n",
    "        # Generate confusion matrix\n",
    "        for class_name, labels in label_classes.items():\n",
    "            # Get indices corresponding to labels in this class\n",
    "            indices = [i for i, label in enumerate(mlb.classes_) if label in labels]\n",
    "            \n",
    "            # Extract true and predicted values for this class\n",
    "            class_true = np.argmax(true_labels[:, indices], axis=1)\n",
    "            class_pred = np.argmax(pred_labels[:, indices], axis=1)\n",
    "            \n",
    "            # Compute the confusion matrix\n",
    "            matrix = confusion_matrix(class_true, class_pred)\n",
    "\n",
    "            # Save or visualize the confusion matrix\n",
    "            plt.figure(figsize=(10,10))\n",
    "            sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=labels,\n",
    "                    yticklabels=labels)\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('Actual')\n",
    "            plt.title(f'Confusion Matrix for {class_name}')\n",
    "            plt.savefig(f'{output_dir}confusion_matrix_{class_name}.png')\n",
    "            plt.close()\n",
    "\n",
    "        # Generate report \n",
    "        report = classification_report(test_true_labels, test_pred_labels, target_names=mlb.classes_, output_dict=True)\n",
    "        report_name = output_dir + \"classification_report_\" + str(epoch_no) + \".txt\"\n",
    "\n",
    "        with open(report_name, \"w\") as f:\n",
    "            f.write(classification_report(test_true_labels, test_pred_labels, target_names=mlb.classes_))\n",
    "        \n",
    "        # Print results \n",
    "        #print(f\"Epoch {epoch+1}:\")\n",
    "        print(f\"  Train Loss = {train_loss:.4f}\")\n",
    "        print(f\"  Test Loss = {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "062ba0ed-374d-4c3f-8a7c-94d66fa9255c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████| 54/54 [1:36:59<00:00, 107.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5275223475915415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████| 14/14 [03:15<00:00, 13.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.49728811212948393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss = 0.5275\n",
      "  Test Loss = 0.4973\n"
     ]
    }
   ],
   "source": [
    "main_2()\n",
    "\n",
    "#approx. 1h 28 min to run (1 epoch, 1/6 of the data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08352b5-65c0-4a77-bd19-c06647d5da05",
   "metadata": {},
   "source": [
    "# Model with reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96069172-37fe-43a0-8525-eb663afcdb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the 02_model_with_ref with the original model\n",
    "# Current code is working \n",
    "\n",
    "\"\"\"\n",
    "=================================\n",
    "Model Training 2 - Reference Text\n",
    "=================================\n",
    "\n",
    "This script takes our cleaned twitter data and builds a pipeline to fine-tune a BERT which can classify the tweet into its 3 labels classes. \n",
    "\n",
    "The label classes are as follows: \n",
    "Type (3 labels): Antagonizing, Other political statement, Unclassifiable\n",
    "Tone Hateful (3 labels):  Hateful, Not Hateful, Unclassifiable Hateful \n",
    "Tone Constructive (3 labels): Constructive, Not Constructive, Unclassifiable Constructive\n",
    "\n",
    "To include the reference tweet information, there is one modification to this model from the basic 'No Reference Model' (01_model_no_ref.py): \n",
    "1. The reference text is appended to the reply tweet text with a [SEP] token to delineate the two tweets before the classification is made.\n",
    "    - This means the model has more information to base its prediction upon as it can see patterns in the reference text and how this may influence the reply tweet text. \n",
    "\n",
    "Usage:\n",
    "  $ python3 src/02_model_with_ref.py\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "=================================\n",
    "----- Import Depenendencies -----\n",
    "=================================\n",
    "\"\"\"\n",
    "# Data processing \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelling \n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\"\"\"\n",
    "=========================\n",
    "----- Main Function -----\n",
    "=========================\n",
    "\"\"\"\n",
    "def main_3():\n",
    "    \"\"\"\n",
    "    ==========================\n",
    "    Parameters and Directories \n",
    "    ==========================\n",
    "    \"\"\"\n",
    "    # -- Model parameters -- \n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') # Can change BERT model\n",
    "    batch_size = 16     # small batch size due to computation, increase to 32 if using GPU\n",
    "    num_labels = 12\n",
    "    num_epochs = 1      # Increase if desired, model started to overfit after around 5 epochs\n",
    "    epoch_no = 0 \n",
    "\n",
    "    # -- Directories --\n",
    "    #input_dir = \"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/Data\"\n",
    "    output_dir = \"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/output/model_with_reference_text/\"\n",
    "    checkpoint_dir = \"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/output/model_with_reference_text/checkpoints/\" # path for checkpoints to be saved\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    =======\n",
    "    Classes\n",
    "    =======\n",
    "    \"\"\"\n",
    "    # create a Dataset class for text and reference labels\n",
    "    class TextDatasetWithRefLabels(Dataset):\n",
    "        def __init__(self, ref_texts, ref_labels, texts, labels, tokenizer, max_length):\n",
    "            self.ref_texts = ref_texts\n",
    "            self.ref_labels = ref_labels\n",
    "            self.texts = texts\n",
    "            self.labels = labels\n",
    "            self.tokenizer = tokenizer\n",
    "            self.max_length = max_length\n",
    "\n",
    "            # Binarize the reference labels\n",
    "            self.mlb = MultiLabelBinarizer(classes=['Antagonizing', 'Other political statement', 'Unclassifiable', 'Hateful', 'Not Hateful', 'Unclassifiable Hateful', 'Constructive', 'Not Constructive','Unclassifiable Constructive', 'Agree', 'Disagree', 'Unclear'])\n",
    "            self.ref_labels = self.mlb.fit_transform(ref_labels)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.texts)\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            ref_text = self.ref_texts[index]\n",
    "            ref_label = self.ref_labels[index]\n",
    "            text = self.texts[index]\n",
    "            label = self.labels[index]\n",
    "\n",
    "            # Tokenize the reply tweet \n",
    "            rep_tokens = self.tokenizer.tokenize(text)\n",
    "\n",
    "            # Determine the maximum length of the reference text that can be used \n",
    "            max_ref_length = 511 - len(rep_tokens)\n",
    "\n",
    "            # Tokenize the reference text and truncate if necessary\n",
    "            ref_tokens = self.tokenizer.tokenize(ref_text)\n",
    "            if len(ref_tokens) > max_ref_length:\n",
    "                truncated_ref_tokens = ref_tokens[-max_ref_length:]\n",
    "            else:\n",
    "                truncated_ref_tokens = ref_tokens\n",
    "            \n",
    "            # Combine the reference and reply text tokens with a [SEP] token\n",
    "            combined_tokens = truncated_ref_tokens + [self.tokenizer.sep_token] + rep_tokens \n",
    "\n",
    "            # Convert the combined tokens to a text string\n",
    "            combined_text = self.tokenizer.convert_tokens_to_string(combined_tokens)\n",
    "\n",
    "            # Encode the combined text\n",
    "            encoded_data = self.tokenizer.encode_plus(\n",
    "                combined_text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=512,\n",
    "                padding='max_length',\n",
    "                truncation='only_first',\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "            input_ids = encoded_data['input_ids']\n",
    "            attention_mask = encoded_data['attention_mask']\n",
    "\n",
    "            # Convert the label data to tensors\n",
    "            label_tensor = torch.tensor(label, dtype=torch.float32)\n",
    "            ref_label_tensor = torch.tensor(ref_label, dtype=torch.float32)\n",
    "\n",
    "            return {\n",
    "                'input_ids': input_ids.squeeze(0),\n",
    "                'attention_mask': attention_mask.squeeze(0),\n",
    "                'ref_labels': ref_label_tensor,\n",
    "                'labels': label_tensor\n",
    "            }\n",
    "\n",
    "    class BertForContextualClassification(nn.Module):\n",
    "        def __init__(self, num_labels):\n",
    "            super(BertForContextualClassification, self).__init__()\n",
    "            self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "            self.dropout = nn.Dropout(0.1)\n",
    "            self.linear = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "\n",
    "        def forward(self, input_ids, attention_mask, ref_input_ids=None, ref_attention_mask=None):\n",
    "            if ref_input_ids is not None:\n",
    "                output = self.bert(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    inputs_embeds=None\n",
    "                )\n",
    "            else:\n",
    "                output = self.bert(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    inputs_embeds=None\n",
    "                )\n",
    "            pooled_output = output[1]\n",
    "            pooled_output = self.dropout(pooled_output)\n",
    "            logits = self.linear(pooled_output)\n",
    "            return logits\n",
    "\n",
    "    \"\"\"\n",
    "    =============\n",
    "    Preprocessing\n",
    "    =============\n",
    "    \"\"\"\n",
    "    # -- Load Data -- \n",
    "    train_data = pd.read_csv(\"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/Data/train/train_data_ref.csv\").head(864) #smaller sample for testing\n",
    "    test_data = pd.read_csv(\"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/Data/test/test_data_ref.csv\").head(216)\n",
    "\n",
    "    # prepare the train and test labels using MultiLabelBinarizer\n",
    "    mlb = MultiLabelBinarizer(classes=['Antagonizing', 'Other political statement', 'Unclassifiable', 'Hateful', 'Not Hateful', 'Unclassifiable Hateful', 'Constructive', 'Not Constructive','Unclassifiable Constructive', 'Agree', 'Disagree', 'Unclear'])\n",
    "\n",
    "    train_labels = mlb.fit_transform(train_data[['rep_type', 'rep_hateful', 'rep_constructive', 'rep_agree']].values)\n",
    "    test_labels = mlb.transform(test_data[['rep_type', 'rep_hateful', 'rep_constructive', 'rep_agree']].values)\n",
    "\n",
    "    # -- create train and test datasets -- \n",
    "    train_dataset = TextDatasetWithRefLabels(train_data['ref_text'].tolist(),\n",
    "                                            train_data[['ref_type', 'ref_hateful', 'ref_constructive']].values,\n",
    "                                            train_data['rep_text'].tolist(),\n",
    "                                            train_labels,\n",
    "                                            tokenizer,\n",
    "                                            max_length=512)\n",
    "\n",
    "    test_dataset = TextDatasetWithRefLabels(test_data['ref_text'].tolist(),\n",
    "                                            test_data[['ref_type', 'ref_hateful', 'ref_constructive']].values,\n",
    "                                            test_data['rep_text'].tolist(),\n",
    "                                            test_labels,\n",
    "                                            tokenizer,\n",
    "                                            max_length=512)\n",
    "    \n",
    "    # create train and test dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    \"\"\"\n",
    "    =====\n",
    "    Model\n",
    "    =====\n",
    "    \"\"\"\n",
    "    # Initialize the model\n",
    "    model = BertForContextualClassification(num_labels)\n",
    "\n",
    "    # Define your optimizer, loss function and learning rate\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Create training function \n",
    "    def train(model, dataloader, criterion, optimizer, device):\n",
    "        model.train()\n",
    "        model.to(device)\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            ref_labels = batch[\"ref_labels\"].to(device)\n",
    "            #print(\"input_ids shape:\", input_ids.shape)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        return avg_loss\n",
    "    \n",
    "    # -- create evaluation function -- \n",
    "    def evaluate(model, dataloader, criterion, device):\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        total_loss = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            logits = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = (logits.sigmoid() > 0.5).cpu().detach().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().detach().numpy())\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "        return avg_loss, np.array(all_labels), np.array(all_preds)\n",
    "    \n",
    "\n",
    "    # Define the model checkpoint file format (e.g., \"model_epoch_{epoch}.pt\")\n",
    "    checkpoint_filename = \"model_epoch_{epoch}.pt\"\n",
    "\n",
    "    # Define the label classes\n",
    "    label_classes = {\n",
    "        'rep_type': ['Antagonizing', 'Other political statement', 'Unclassifiable'],\n",
    "        'rep_constructive': ['Constructive', 'Not Constructive', 'Unclassifiable Constructive'],\n",
    "        'rep_hateful': ['Hateful', 'Not Hateful', 'Unclassifiable Hateful'],\n",
    "        'rep_agree': ['Agree', 'Disagree', 'Unclear']\n",
    "    }\n",
    "    \n",
    "    # -- Wrap it up into a function -- \n",
    "    # Call device \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Free up memory by deleting variables\n",
    "        epoch_no = epoch_no + 1\n",
    "        print(f\"Epoch {epoch_no}:\")\n",
    "        # -- Train model -- \n",
    "        train_loss = train(model, train_dataloader, criterion, optimizer, device)\n",
    "        print(f\"Train Loss: {train_loss}\")\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = checkpoint_dir + checkpoint_filename.format(epoch=epoch_no)\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "        # Evaluate the training data \n",
    "        #train_loss, true_labels, pred_labels = evaluate(model, train_dataloader, criterion, device)\n",
    "\n",
    "        # -- Test model -- \n",
    "        test_loss, test_true_labels, test_pred_labels = evaluate(model, test_dataloader, criterion, device)\n",
    "        print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "        # Convert output from one hot encoding \n",
    "        true_labels = np.array(test_true_labels)\n",
    "        pred_labels = np.array(test_pred_labels)\n",
    "\n",
    "        # Generate confusion matrix\n",
    "        for class_name, labels in label_classes.items():\n",
    "            # Get indices corresponding to labels in this class\n",
    "            indices = [i for i, label in enumerate(mlb.classes_) if label in labels]\n",
    "            \n",
    "            # Extract true and predicted values for this class\n",
    "            class_true = np.argmax(true_labels[:, indices], axis=1)\n",
    "            class_pred = np.argmax(pred_labels[:, indices], axis=1)\n",
    "            \n",
    "            # Compute the confusion matrix\n",
    "            matrix = confusion_matrix(class_true, class_pred)\n",
    "\n",
    "            # Save or visualize the confusion matrix\n",
    "            plt.figure(figsize=(10,10))\n",
    "            sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=labels,\n",
    "                    yticklabels=labels)\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('Actual')\n",
    "            plt.title(f'Confusion Matrix for {class_name}')\n",
    "            plt.savefig(f'{output_dir}confusion_matrix_{class_name}.png')\n",
    "            plt.close()\n",
    "\n",
    "        # Generate report \n",
    "        report = classification_report(test_true_labels, test_pred_labels, target_names=mlb.classes_, output_dict=True)\n",
    "        report_name = output_dir + \"classification_report_\" + str(epoch_no) + \".txt\"\n",
    "\n",
    "        with open(report_name, \"w\") as f:\n",
    "            f.write(classification_report(test_true_labels, test_pred_labels, target_names=mlb.classes_))\n",
    "        \n",
    "        # Print results \n",
    "        #print(f\"Epoch {epoch+1}:\")\n",
    "        print(f\"  Train Loss = {train_loss:.4f}\")\n",
    "        print(f\"  Test Loss = {test_loss:.4f}\")\n",
    "\n",
    "        # Activate if kernel struggles to run model \n",
    "        #if epoch < 5:\n",
    "            #del train_loss, true_labels, pred_labels, test_loss, test_true_labels, test_pred_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fad6320a-ff91-4cdb-8682-96a11f46c0ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████| 54/54 [18:02<00:00, 20.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5449445816101851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████| 14/14 [02:30<00:00, 10.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4690816445010049\n",
      "  Train Loss = 0.5449\n",
      "  Test Loss = 0.4691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "main_3()\n",
    "\n",
    "#approx. 19 min to run (1 epoch, 1/6 of the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ba43483-8205-415d-a55c-53defec1ee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the 02_model_with_ref with a new model (XLM-Roberta)\n",
    "# Current code is working\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "=================================\n",
    "Model Training 2 - Reference Text\n",
    "=================================\n",
    "\n",
    "This script takes our cleaned twitter data and builds a pipeline to fine-tune a BERT which can classify the tweet into its 3 labels classes. \n",
    "\n",
    "The label classes are as follows: \n",
    "Type (3 labels): Antagonizing, Other political statement, Unclassifiable\n",
    "Tone Hateful (3 labels):  Hateful, Not Hateful, Unclassifiable Hateful \n",
    "Tone Constructive (3 labels): Constructive, Not Constructive, Unclassifiable Constructive\n",
    "\n",
    "To include the reference tweet information, there is one modification to this model from the basic 'No Reference Model' (01_model_no_ref.py): \n",
    "1. The reference text is appended to the reply tweet text with a [SEP] token to delineate the two tweets before the classification is made.\n",
    "    - This means the model has more information to base its prediction upon as it can see patterns in the reference text and how this may influence the reply tweet text. \n",
    "\n",
    "Usage:\n",
    "  $ python3 src/02_model_with_ref.py\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "=================================\n",
    "----- Import Depenendencies -----\n",
    "=================================\n",
    "\"\"\"\n",
    "# Data processing \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelling \n",
    "from transformers import AutoTokenizer, XLMRobertaModel\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\"\"\"\n",
    "=========================\n",
    "----- Main Function -----\n",
    "=========================\n",
    "\"\"\"\n",
    "\n",
    "def main_4():\n",
    "    \"\"\"\n",
    "    ==========================\n",
    "    Parameters and Directories \n",
    "    ==========================\n",
    "    \"\"\"\n",
    "    # -- Model parameters -- \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-large\") # Can change BERT model\n",
    "    batch_size = 8     # small batch size due to computation, increase to 32 if using GPU\n",
    "    num_labels = 12\n",
    "    num_epochs = 2      # Increase if desired, model started to overfit after around 5 epochs\n",
    "    epoch_no = 0 \n",
    "\n",
    "    # -- Directories --\n",
    "    #input_dir = \"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/Data\"\n",
    "    output_dir = \"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/output/model_with_reference_text_new/\"\n",
    "    checkpoint_dir = \"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/output/model_with_reference_text_new/checkpoints/\" # path for checkpoints to be saved\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    =======\n",
    "    Classes\n",
    "    =======\n",
    "    \"\"\"\n",
    "    # create a Dataset class for text and reference labels\n",
    "    class TextDatasetWithRefLabels(Dataset):\n",
    "        def __init__(self, ref_texts, ref_labels, texts, labels, tokenizer, max_length):\n",
    "            self.ref_texts = ref_texts\n",
    "            self.ref_labels = ref_labels\n",
    "            self.texts = texts\n",
    "            self.labels = labels\n",
    "            self.tokenizer = tokenizer\n",
    "            self.max_length = max_length\n",
    "\n",
    "            # Binarize the reference labels\n",
    "            self.mlb = MultiLabelBinarizer(classes=['Antagonizing', 'Other political statement', 'Unclassifiable', 'Hateful', 'Not Hateful', 'Unclassifiable Hateful', 'Constructive', 'Not Constructive','Unclassifiable Constructive', 'Agree', 'Disagree', 'Unclear'])\n",
    "            self.ref_labels = self.mlb.fit_transform(ref_labels)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.texts)\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            ref_text = self.ref_texts[index]\n",
    "            ref_label = self.ref_labels[index]\n",
    "            text = self.texts[index]\n",
    "            label = self.labels[index]\n",
    "\n",
    "            # Tokenize the reply tweet \n",
    "            rep_tokens = self.tokenizer.tokenize(text)\n",
    "\n",
    "            # Determine the maximum length of the reference text that can be used \n",
    "            max_ref_length = 511 - len(rep_tokens)\n",
    "\n",
    "            # Tokenize the reference text and truncate if necessary\n",
    "            ref_tokens = self.tokenizer.tokenize(ref_text)\n",
    "            if len(ref_tokens) > max_ref_length:\n",
    "                truncated_ref_tokens = ref_tokens[-max_ref_length:]\n",
    "            else:\n",
    "                truncated_ref_tokens = ref_tokens\n",
    "            \n",
    "            # Combine the reference and reply text tokens with a [SEP] token\n",
    "            combined_tokens = truncated_ref_tokens + [self.tokenizer.sep_token] + rep_tokens \n",
    "\n",
    "            # Convert the combined tokens to a text string\n",
    "            combined_text = self.tokenizer.convert_tokens_to_string(combined_tokens)\n",
    "\n",
    "            # Encode the combined text\n",
    "            encoded_data = self.tokenizer.encode_plus(\n",
    "                combined_text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=512,\n",
    "                padding='max_length',\n",
    "                truncation='only_first',\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "            input_ids = encoded_data['input_ids']\n",
    "            attention_mask = encoded_data['attention_mask']\n",
    "\n",
    "            # Convert the label data to tensors\n",
    "            label_tensor = torch.tensor(label, dtype=torch.float32)\n",
    "            ref_label_tensor = torch.tensor(ref_label, dtype=torch.float32)\n",
    "\n",
    "            return {\n",
    "                'input_ids': input_ids.squeeze(0),\n",
    "                'attention_mask': attention_mask.squeeze(0),\n",
    "                'ref_labels': ref_label_tensor,\n",
    "                'labels': label_tensor\n",
    "            }\n",
    "\n",
    "    class RobertaForContextualClassification(nn.Module):\n",
    "        def __init__(self, num_labels):\n",
    "            super(RobertaForContextualClassification, self).__init__() \n",
    "            self.bert = XLMRobertaModel.from_pretrained('xlm-roberta-large')\n",
    "            self.dropout = nn.Dropout(0.1)\n",
    "            self.linear = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "\n",
    "        def forward(self, input_ids, attention_mask, ref_input_ids=None, ref_attention_mask=None):\n",
    "            if ref_input_ids is not None:\n",
    "                output = self.bert(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    inputs_embeds=None\n",
    "                )\n",
    "            else:\n",
    "                output = self.bert(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    inputs_embeds=None\n",
    "                )\n",
    "            pooled_output = output[1]\n",
    "            pooled_output = self.dropout(pooled_output)\n",
    "            logits = self.linear(pooled_output)\n",
    "            return logits\n",
    "\n",
    "    \"\"\"\n",
    "    =============\n",
    "    Preprocessing\n",
    "    =============\n",
    "    \"\"\"\n",
    "    # -- Load Data -- \n",
    "    train_data = pd.read_csv(\"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/Data/train/train_data_ref.csv\").head(288) #smaller sample for testing\n",
    "    test_data = pd.read_csv(\"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/Data/test/test_data_ref.csv\").head(72)\n",
    "\n",
    "\n",
    "    # prepare the train and test labels using MultiLabelBinarizer\n",
    "    mlb = MultiLabelBinarizer(classes=['Antagonizing', 'Other political statement', 'Unclassifiable', 'Hateful', 'Not Hateful', 'Unclassifiable Hateful', 'Constructive', 'Not Constructive','Unclassifiable Constructive', 'Agree', 'Disagree', 'Unclear'])\n",
    "\n",
    "    train_labels = mlb.fit_transform(train_data[['rep_type', 'rep_hateful', 'rep_constructive', 'rep_agree']].values)\n",
    "    test_labels = mlb.transform(test_data[['rep_type', 'rep_hateful', 'rep_constructive', 'rep_agree']].values)\n",
    "\n",
    "    # -- create train and test datasets -- \n",
    "    train_dataset = TextDatasetWithRefLabels(train_data['ref_text'].tolist(),\n",
    "                                            train_data[['ref_type', 'ref_hateful', 'ref_constructive']].values,\n",
    "                                            train_data['rep_text'].tolist(),\n",
    "                                            train_labels,\n",
    "                                            tokenizer,\n",
    "                                            max_length=512)\n",
    "\n",
    "    test_dataset = TextDatasetWithRefLabels(test_data['ref_text'].tolist(),\n",
    "                                            test_data[['ref_type', 'ref_hateful', 'ref_constructive']].values,\n",
    "                                            test_data['rep_text'].tolist(),\n",
    "                                            test_labels,\n",
    "                                            tokenizer,\n",
    "                                            max_length=512)\n",
    "    \n",
    "    # create train and test dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    \"\"\"\n",
    "    =====\n",
    "    Model\n",
    "    =====\n",
    "    \"\"\"\n",
    "    # Initialize the model\n",
    "    model = RobertaForContextualClassification(num_labels) \n",
    "\n",
    "    # Define your optimizer, loss function and learning rate\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Create training function \n",
    "    def train(model, dataloader, criterion, optimizer, device):\n",
    "        model.train()\n",
    "        model.to(device)\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            ref_labels = batch[\"ref_labels\"].to(device)\n",
    "            #print(\"input_ids shape:\", input_ids.shape)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        return avg_loss\n",
    "    \n",
    "    # -- create evaluation function -- \n",
    "    def evaluate(model, dataloader, criterion, device):\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        total_loss = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            logits = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = (logits.sigmoid() > 0.5).cpu().detach().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().detach().numpy())\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "        return avg_loss, np.array(all_labels), np.array(all_preds)\n",
    "    \n",
    "\n",
    "    # Define the model checkpoint file format (e.g., \"model_epoch_{epoch}.pt\")\n",
    "    checkpoint_filename = \"model_epoch_{epoch}.pt\"\n",
    "\n",
    "    # Define the label classes\n",
    "    label_classes = {\n",
    "        'rep_type': ['Antagonizing', 'Other political statement', 'Unclassifiable'],\n",
    "        'rep_constructive': ['Constructive', 'Not Constructive', 'Unclassifiable Constructive'],\n",
    "        'rep_hateful': ['Hateful', 'Not Hateful', 'Unclassifiable Hateful'],\n",
    "        'rep_agree': ['Agree', 'Disagree', 'Unclear']\n",
    "    }\n",
    "    \n",
    "    # -- Wrap it up into a function -- \n",
    "    # Call device \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Free up memory by deleting variables\n",
    "        epoch_no = epoch_no + 1\n",
    "        print(f\"Epoch {epoch_no}:\")\n",
    "        # -- Train model -- \n",
    "        train_loss = train(model, train_dataloader, criterion, optimizer, device)\n",
    "        print(f\"Train Loss: {train_loss}\")\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = checkpoint_dir + checkpoint_filename.format(epoch=epoch_no)\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "        # Evaluate the training data \n",
    "        train_loss, true_labels, pred_labels = evaluate(model, train_dataloader, criterion, device)\n",
    "\n",
    "        # -- Test model -- \n",
    "        test_loss, test_true_labels, test_pred_labels = evaluate(model, test_dataloader, criterion, device)\n",
    "        print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "        # Convert output from one hot encoding \n",
    "        true_labels = np.array(test_true_labels)\n",
    "        pred_labels = np.array(test_pred_labels)\n",
    "\n",
    "        # Generate confusion matrix\n",
    "        for class_name, labels in label_classes.items():\n",
    "            # Get indices corresponding to labels in this class\n",
    "            indices = [i for i, label in enumerate(mlb.classes_) if label in labels]\n",
    "            \n",
    "            # Extract true and predicted values for this class\n",
    "            class_true = np.argmax(true_labels[:, indices], axis=1)\n",
    "            class_pred = np.argmax(pred_labels[:, indices], axis=1)\n",
    "            \n",
    "            # Compute the confusion matrix\n",
    "            matrix = confusion_matrix(class_true, class_pred)\n",
    "\n",
    "            # Save or visualize the confusion matrix\n",
    "            plt.figure(figsize=(10,10))\n",
    "            sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=labels,\n",
    "                    yticklabels=labels)\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('Actual')\n",
    "            plt.title(f'Confusion Matrix for {class_name}')\n",
    "            plt.savefig(f'{output_dir}confusion_matrix_{class_name}.png')\n",
    "            plt.close()\n",
    "\n",
    "        # Generate report \n",
    "        report = classification_report(test_true_labels, test_pred_labels, target_names=mlb.classes_, output_dict=True)\n",
    "        report_name = output_dir + \"classification_report_\" + str(epoch_no) + \".txt\"\n",
    "\n",
    "        with open(report_name, \"w\") as f:\n",
    "            f.write(classification_report(test_true_labels, test_pred_labels, target_names=mlb.classes_))\n",
    "        \n",
    "        # Print results \n",
    "        #print(f\"Epoch {epoch+1}:\")\n",
    "        print(f\"  Train Loss = {train_loss:.4f}\")\n",
    "        print(f\"  Test Loss = {test_loss:.4f}\")\n",
    "\n",
    "        # Activate if kernel struggles to run model \n",
    "        if epoch < 5:\n",
    "            del train_loss, true_labels, pred_labels, test_loss, test_true_labels, test_pred_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe37b531-3f47-4a66-ae7a-d57cc4330a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idahelenedencker/myenv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████| 36/36 [35:49<00:00, 59.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5484334453940392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████| 36/36 [14:16<00:00, 23.78s/it]\n",
      "Evaluating: 100%|█████████████████████████████████| 9/9 [02:51<00:00, 19.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5133921967612373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idahelenedencker/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/idahelenedencker/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss = 0.4864\n",
      "  Test Loss = 0.5134\n",
      "Epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████| 36/36 [34:36<00:00, 57.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.49987006684144336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████| 36/36 [13:47<00:00, 22.99s/it]\n",
      "Evaluating: 100%|█████████████████████████████████| 9/9 [03:07<00:00, 20.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5193341970443726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idahelenedencker/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/idahelenedencker/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss = 0.4799\n",
      "  Test Loss = 0.5193\n"
     ]
    }
   ],
   "source": [
    "main_4() \n",
    "\n",
    "#aprrox. 2h 18m to run (kernel died when evaluating)\n",
    "\n",
    "#tried batchsize 8, epochs 2, 1/18 of the data, ''Activate if kernel struggles to run model'' code uncommented, ''Evaluate the training data'' code uncommented (will run, 50 min pr epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed47ea4-1dfb-43cf-8445-e54ffb836fd0",
   "metadata": {},
   "source": [
    "# Model with reference and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e892ea1-1d24-4567-a20b-99eba2b08645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the 03_model_with_ref_and_labels with the original model\n",
    "# Current code is working\n",
    "\n",
    "# Data processing \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelling \n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def main_5():\n",
    "    \"\"\"\n",
    "    ==========================\n",
    "    Parameters and Directories \n",
    "    ==========================\n",
    "    \"\"\"\n",
    "    # Argparse parameters \n",
    "    model_name = 'bert-base-uncased'\n",
    "    num_epochs = 1\n",
    "\n",
    "    # Model parameters \n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    batch_size = 16    # Increase to 32 if using on GPU for faster training\n",
    "    num_ref_labels = 12\n",
    "    num_labels = 12\n",
    "\n",
    "    # Directories \n",
    "    #input_dir = \"./data/\"\n",
    "    output_dir = \"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/output/model_with_reference_text_and_labels/\"\n",
    "    checkpoint_dir = \"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/output/model_with_reference_text_and_labels/checkpoints/\" # path for checkpoints to be saved\n",
    "    \n",
    "    \"\"\"\n",
    "    =======\n",
    "    Classes\n",
    "    =======\n",
    "    \"\"\"\n",
    "    # -- Class for creating dataset with referemce text and labels -- \n",
    "    class TextDatasetWithRefLabels(Dataset):\n",
    "        def __init__(self, ref_texts, ref_labels, texts, labels, tokenizer, max_length):\n",
    "            self.ref_texts = ref_texts\n",
    "            self.ref_labels = ref_labels\n",
    "            self.texts = texts\n",
    "            self.labels = labels\n",
    "            self.tokenizer = tokenizer\n",
    "            self.max_length = max_length\n",
    "\n",
    "            # Binarize the reference labels\n",
    "            self.mlb = MultiLabelBinarizer(classes=['Antagonizing', 'Other political statement', 'Unclassifiable', 'Hateful', 'Not Hateful', 'Unclassifiable Hateful', 'Constructive', 'Not Constructive','Unclassifiable Constructive', 'Agree', 'Disagree', 'Unclear'])\n",
    "            self.ref_labels = self.mlb.fit_transform(ref_labels)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.texts)\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            ref_text = self.ref_texts[index]\n",
    "            ref_label = self.ref_labels[index]\n",
    "            text = self.texts[index]\n",
    "            label = self.labels[index]\n",
    "\n",
    "            # Tokenize the reply tweet \n",
    "            rep_tokens = self.tokenizer.tokenize(text)\n",
    "\n",
    "            # Determine the maximum length of the reference text that can be used \n",
    "            max_ref_length = 511 - len(rep_tokens)\n",
    "\n",
    "            # Tokenize the reference text and truncate if necessary\n",
    "            ref_tokens = self.tokenizer.tokenize(ref_text)\n",
    "            if len(ref_tokens) > max_ref_length:\n",
    "                truncated_ref_tokens = ref_tokens[-max_ref_length:]\n",
    "            else:\n",
    "                truncated_ref_tokens = ref_tokens\n",
    "                \n",
    "            # Combine the reference and reply text tokens with a [SEP] token\n",
    "            combined_tokens = truncated_ref_tokens + [self.tokenizer.sep_token] + rep_tokens \n",
    "\n",
    "            # Convert the combined tokens to a text string\n",
    "            combined_text = self.tokenizer.convert_tokens_to_string(combined_tokens)\n",
    "\n",
    "            # Encode the combined text\n",
    "            encoded_data = self.tokenizer.encode_plus(\n",
    "                combined_text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=512,\n",
    "                padding='max_length',\n",
    "                truncation='only_first',\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "            input_ids = encoded_data['input_ids']\n",
    "            attention_mask = encoded_data['attention_mask']\n",
    "\n",
    "            # Convert the label data to tensors\n",
    "            label_tensor = torch.tensor(label, dtype=torch.float32)\n",
    "            ref_label_tensor = torch.tensor(ref_label, dtype=torch.float32)\n",
    "\n",
    "            return {\n",
    "                'input_ids': input_ids.squeeze(0),\n",
    "                'attention_mask': attention_mask.squeeze(0),\n",
    "                'ref_labels': ref_label_tensor,\n",
    "                'labels': label_tensor\n",
    "            }\n",
    "    \n",
    "    # -- class for modelling with reference text and labels -- \n",
    "    class BertForContextualClassification(nn.Module):\n",
    "        def __init__(self, num_labels, num_ref_labels, model_name):\n",
    "            super(BertForContextualClassification, self).__init__()\n",
    "            self.bert = BertModel.from_pretrained(model_name)\n",
    "            self.dropout = nn.Dropout(0.1)\n",
    "            self.linear_ref_labels = nn.Linear(num_ref_labels, num_ref_labels) # Additional layer for reference labels\n",
    "            self.linear_combined = nn.Linear(self.bert.config.hidden_size + num_ref_labels, num_labels) # Combining BERT output and reference labels\n",
    "\n",
    "        def forward(self, input_ids, attention_mask, ref_labels):\n",
    "            # Obtain BERT's output for the combined text\n",
    "            output = self.bert(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            pooled_output = output[1]\n",
    "            pooled_output = self.dropout(pooled_output)\n",
    "\n",
    "            # Pass the reference labels through a linear layer\n",
    "            ref_labels_output = self.linear_ref_labels(ref_labels)\n",
    "\n",
    "            # Concatenate the BERT pooled output with the processed reference labels\n",
    "            combined_output = torch.cat((pooled_output, ref_labels_output), dim=1)\n",
    "\n",
    "            # Pass the combined output through the final linear layer\n",
    "            logits = self.linear_combined(combined_output)\n",
    "\n",
    "            return logits\n",
    "\n",
    "    \"\"\"\n",
    "    =============\n",
    "    Preprocessing\n",
    "    =============\n",
    "    \"\"\"\n",
    "    # -- Load Data -- \n",
    "    train_data = pd.read_csv(\"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/Data/train/train_data_ref.csv\").head(864) #smaller sample for testing\n",
    "    test_data = pd.read_csv(\"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/Data/test/test_data_ref.csv\").head(216)\n",
    "\n",
    "    #Define the labels to be binarised and transform\n",
    "    mlb = MultiLabelBinarizer(classes=['Antagonizing', 'Other political statement', 'Unclassifiable', 'Hateful', 'Not Hateful', 'Unclassifiable Hateful', 'Constructive', 'Not Constructive','Unclassifiable Constructive', 'Agree', 'Disagree', 'Unclear'])\n",
    "    train_labels = mlb.fit_transform(train_data[['rep_type', 'rep_hateful', 'rep_constructive', 'rep_agree']].values)\n",
    "    test_labels = mlb.transform(test_data[['rep_type', 'rep_hateful', 'rep_constructive', 'rep_agree']].values)\n",
    "\n",
    "    # create datasets\n",
    "    train_dataset = TextDatasetWithRefLabels(ref_texts=train_data['ref_text'].tolist(),\n",
    "                                          ref_labels=train_data[['ref_type', 'ref_hateful', 'ref_constructive']].values,\n",
    "                                          texts=train_data['rep_text'].tolist(),\n",
    "                                          labels=train_labels,\n",
    "                                          tokenizer=tokenizer,\n",
    "                                          max_length=512)\n",
    "    \n",
    "    test_dataset = TextDatasetWithRefLabels(ref_texts=test_data['ref_text'].tolist(),\n",
    "                                         ref_labels=test_data[['ref_type', 'ref_hateful', 'ref_constructive']].values,\n",
    "                                         texts=test_data['rep_text'].tolist(),\n",
    "                                         labels=test_labels,\n",
    "                                         tokenizer=tokenizer,\n",
    "                                         max_length=512)\n",
    "\n",
    "    # create train and test dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    \"\"\"\n",
    "    =====\n",
    "    Model\n",
    "    =====\n",
    "    \"\"\"\n",
    "    # Initialize the model\n",
    "    model = BertForContextualClassification(num_labels, num_ref_labels, model_name)\n",
    "\n",
    "    # Define your optimizer, loss function and learning rate\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Create training function \n",
    "    def train(model, dataloader, criterion, optimizer, device):\n",
    "        model.train()\n",
    "        model.to(device)\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            ref_labels = batch[\"ref_labels\"].to(device) # Extract reference labels from the batch\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(input_ids, attention_mask=attention_mask, ref_labels=ref_labels) # Include reference labels when calling the model\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        return avg_loss\n",
    "    \n",
    "    # -- create evaluation function -- \n",
    "    def evaluate(model, dataloader, criterion, device):\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        total_loss = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            ref_labels = batch[\"ref_labels\"].to(device) # Extract reference labels from the batch\n",
    "\n",
    "            logits = model(input_ids, attention_mask=attention_mask, ref_labels=ref_labels) # Include reference labels when calling the model\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = (logits.sigmoid() > 0.5).cpu().detach().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().detach().numpy())\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "        return avg_loss, np.array(all_labels), np.array(all_preds)\n",
    "    \n",
    "    # Call device \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # -- Wrap it up into a function -- \n",
    "    epoch_no = 0 \n",
    "\n",
    "    # Define the model checkpoint file format (e.g., \"model_epoch_{epoch}.pt\")\n",
    "    checkpoint_filename = \"model_epoch_{epoch}.pt\"\n",
    "\n",
    "    # Define the label classes\n",
    "    label_classes = {\n",
    "        'rep_type': ['Antagonizing', 'Other political statement', 'Unclassifiable'],\n",
    "        'rep_constructive': ['Constructive', 'Not Constructive', 'Unclassifiable Constructive'],\n",
    "        'rep_hateful': ['Hateful', 'Not Hateful', 'Unclassifiable Hateful'],\n",
    "        'rep_agree': ['Agree', 'Disagree', 'Unclear']\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Free up memory by deleting variables\n",
    "        epoch_no = epoch_no + 1\n",
    "        print(f\"Epoch {epoch_no}:\")\n",
    "        # -- Train model -- \n",
    "        train_loss = train(model, train_dataloader, criterion, optimizer, device)\n",
    "        print(f\"Train Loss: {train_loss}\")\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = checkpoint_dir + checkpoint_filename.format(epoch=epoch_no)\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "        # -- Test model -- \n",
    "        test_loss, test_true_labels, test_pred_labels = evaluate(model, test_dataloader, criterion, device)\n",
    "        print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "        # Convert output from one hot encoding \n",
    "        true_labels = np.array(test_true_labels)\n",
    "        pred_labels = np.array(test_pred_labels)\n",
    "\n",
    "        # Generate confusion matrix\n",
    "        for class_name, labels in label_classes.items():\n",
    "            # Get indices corresponding to labels in this class\n",
    "            indices = [i for i, label in enumerate(mlb.classes_) if label in labels]\n",
    "            \n",
    "            # Extract true and predicted values for this class\n",
    "            class_true = np.argmax(true_labels[:, indices], axis=1)\n",
    "            class_pred = np.argmax(pred_labels[:, indices], axis=1)\n",
    "            \n",
    "            # Compute the confusion matrix\n",
    "            matrix = confusion_matrix(class_true, class_pred)\n",
    "\n",
    "            # Save or visualize the confusion matrix\n",
    "            plt.figure(figsize=(10,10))\n",
    "            sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=labels,\n",
    "                    yticklabels=labels)\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('Actual')\n",
    "            plt.title(f'Confusion Matrix for {class_name}')\n",
    "            plt.savefig(f'{output_dir}confusion_matrix_{class_name}.png')\n",
    "            plt.close()\n",
    "\n",
    "        # Generate report \n",
    "        report = classification_report(test_true_labels, test_pred_labels, target_names=mlb.classes_, output_dict=True)\n",
    "        report_name = output_dir + \"classification_report_\" + str(epoch_no) + \".txt\"\n",
    "\n",
    "        with open(report_name, \"w\") as f:\n",
    "            f.write(classification_report(test_true_labels, test_pred_labels, target_names=mlb.classes_))\n",
    "        \n",
    "        # Print results \n",
    "        #print(f\"Epoch {epoch+1}:\")\n",
    "        print(f\"  Train Loss = {train_loss:.4f}\")\n",
    "        print(f\"  Test Loss = {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61b88461-9d06-43e5-a706-9724b1022e33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████| 54/54 [18:25<00:00, 20.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5775867501894633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████| 14/14 [02:16<00:00,  9.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.47699148314339773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss = 0.5776\n",
      "  Test Loss = 0.4770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "main_5()\n",
    "\n",
    "#approx. 19 min to run (1 epoch, 1/6 of the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbf6304f-5655-49cb-af01-f274cb402418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the 03_model_with_ref_and_labels with a new model (XLM-Roberta)\n",
    "# Kernel dies\n",
    "\n",
    "# Data processing \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelling \n",
    "from transformers import AutoTokenizer, XLMRobertaModel\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def main_6():\n",
    "    \"\"\"\n",
    "    ==========================\n",
    "    Parameters and Directories \n",
    "    ==========================\n",
    "    \"\"\"\n",
    "    # Argparse parameters \n",
    "    model_name = 'xlm-roberta-large'\n",
    "    num_epochs = 1\n",
    "\n",
    "    # Model parameters \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-large\")\n",
    "    batch_size = 16    # Increase to 32 if using on GPU for faster training\n",
    "    num_ref_labels = 12\n",
    "    num_labels = 12\n",
    "\n",
    "    # Directories \n",
    "    #input_dir = \"./data/\"\n",
    "    output_dir = \"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/output/model_with_reference_text_and_labels_new/\"\n",
    "    checkpoint_dir = \"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/output/model_with_reference_text_and_labels_new/checkpoints/\" # path for checkpoints to be saved\n",
    "    \n",
    "    \"\"\"\n",
    "    =======\n",
    "    Classes\n",
    "    =======\n",
    "    \"\"\"\n",
    "    # -- Class for creating dataset with referemce text and labels -- \n",
    "    class TextDatasetWithRefLabels(Dataset):\n",
    "        def __init__(self, ref_texts, ref_labels, texts, labels, tokenizer, max_length):\n",
    "            self.ref_texts = ref_texts\n",
    "            self.ref_labels = ref_labels\n",
    "            self.texts = texts\n",
    "            self.labels = labels\n",
    "            self.tokenizer = tokenizer\n",
    "            self.max_length = max_length\n",
    "\n",
    "            # Binarize the reference labels\n",
    "            self.mlb = MultiLabelBinarizer(classes=['Antagonizing', 'Other political statement', 'Unclassifiable', 'Hateful', 'Not Hateful', 'Unclassifiable Hateful', 'Constructive', 'Not Constructive','Unclassifiable Constructive', 'Agree', 'Disagree', 'Unclear'])\n",
    "            self.ref_labels = self.mlb.fit_transform(ref_labels)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.texts)\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            ref_text = self.ref_texts[index]\n",
    "            ref_label = self.ref_labels[index]\n",
    "            text = self.texts[index]\n",
    "            label = self.labels[index]\n",
    "\n",
    "            # Tokenize the reply tweet \n",
    "            rep_tokens = self.tokenizer.tokenize(text)\n",
    "\n",
    "            # Determine the maximum length of the reference text that can be used \n",
    "            max_ref_length = 511 - len(rep_tokens)\n",
    "\n",
    "            # Tokenize the reference text and truncate if necessary\n",
    "            ref_tokens = self.tokenizer.tokenize(ref_text)\n",
    "            if len(ref_tokens) > max_ref_length:\n",
    "                truncated_ref_tokens = ref_tokens[-max_ref_length:]\n",
    "            else:\n",
    "                truncated_ref_tokens = ref_tokens\n",
    "                \n",
    "            # Combine the reference and reply text tokens with a [SEP] token\n",
    "            combined_tokens = truncated_ref_tokens + [self.tokenizer.sep_token] + rep_tokens \n",
    "\n",
    "            # Convert the combined tokens to a text string\n",
    "            combined_text = self.tokenizer.convert_tokens_to_string(combined_tokens)\n",
    "\n",
    "            # Encode the combined text\n",
    "            encoded_data = self.tokenizer.encode_plus(\n",
    "                combined_text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=512,\n",
    "                padding='max_length',\n",
    "                truncation='only_first',\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "            input_ids = encoded_data['input_ids']\n",
    "            attention_mask = encoded_data['attention_mask']\n",
    "\n",
    "            # Convert the label data to tensors\n",
    "            label_tensor = torch.tensor(label, dtype=torch.float32)\n",
    "            ref_label_tensor = torch.tensor(ref_label, dtype=torch.float32)\n",
    "\n",
    "            return {\n",
    "                'input_ids': input_ids.squeeze(0),\n",
    "                'attention_mask': attention_mask.squeeze(0),\n",
    "                'ref_labels': ref_label_tensor,\n",
    "                'labels': label_tensor\n",
    "            }\n",
    "    \n",
    "    # -- class for modelling with reference text and labels -- \n",
    "    class RobertaForContextualClassification(nn.Module):\n",
    "        def __init__(self, num_labels, num_ref_labels, model_name):\n",
    "            super(RobertaForContextualClassification, self).__init__()\n",
    "            self.bert = XLMRobertaModel.from_pretrained(model_name)\n",
    "            self.dropout = nn.Dropout(0.1)\n",
    "            self.linear_ref_labels = nn.Linear(num_ref_labels, num_ref_labels) # Additional layer for reference labels\n",
    "            self.linear_combined = nn.Linear(self.bert.config.hidden_size + num_ref_labels, num_labels) # Combining BERT output and reference labels\n",
    "\n",
    "        def forward(self, input_ids, attention_mask, ref_labels):\n",
    "            # Obtain BERT's output for the combined text\n",
    "            output = self.bert(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            pooled_output = output[1]\n",
    "            pooled_output = self.dropout(pooled_output)\n",
    "\n",
    "            # Pass the reference labels through a linear layer\n",
    "            ref_labels_output = self.linear_ref_labels(ref_labels)\n",
    "\n",
    "            # Concatenate the BERT pooled output with the processed reference labels\n",
    "            combined_output = torch.cat((pooled_output, ref_labels_output), dim=1)\n",
    "\n",
    "            # Pass the combined output through the final linear layer\n",
    "            logits = self.linear_combined(combined_output)\n",
    "\n",
    "            return logits\n",
    "\n",
    "    \"\"\"\n",
    "    =============\n",
    "    Preprocessing\n",
    "    =============\n",
    "    \"\"\"\n",
    "    # -- Load Data -- \n",
    "    train_data = pd.read_csv(\"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/Data/train/train_data_ref.csv\").head(288) #smaller sample for testing\n",
    "    test_data = pd.read_csv(\"/Users/idahelenedencker/Desktop/STANDBY_Ida/Retraining and finetuning counterspeech classifier/Data/test/test_data_ref.csv\").head(72)\n",
    "\n",
    "    #Define the labels to be binarised and transform\n",
    "    mlb = MultiLabelBinarizer(classes=['Antagonizing', 'Other political statement', 'Unclassifiable', 'Hateful', 'Not Hateful', 'Unclassifiable Hateful', 'Constructive', 'Not Constructive','Unclassifiable Constructive', 'Agree', 'Disagree', 'Unclear'])\n",
    "    train_labels = mlb.fit_transform(train_data[['rep_type', 'rep_hateful', 'rep_constructive', 'rep_agree']].values)\n",
    "    test_labels = mlb.transform(test_data[['rep_type', 'rep_hateful', 'rep_constructive', 'rep_agree']].values)\n",
    "\n",
    "    # create datasets\n",
    "    train_dataset = TextDatasetWithRefLabels(ref_texts=train_data['ref_text'].tolist(),\n",
    "                                          ref_labels=train_data[['ref_type', 'ref_hateful', 'ref_constructive']].values,\n",
    "                                          texts=train_data['rep_text'].tolist(),\n",
    "                                          labels=train_labels,\n",
    "                                          tokenizer=tokenizer,\n",
    "                                          max_length=512)\n",
    "    \n",
    "    test_dataset = TextDatasetWithRefLabels(ref_texts=test_data['ref_text'].tolist(),\n",
    "                                         ref_labels=test_data[['ref_type', 'ref_hateful', 'ref_constructive']].values,\n",
    "                                         texts=test_data['rep_text'].tolist(),\n",
    "                                         labels=test_labels,\n",
    "                                         tokenizer=tokenizer,\n",
    "                                         max_length=512)\n",
    "\n",
    "    # create train and test dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    \"\"\"\n",
    "    =====\n",
    "    Model\n",
    "    =====\n",
    "    \"\"\"\n",
    "    # Initialize the model\n",
    "    model = RobertaForContextualClassification(num_labels, num_ref_labels, model_name)\n",
    "\n",
    "    # Define your optimizer, loss function and learning rate\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Create training function \n",
    "    def train(model, dataloader, criterion, optimizer, device):\n",
    "        model.train()\n",
    "        model.to(device)\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            ref_labels = batch[\"ref_labels\"].to(device) # Extract reference labels from the batch\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(input_ids, attention_mask=attention_mask, ref_labels=ref_labels) # Include reference labels when calling the model\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        return avg_loss\n",
    "    \n",
    "    # -- create evaluation function -- \n",
    "    def evaluate(model, dataloader, criterion, device):\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        total_loss = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            ref_labels = batch[\"ref_labels\"].to(device) # Extract reference labels from the batch\n",
    "\n",
    "            logits = model(input_ids, attention_mask=attention_mask, ref_labels=ref_labels) # Include reference labels when calling the model\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = (logits.sigmoid() > 0.5).cpu().detach().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().detach().numpy())\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "        return avg_loss, np.array(all_labels), np.array(all_preds)\n",
    "    \n",
    "    # Call device \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # -- Wrap it up into a function -- \n",
    "    epoch_no = 0 \n",
    "\n",
    "    # Define the model checkpoint file format (e.g., \"model_epoch_{epoch}.pt\")\n",
    "    checkpoint_filename = \"model_epoch_{epoch}.pt\"\n",
    "\n",
    "    # Define the label classes\n",
    "    label_classes = {\n",
    "        'rep_type': ['Antagonizing', 'Other political statement', 'Unclassifiable'],\n",
    "        'rep_constructive': ['Constructive', 'Not Constructive', 'Unclassifiable Constructive'],\n",
    "        'rep_hateful': ['Hateful', 'Not Hateful', 'Unclassifiable Hateful'],\n",
    "        'rep_agree': ['Agree', 'Disagree', 'Unclear']\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Free up memory by deleting variables\n",
    "        epoch_no = epoch_no + 1\n",
    "        print(f\"Epoch {epoch_no}:\")\n",
    "        # -- Train model -- \n",
    "        train_loss = train(model, train_dataloader, criterion, optimizer, device)\n",
    "        print(f\"Train Loss: {train_loss}\")\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = checkpoint_dir + checkpoint_filename.format(epoch=epoch_no)\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "        # Evaluate the training data \n",
    "        train_loss, true_labels, pred_labels = evaluate(model, train_dataloader, criterion, device)\n",
    "\n",
    "        # -- Test model -- \n",
    "        test_loss, test_true_labels, test_pred_labels = evaluate(model, test_dataloader, criterion, device)\n",
    "        print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "        # Convert output from one hot encoding \n",
    "        true_labels = np.array(test_true_labels)\n",
    "        pred_labels = np.array(test_pred_labels)\n",
    "\n",
    "        # Generate confusion matrix\n",
    "        for class_name, labels in label_classes.items():\n",
    "            # Get indices corresponding to labels in this class\n",
    "            indices = [i for i, label in enumerate(mlb.classes_) if label in labels]\n",
    "            \n",
    "            # Extract true and predicted values for this class\n",
    "            class_true = np.argmax(true_labels[:, indices], axis=1)\n",
    "            class_pred = np.argmax(pred_labels[:, indices], axis=1)\n",
    "            \n",
    "            # Compute the confusion matrix\n",
    "            matrix = confusion_matrix(class_true, class_pred)\n",
    "\n",
    "            # Save or visualize the confusion matrix\n",
    "            plt.figure(figsize=(10,10))\n",
    "            sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=labels,\n",
    "                    yticklabels=labels)\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('Actual')\n",
    "            plt.title(f'Confusion Matrix for {class_name}')\n",
    "            plt.savefig(f'{output_dir}confusion_matrix_{class_name}.png')\n",
    "            plt.close()\n",
    "\n",
    "        # Generate report \n",
    "        report = classification_report(test_true_labels, test_pred_labels, target_names=mlb.classes_, output_dict=True)\n",
    "        report_name = output_dir + \"classification_report_\" + str(epoch_no) + \".txt\"\n",
    "\n",
    "        with open(report_name, \"w\") as f:\n",
    "            f.write(classification_report(test_true_labels, test_pred_labels, target_names=mlb.classes_))\n",
    "        \n",
    "        # Print results \n",
    "        #print(f\"Epoch {epoch+1}:\")\n",
    "        print(f\"  Train Loss = {train_loss:.4f}\")\n",
    "        print(f\"  Test Loss = {test_loss:.4f}\")\n",
    "\n",
    "        # Activate if kernel struggles to run model \n",
    "        if epoch < 5:\n",
    "            del train_loss, true_labels, pred_labels, test_loss, test_true_labels, test_pred_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93d54b8-b515-43d3-9235-637c4d82570f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|██████████████▋                  | 8/18 [13:29<17:45, 106.57s/it]"
     ]
    }
   ],
   "source": [
    "main_6()\n",
    "\n",
    "#approx. 1h 32 min to run (1 epoch, 1/6 of the data)\n",
    "#(kernel died when evaluating)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
