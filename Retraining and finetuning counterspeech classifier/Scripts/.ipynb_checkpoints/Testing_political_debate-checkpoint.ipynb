{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "272dac35-52a0-4f04-a796-1b13e0b0530a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.1.0)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.44.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas torch transformers numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e88f38d-85ba-4ed8-8f62-117708446f71",
   "metadata": {},
   "source": [
    "# Political Debates models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a4f666-806b-4bca-bd7a-db8efa999e71",
   "metadata": {},
   "source": [
    "https://huggingface.co/MoritzLaurer/deberta-v3-large-zeroshot-v2.0-c\n",
    "\n",
    "Political DEBATE (DeBERTa Algorithm for Textual Entailment) is an NLI classifier trained for zero-shot and few-shot classification of political documents.\n",
    "\n",
    "Trained on tasks:\n",
    "- Stance detection (i.e. opinion mining).\n",
    "- Hatespeech detection.\n",
    "- Event extraction.\n",
    "- Topic classification.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45e3f3d-782d-464f-ba84-3cd405259392",
   "metadata": {},
   "source": [
    "## base vs. large model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2295733a-6a7f-4bc8-a17a-1b7c01790d9b",
   "metadata": {},
   "source": [
    "Use large for zero-shot and few-shot applications UNLESS your use case is explicitly in the training data\n",
    "\n",
    "for tasks that are more explicitly within the training distribution such as hate-speech detection or approval of politicians, we expect comparable performance between the large and base models, with the base model offering a significant advantage in efficiency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c5f425-d13d-4293-b185-049e65637946",
   "metadata": {},
   "source": [
    "## Hypothesis generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76e49c2-ebae-433f-9bee-6102b1ac1bcd",
   "metadata": {},
   "source": [
    "In training the model in the hatespeech detection task they used hypothesis like 'This text is hate speech' or 'This text is attacking political outgroups.', 'This text is attacking X', 'This text is defending X' (however there are many more examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8034e26-f7c4-4c76-b018-3ebf5aa6adf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef3b556ff3c41c8bf6358cefc32ba7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c55aa7e3c564a7b96816f9493fbf279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/738M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a883e97e864ce3986198e2ff1920cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.51k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06b334fdae5477c9946536a52fdd207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/8.65M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0abb07ffbcef4128bb1695e8d9771cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "# Using pipeline\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"zero-shot-classification\", model=\"mlburnham/Political_DEBATE_base_v1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e0b57a0-cb5c-430c-8614-3e80cf2ff447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I have a problem with my iphone that needs to be resolved asap!!',\n",
       " 'labels': ['phone', 'urgent', 'computer', 'tablet', 'not urgent'],\n",
       " 'scores': [0.9471964240074158,\n",
       "  0.052190061658620834,\n",
       "  0.00041983439587056637,\n",
       "  0.00018530180386733264,\n",
       "  8.329217052960303e-06]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classic zero shot syntax\n",
    "\n",
    "pipe(\"I have a problem with my iphone that needs to be resolved asap!!\",\n",
    "    candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6d128ce-c975-4964-a864-d2633b97ed75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'i fucking love donald trump!', 'labels': ['love', 'neutral speech', 'hate'], 'scores': [0.9992910623550415, 0.0005671571125276387, 0.0001418278261553496]}\n"
     ]
    }
   ],
   "source": [
    "#code from https://huggingface.co/MoritzLaurer/deberta-v3-large-zeroshot-v2.0-c\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "text = \"i fucking love donald trump!\"\n",
    "hypothesis_template = \"This text contains elements of {}\"\n",
    "classes_verbalized = [\"love\", \"hate\", \"neutral speech\"]\n",
    "zeroshot_classifier = pipeline(\"zero-shot-classification\", model=\"mlburnham/Political_DEBATE_base_v1.0\")  # change the model identifier here\n",
    "output = zeroshot_classifier(text, classes_verbalized, hypothesis_template=hypothesis_template, multi_label=False)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a6b9b7d-de2c-46dc-a230-8ce884149238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'i fucking love donald trump!', 'labels': ['hate'], 'scores': [9.521207175566815e-06]}\n"
     ]
    }
   ],
   "source": [
    "#testing, how to formulate only hypothesis??\n",
    "\n",
    "text = \"i fucking love donald trump!\"\n",
    "hypothesis_template = \"This text contains elements of {}\"\n",
    "classes_verbalized = [\"hate\"]\n",
    "zeroshot_classifier = pipeline(\"zero-shot-classification\", model=\"mlburnham/Political_DEBATE_base_v1.0\")  # change the model identifier here\n",
    "output = zeroshot_classifier(text, classes_verbalized, hypothesis_template=hypothesis_template, multi_label=False)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1bab05-9c4b-4df2-8942-18d1d8b5adea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea: Use the large model on few examples shot \n",
    "# i.e. finetune with 25 examples of counterspeech (from our existing dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
