#load in data
sentiment_data <- read_csv('/Users/idahelenedencker/Desktop/STANDBY/Sentiment CSV files/5_types_sen.csv')
#can check number of distinct values for a column
n_distinct(sentiment_data$ID)
#limiting the data to exclude the main posts
# Filter to exclude main posts
sentiment_data <- subset(sentiment_data, main_post == 0)
#load in data
sentiment_data <- read_csv('/Users/idahelenedencker/Desktop/STANDBY/Sentiment CSV files/5_types_sen.csv')
#limiting the data to exclude the main posts
# Filter to exclude main posts
sentiment_data <- subset(sentiment_data, main_post == 0)
# preprocessing the data
#check class of every column
sapply(sentiment_data, class)
#factorize data
# data that cant be 'integer' numbers and have levels are transformed, e.g we can't have 7,3 weeks or 1,2 municipality == transformed
sentiment_data <- sentiment_data %>%
mutate(
intervention = as.factor(intervention),
main_post = as.factor(main_post),
week = as.factor(week),
subcomment = as.factor(subcomment),
municipality = as.factor(municipality),
offentlig_privat = as.factor(offentlig_privat),
roberta_label = as.factor(roberta_label),
name_abbreviation = as.factor(name_abbreviation)
)
#should ID be level??
#check the levels look right
sapply(sentiment_data, levels)
#can check the number of levels for a factor column
nlevels(sentiment_data$name_abbreviation)
#OBS note that the sentiment_data dataframe contains both the post and the comments!
library(ggplot2)
library(gridExtra)
# Plotting positive scores
p1 <- ggplot(sentiment_data, aes(x = intervention, y = pos_score_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "skyblue", color = "black") +
labs(title = "Positive") +
theme_minimal()
# Plotting neutral scores
p2 <- ggplot(sentiment_data, aes(x = intervention, y = neu_score_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "lightgreen", color = "black") +
labs(title = "Neutral") +
theme_minimal()
# Plotting negative scores
p3 <- ggplot(sentiment_data, aes(x = intervention, y = neg_score_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "salmon", color = "black") +
labs(title = "Negative") +
theme_minimal()
# Plotting compound scores
p4 <- ggplot(sentiment_data, aes(x = intervention, y = compound_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "lightgrey", color = "black") +
labs(title = "Compound") +
theme_minimal()
# Combining plots
grid.arrange(p1, p2, p3, p4, ncol = 2)
#looking here we see that when the intervention is yes the comments are generally more negative (lower pos score + higher neg score + lower compound score). This is good to know before starting to model the effect of intervention. So looking at this, we expect that an intervention (intervention==yes) will entail a more negative sentiment in comments compared to no intervention (intervention == no)
#First: check level of the outcome variable
levels(sentiment_data$intervention)
#first level (here no) is encoded as 0 and the second level (here yes) is encoded as 1, estimates we are getting are **log odds of level 1** i.e. the probability of the intervention being yes
##INTERCEPT ONLY MODEL:
#Below are the commands to run an empty model, that is, a model containing no predictors,
empty_model <- glmer(intervention ~ ( 1 | ID), data=sentiment_data, family = "binomial")
summary(empty_model)
no_mixed_model <- glm(intervention ~ compound_roberta,family=binomial(link='logit'),data=sentiment_data)
summary(no_mixed_model)
two_level_model <- glmer(intervention ~ compound_roberta + (1| ID), data = sentiment_data, family = binomial)
summary(two_level_model)
three_level_model <- glmer(intervention ~ compound_roberta + (1| ID/name_abbreviation), data = sentiment_data, family = binomial)
summary(three_level_model)
four_level_model <- glmer(intervention ~ compound_roberta + (1| ID/name_abbreviation/municipality), data = sentiment_data, family = binomial)
summary(four_level_model)
f1 <- performance::model_performance(empty_model, metrics= "common")
f2 <- performance::model_performance(no_mixed_model, metrics= "common")
f3 <- performance::model_performance(two_level_model, metrics= "common")
f4 <- performance::model_performance(three_level_model, metrics= "common")
f5 <- performance::model_performance(four_level_model, metrics= "common")
f6 <- performance::model_performance(no_hier_model, metrics= "common")
no_hier_model <- glmer(intervention ~ compound_roberta + (1| ID) + (1| name_abbreviation) + (1| municipality), data = sentiment_data, family = binomial)
summary(no_hier_model)
f1 <- performance::model_performance(empty_model, metrics= "common")
f2 <- performance::model_performance(no_mixed_model, metrics= "common")
f3 <- performance::model_performance(two_level_model, metrics= "common")
f4 <- performance::model_performance(three_level_model, metrics= "common")
f5 <- performance::model_performance(four_level_model, metrics= "common")
f6 <- performance::model_performance(no_hier_model, metrics= "common")
print("empty_model:")
f1
print("no_mixed_model:")
f2
print("two_level_model:")
f3
print("three_level_model:")
f4
print("four_level_model:")
f5
print("no_hier_model:")
f6
# make a plot like this one: https://blogs.uoregon.edu/rclub/2016/04/05/plotting-your-logistic-regression-models/
#make a model like two_level_model with muni as predictor also:
two_level_model_muni <- glmer(intervention ~ compound_roberta + municipality + (1| ID), data = sentiment_data, family = binomial)
summary(two_level_model_muni)
# check the levels
levels(sentiment_data$municipality)
#Get the coefficients from the new model
fixed_effects <- fixef(two_level_model_muni)
print(fixed_effects)
b0 <- -16.2807   # intercept
rob <- -0.4848
cop <- -1.9202
#set range
compound_range <- seq(from=min(sentiment_data$compound_roberta), to=max(sentiment_data$compound_roberta), by=.01)
#calculate probs for each of the 2 levels
aar_logits <-b0 +
rob * compound_range +
cop *0  #This is the reference group, i.e the first level of the muni i.e. aarhus
cop_logits <-b0 +
rob * compound_range +
cop *1
# Compute the probabilities (this is what will actually get plotted):
aar_probs<- exp(aar_logits)/(1 + exp(aar_logits))
cop_probs<- exp(cop_logits)/(1 + exp(cop_logits))
# the plot can be done in ggplot, which automatically adds legends
# first you have to get the information into a long dataframe, which is what ggplot likes :)
plot.data <- data.frame(aar=aar_probs, cop=cop_probs, compound_roberta=compound_range)
plot.data <- gather(plot.data, key=group, value=probs, aar:cop)
head(plot.data)
#ggplot(plot.data, aes(x=compound_roberta, y=probs, color=group)) + # asking it to set the color by the variable "group" is what makes it draw different lines
#geom_line(lwd=2) +
#labs(x="Compound", y="Probability of the intervention being yes", title="Probability of intervention by municipality")
# Your plotting code
ggplot(plot.data, aes(x=compound_roberta, y=probs, color=group)) +
geom_line(lwd=2) +
labs(x="Compound", y="Probability of the intervention being yes", title="Probability of intervention by municipality") +
# Scale the y-axis using log10 transformation
scale_y_continuous(trans = "log10",
breaks = scales::trans_breaks("log10", function(x) 10^x),
labels = scales::trans_format("log10", scales::math_format(10^.x)))
#ggplot(plot.data, aes(x=compound_roberta, y=log(probs), color=group)) +
#geom_line(lwd=2) +
#labs(x="Compound", y="Log Probability of the intervention being yes", title="Probability of intervention by municipality")
#the results show any possible difference in effect for the different municipalities. Generally, the probability for the intervention being yes is low, hence the very small numbers on the y-axis. The curvature of the 2 lines resemble each other
model <- lmer(compound_roberta ~ municipality + offentlig_privat + total_n_comments + n_total_reactions + (1 | ID), data=sentiment_data)
summary(model)
model_reactions <- lmer(compound_roberta ~ municipality + offentlig_privat + total_n_comments + n_total_reactions + count_like + count_haha+ count_heart+ count_care + count_sad + count_wow + count_angry + (1 | ID), data=sentiment_data_only_comments)
model_reactions <- lmer(compound_roberta ~ municipality + offentlig_privat + total_n_comments + n_total_reactions + count_like + count_haha+ count_heart+ count_care + count_sad + count_wow + count_angry + (1 | ID), data=sentiment_data)
summary(model_reactions)
levels(sentiment_data$offentlig_privat)
# check the levels
levels(sentiment_data$municipality)
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, lme4)
#load in data
sentiment_data <- read_csv('/Users/idahelenedencker/Desktop/STANDBY/Sentiment CSV files/5_types_sen.csv')
#can check number of distinct values for a column
n_distinct(sentiment_data$ID)
#limiting the data to exclude the main posts
sentiment_data <- subset(sentiment_data, main_post == 0)
# preprocessing the data
#check class of every column
sapply(sentiment_data, class)
#factorize data
# data that cant be 'integer' numbers and have levels are transformed, e.g we can't have 7,3 weeks or 1,2 municipality == transformed
sentiment_data <- sentiment_data %>%
mutate(
intervention = as.factor(intervention),
main_post = as.factor(main_post),
week = as.factor(week),
subcomment = as.factor(subcomment),
municipality = as.factor(municipality),
offentlig_privat = as.factor(offentlig_privat),
roberta_label = as.factor(roberta_label),
name_abbreviation = as.factor(name_abbreviation)
)
#check the levels look right
sapply(sentiment_data, levels)
#can check the number of levels for a factor column
nlevels(sentiment_data$name_abbreviation)
library(ggplot2)
library(gridExtra)
# Plotting positive scores
p1 <- ggplot(sentiment_data, aes(x = intervention, y = pos_score_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "skyblue", color = "black") +
labs(title = "Positive") +
theme_minimal()
# Plotting neutral scores
p2 <- ggplot(sentiment_data, aes(x = intervention, y = neu_score_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "lightgreen", color = "black") +
labs(title = "Neutral") +
theme_minimal()
# Plotting negative scores
p3 <- ggplot(sentiment_data, aes(x = intervention, y = neg_score_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "salmon", color = "black") +
labs(title = "Negative") +
theme_minimal()
# Plotting compound scores
p4 <- ggplot(sentiment_data, aes(x = intervention, y = compound_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "lightgrey", color = "black") +
labs(title = "Compound") +
theme_minimal()
# Combining plots
grid.arrange(p1, p2, p3, p4, ncol = 2)
#looking here we see that when the intervention is yes the comments are generally more negative (lower pos score + higher neg score + lower compound score). This is good to know before starting to model the effect of intervention. So looking at this, we expect that an intervention (intervention==yes) will entail a more negative sentiment in comments compared to no intervention (intervention == no)
#First: check level of the outcome variable
levels(sentiment_data$intervention)
#first level (here no) is encoded as 0 and the second level (here yes) is encoded as 1, estimates we are getting are **log odds of level 1** i.e. the probability of the intervention being yes
#remember that in logistic regression coefficients are a on log-oods scale = positive means increase in possibility
##log odds of intervention is predicted by compound score (fixed effect) allowing some of the models to vary by groups (random effects)
##INTERCEPT ONLY MODEL:
#Below are the commands to run an empty model, that is, a model containing no predictors,
empty_model <- glmer(intervention ~ ( 1 | ID), data=sentiment_data, family = "binomial")
summary(empty_model)
#There is substantial variability in the intercept across different levels of ID (Std.Dev. = 84.32), suggesting that the random effect of ID is important in the model.
# The intercept of -17.455 is significantly different from zero, indicating that on average, without considering the random effect, the log odds of intervention are very low. That makes sense since there are way more no-intervention posts, so the general probability of the post being intervention is very low
## SIMPLE LOGISTIC REGRESSION MODEL (no mixed effects):
#no mixed effects model
no_mixed_model <- glm(intervention ~ compound_roberta,family=binomial(link='logit'),data=sentiment_data)
summary(no_mixed_model)
#no random effects: assume all data are independent from each other (not the case in our data though)
#when the compound score increase with 1 (more positive sentiment) the log odds of the intervention being yes decreases with -0.59, i.e. more positive sentiment entails a lower probability of the intervention being yes, in accordance with what the plots above are showing. The predictor is significant here.
## 2-LEVEL MODEL (Comments nested in ID):
two_level_model <- glmer(intervention ~ compound_roberta + (1| ID), data = sentiment_data, family = binomial)
summary(two_level_model)
# allowing to vary by ID
# The intercept of the fixed effects are still negative, indicating that in increase in compound decreases the possibility of intervention. After having accounted for the fact that some of the variance in sentiment can be accounted for by ID, not 'much is left' for the model to explain the compound by the intervention (so significance)
## 3-LEVEL MODEL (comments nested in ID nested in politicians):
three_level_model <- glmer(intervention ~ compound_roberta + (1| ID/name_abbreviation), data = sentiment_data, family = binomial)
summary(three_level_model)
# Same case as with the 2-level model
## 4-LEVEL MODEL (comments nested in ID nested in politicians nested in municipality):
four_level_model <- glmer(intervention ~ compound_roberta + (1| ID/name_abbreviation/municipality), data = sentiment_data, family = binomial)
summary(four_level_model)
#Same case again
## NO HIERARCHY MODEL
#Exploratory: a model with separate random intercepts for each grouping variable without explicitly specifying the nesting. This is assuming that the grouping variables are independent of each other.
no_hier_model <- glmer(intervention ~ compound_roberta + (1| ID) + (1| name_abbreviation) + (1| municipality), data = sentiment_data, family = binomial)
summary(no_hier_model)
#compare the different models:
f1 <- performance::model_performance(empty_model, metrics= "common")
f2 <- performance::model_performance(no_mixed_model, metrics= "common")
f3 <- performance::model_performance(two_level_model, metrics= "common")
f4 <- performance::model_performance(three_level_model, metrics= "common")
f5 <- performance::model_performance(four_level_model, metrics= "common")
f6 <- performance::model_performance(no_hier_model, metrics= "common")
print("empty_model:")
f1
print("no_mixed_model:")
f2
print("two_level_model:")
f3
print("three_level_model:")
f4
print("four_level_model:")
f5
print("no_hier_model:")
f6
# The empty model and and the 2 level models has the lowest AIC indicating better model performance. These however are not very useful to us. The empty model has obviously no predictors. The 2-level model does not account for the nestedness in the data.
# make a plot like this one: https://blogs.uoregon.edu/rclub/2016/04/05/plotting-your-logistic-regression-models/
#make a model like two_level_model with muni as predictor also:
two_level_model_muni <- glmer(intervention ~ compound_roberta + municipality + (1| ID), data = sentiment_data, family = binomial)
summary(two_level_model_muni)
# check the levels
levels(sentiment_data$municipality)
#Get the coefficients from the new model
fixed_effects <- fixef(two_level_model_muni)
print(fixed_effects)
b0 <- -16.2807   # intercept
rob <- -0.4848
cop <- -1.9202
#set range
compound_range <- seq(from=min(sentiment_data$compound_roberta), to=max(sentiment_data$compound_roberta), by=.01)
#calculate probs for each of the 2 levels
aar_logits <-b0 +
rob * compound_range +
cop *0  #This is the reference group, i.e the first level of the muni i.e. aarhus
cop_logits <-b0 +
rob * compound_range +
cop *1
# Compute the probabilities (this is what will actually get plotted):
aar_probs<- exp(aar_logits)/(1 + exp(aar_logits))
cop_probs<- exp(cop_logits)/(1 + exp(cop_logits))
# the plot can be done in ggplot, which automatically adds legends
# first you have to get the information into a long dataframe, which is what ggplot likes
plot.data <- data.frame(aar=aar_probs, cop=cop_probs, compound_roberta=compound_range)
plot.data <- gather(plot.data, key=group, value=probs, aar:cop)
head(plot.data)
# plotting code
ggplot(plot.data, aes(x=compound_roberta, y=probs, color=group)) +
geom_line(lwd=2) +
labs(x="Compound", y="Probability of the intervention being yes", title="Probability of intervention by municipality") +
# Scale the y-axis using log10 transformation
scale_y_continuous(trans = "log10",
breaks = scales::trans_breaks("log10", function(x) 10^x),
labels = scales::trans_format("log10", scales::math_format(10^.x)))
#the results show any possible difference in effect for the different municipalities. Generally, the probability for the intervention being yes is low, hence the very small numbers on the y-axis. The curvature of the 2 lines resemble each other
#Explorative models with more predictors
model <- lmer(compound_roberta ~ municipality + offentlig_privat + total_n_comments + n_total_reactions + (1 | ID), data=sentiment_data)
summary(model)
levels(sentiment_data$offentlig_privat)
#0.2915654 is the compound score when municipality is århus, offentlig, and total number of comments and reaction are both 0. The estimates are the change in compound when all the other predictors are being held constant. If e.g. the level change from Århus to Copenhagen it will entail a change in compound by -0.1795006 (still offentlig, and total number of comments and reaction are both 0) This is in accordance with previous findings showing that comments are generally more negative on copenhagen posts.
#the estimate for offentlig_privatP -0.0013759 shows that a change from offentlig to privat will entail a drop in sentiment i.e more negative sentiment. The low estimates for n_total_reactions and total_n_comments show that an increase in comments per post or n_total_reactions will only entail a very small increase in sentiment
#incorporate count of different types of reactions, to determine if any types of reactions, e.g. 'angry' or 'sad' will significantly predict the sentiment
model_reactions <- lmer(compound_roberta ~ municipality + offentlig_privat + total_n_comments + n_total_reactions + count_like + count_haha+ count_heart+ count_care + count_sad + count_wow + count_angry + (1 | ID), data=sentiment_data)
summary(model_reactions)
#interestingly, only an increase in the count of heart and care reactions to a comment will increase the compound score. Like the model above, this one also shows that if the level change from Århus to Copenhagen it will entail a negative change in compound by -0.2156951
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, lme4)
#load in data
sentiment_data <- read_csv('/Users/idahelenedencker/Desktop/STANDBY/Sentiment CSV files/5_types_sen.csv')
#can check number of distinct values for a column
n_distinct(sentiment_data$ID)
#limiting the data to exclude the main posts
sentiment_data <- subset(sentiment_data, main_post == 0)
# preprocessing the data
#check class of every column
sapply(sentiment_data, class)
#factorize data
# data that cant be 'integer' numbers and have levels are transformed, e.g we can't have 7,3 weeks or 1,2 municipality == transformed
sentiment_data <- sentiment_data %>%
mutate(
intervention = as.factor(intervention),
main_post = as.factor(main_post),
week = as.factor(week),
subcomment = as.factor(subcomment),
municipality = as.factor(municipality),
offentlig_privat = as.factor(offentlig_privat),
roberta_label = as.factor(roberta_label),
name_abbreviation = as.factor(name_abbreviation)
)
#check the levels look right
sapply(sentiment_data, levels)
#can check the number of levels for a factor column
nlevels(sentiment_data$name_abbreviation)
library(ggplot2)
library(gridExtra)
# Plotting positive scores
p1 <- ggplot(sentiment_data, aes(x = intervention, y = pos_score_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "skyblue", color = "black") +
labs(title = "Positive") +
theme_minimal()
# Plotting neutral scores
p2 <- ggplot(sentiment_data, aes(x = intervention, y = neu_score_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "lightgreen", color = "black") +
labs(title = "Neutral") +
theme_minimal()
# Plotting negative scores
p3 <- ggplot(sentiment_data, aes(x = intervention, y = neg_score_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "salmon", color = "black") +
labs(title = "Negative") +
theme_minimal()
# Plotting compound scores
p4 <- ggplot(sentiment_data, aes(x = intervention, y = compound_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "lightgrey", color = "black") +
labs(title = "Compound") +
theme_minimal()
# Combining plots
grid.arrange(p1, p2, p3, p4, ncol = 2)
#looking here we see that when the intervention is yes the comments are generally more negative (lower pos score + higher neg score + lower compound score). This is good to know before starting to model the effect of intervention. So looking at this, we expect that an intervention (intervention==yes) will entail a more negative sentiment in comments compared to no intervention (intervention == no)
#First: check level of the outcome variable
levels(sentiment_data$intervention)
#first level (here no) is encoded as 0 and the second level (here yes) is encoded as 1, estimates we are getting are **log odds of level 1** i.e. the probability of the intervention being yes
#remember that in logistic regression coefficients are a on log-oods scale = positive means increase in possibility
##log odds of intervention is predicted by compound score (fixed effect) allowing some of the models to vary by groups (random effects)
##INTERCEPT ONLY MODEL:
#Below are the commands to run an empty model, that is, a model containing no predictors,
empty_model <- glmer(intervention ~ ( 1 | ID), data=sentiment_data, family = "binomial")
summary(empty_model)
#There is substantial variability in the intercept across different levels of ID (Std.Dev. = 84.32), suggesting that the random effect of ID is important in the model.
# The intercept of -17.455 is significantly different from zero, indicating that on average, without considering the random effect, the log odds of intervention are very low. That makes sense since there are way more no-intervention posts, so the general probability of the post being intervention is very low
## SIMPLE LOGISTIC REGRESSION MODEL (no mixed effects):
#no mixed effects model
no_mixed_model <- glm(intervention ~ compound_roberta,family=binomial(link='logit'),data=sentiment_data)
summary(no_mixed_model)
#no random effects: assume all data are independent from each other (not the case in our data though)
#when the compound score increase with 1 (more positive sentiment) the log odds of the intervention being yes decreases with -0.59, i.e. more positive sentiment entails a lower probability of the intervention being yes, in accordance with what the plots above are showing. The predictor is significant here.
## 2-LEVEL MODEL (Comments nested in ID):
two_level_model <- glmer(intervention ~ compound_roberta + (1| ID), data = sentiment_data, family = binomial)
summary(two_level_model)
# allowing to vary by ID
# The intercept of the fixed effects are still negative, indicating that in increase in compound decreases the possibility of intervention. After having accounted for the fact that some of the variance in sentiment can be accounted for by ID, not 'much is left' for the model to explain the compound by the intervention (so significance)
## 3-LEVEL MODEL (comments nested in ID nested in politicians):
three_level_model <- glmer(intervention ~ compound_roberta + (1| ID/name_abbreviation), data = sentiment_data, family = binomial)
summary(three_level_model)
# Same case as with the 2-level model
## 4-LEVEL MODEL (comments nested in ID nested in politicians nested in municipality):
four_level_model <- glmer(intervention ~ compound_roberta + (1| ID/name_abbreviation/municipality), data = sentiment_data, family = binomial)
summary(four_level_model)
#Same case again
## NO HIERARCHY MODEL
#Exploratory: a model with separate random intercepts for each grouping variable without explicitly specifying the nesting. This is assuming that the grouping variables are independent of each other.
no_hier_model <- glmer(intervention ~ compound_roberta + (1| ID) + (1| name_abbreviation) + (1| municipality), data = sentiment_data, family = binomial)
summary(no_hier_model)
#compare the different models:
f1 <- performance::model_performance(empty_model, metrics= "common")
f2 <- performance::model_performance(no_mixed_model, metrics= "common")
f3 <- performance::model_performance(two_level_model, metrics= "common")
f4 <- performance::model_performance(three_level_model, metrics= "common")
f5 <- performance::model_performance(four_level_model, metrics= "common")
f6 <- performance::model_performance(no_hier_model, metrics= "common")
print("empty_model:")
f1
print("no_mixed_model:")
f2
print("two_level_model:")
f3
print("three_level_model:")
f4
print("four_level_model:")
f5
print("no_hier_model:")
f6
# The empty model and and the 2 level models has the lowest AIC indicating better model performance. These however are not very useful to us. The empty model has obviously no predictors. The 2-level model does not account for the nestedness in the data.
# make a plot like this one: https://blogs.uoregon.edu/rclub/2016/04/05/plotting-your-logistic-regression-models/
#make a model like two_level_model with muni as predictor also:
two_level_model_muni <- glmer(intervention ~ compound_roberta + municipality + (1| ID), data = sentiment_data, family = binomial)
summary(two_level_model_muni)
# check the levels
levels(sentiment_data$municipality)
#Get the coefficients from the new model
fixed_effects <- fixef(two_level_model_muni)
print(fixed_effects)
b0 <- -16.2807   # intercept
rob <- -0.4848
cop <- -1.9202
#set range
compound_range <- seq(from=min(sentiment_data$compound_roberta), to=max(sentiment_data$compound_roberta), by=.01)
#calculate probs for each of the 2 levels
aar_logits <-b0 +
rob * compound_range +
cop *0  #This is the reference group, i.e the first level of the muni i.e. aarhus
cop_logits <-b0 +
rob * compound_range +
cop *1
# Compute the probabilities (this is what will actually get plotted):
aar_probs<- exp(aar_logits)/(1 + exp(aar_logits))
cop_probs<- exp(cop_logits)/(1 + exp(cop_logits))
# the plot can be done in ggplot, which automatically adds legends
# first you have to get the information into a long dataframe, which is what ggplot likes
plot.data <- data.frame(aar=aar_probs, cop=cop_probs, compound_roberta=compound_range)
plot.data <- gather(plot.data, key=group, value=probs, aar:cop)
head(plot.data)
# plotting code
ggplot(plot.data, aes(x=compound_roberta, y=probs, color=group)) +
geom_line(lwd=2) +
labs(x="Compound", y="Probability of the intervention being yes", title="Probability of intervention by municipality") +
# Scale the y-axis using log10 transformation
scale_y_continuous(trans = "log10",
breaks = scales::trans_breaks("log10", function(x) 10^x),
labels = scales::trans_format("log10", scales::math_format(10^.x)))
#the results show any possible difference in effect for the different municipalities. Generally, the probability for the intervention being yes is low, hence the very small numbers on the y-axis. The curvature of the 2 lines resemble each other
#Explorative models with more predictors
model <- lmer(compound_roberta ~ municipality + offentlig_privat + total_n_comments + n_total_reactions + (1 | ID), data=sentiment_data)
summary(model)
levels(sentiment_data$offentlig_privat)
#0.2915654 is the compound score when municipality is århus, offentlig, and total number of comments and reaction are both 0. The estimates are the change in compound when all the other predictors are being held constant. If e.g. the level change from Århus to Copenhagen it will entail a change in compound by -0.1795006 (still offentlig, and total number of comments and reaction are both 0) This is in accordance with previous findings showing that comments are generally more negative on copenhagen posts.
#the estimate for offentlig_privatP -0.0013759 shows that a change from offentlig to privat will entail a drop in sentiment i.e more negative sentiment. The low estimates for n_total_reactions and total_n_comments show that an increase in comments per post or n_total_reactions will only entail a very small increase in sentiment
#incorporate count of different types of reactions, to determine if any types of reactions, e.g. 'angry' or 'sad' will significantly predict the sentiment
model_reactions <- lmer(compound_roberta ~ municipality + offentlig_privat + total_n_comments + n_total_reactions + count_like + count_haha+ count_heart+ count_care + count_sad + count_wow + count_angry + (1 | ID), data=sentiment_data)
summary(model_reactions)
#interestingly, only an increase in the count of heart and care reactions to a comment will increase the compound score. Like the model above, this one also shows that if the level change from Århus to Copenhagen it will entail a negative change in compound by -0.2156951
library(tidyverse)
library(dplyr)
library(magrittr)
data <- read_csv('/Users/idahelenedencker/Desktop/STANDBY/all_files_final.csv',show_col_types = FALSE)
data <- read_csv('/Users/idahelenedencker/Desktop/STANDBY/all_files_final.csv',show_col_types = FALSE)
data <- read_csv('/Users/idahelenedencker/Desktop/STANDBY/Facebook Field Study with Local Politicians/all_files_final.csv',show_col_types = FALSE)
#counts:
#how many posts: 1601
data$main_post <- as.numeric(data$main_post)
sum(data$main_post)
#how many different politicians: 77
unique_counts <- table(data$name_abbreviation) # Count unique occurrences
print(unique_counts) # Print the counts
total_unique <- length(unique(data$name_abbreviation))
print(total_unique)  # Print the total number of unique occurrences
#how many politicians from aarhus: 27
unique_aarhus <- data %>%
filter(municipality == "aarhus") %>%
pull(name_abbreviation) %>%
unique() %>%
length()
print(unique_aarhus) # Print the result
#how many politicians from copenhagen: 50
unique_copenhagen <- data %>%
filter(municipality == "copenhagen") %>%
pull(name_abbreviation) %>%
unique() %>%
length()
print(unique_copenhagen) # Print the result
#how many politicians in the intervention: 11
unique <- data %>%
filter(intervention == "yes") %>%
pull(name_abbreviation) %>%
unique() %>%
length()
print(unique) # Print the result
#what politicians
unique_name <- data %>%
filter(intervention == "yes") %>%
pull(name_abbreviation) %>%
unique()
print(unique_name) # Print the result
#what politicians
unique_name_df <- data %>%
filter(intervention == "yes")
View(unique_name_df)
unique_name_df <- data %>%
filter(intervention == "yes") %>%
distinct(name_abbreviation, .keep_all = TRUE)
View(unique_name_df)
