---
title: "Multilevel modelling"
author: "Ida Dencker"
date: "2024-05-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
pacman::p_load(tidyverse, lme4) 
```


```{r}
#load in data
sentiment_data <- read_csv('/Users/idahelenedencker/Desktop/STANDBY/Sentiment CSV files/5_types_sen.csv')

#can check number of distinct values for a column
n_distinct(sentiment_data$ID)

#limiting the data to exclude the main posts
sentiment_data <- subset(sentiment_data, main_post == 0)
```

# Multilevel modelling (predictive modelling)

List of predictors:
- offentlig_privat
- week
- n_post_day
- municipality
- subcomment
- total_n_comments
- total_n_reactions
- count_like
- count_care
- count_heart
- count_haha
- count_sad
- count_angry
- count_wow
- count_heart

sentiment predictors
- neg_vader
- neu_vader
- pos_vader
- compound_vader
- pos_score_roberta
- neg_score_roberta
- neu_score_roberta
- compound_roberta
- roberta_label
- bert_emotion_label 
- attack
- rec-nition

outcome
- intervention

```{r}
# preprocessing the data

#check class of every column
sapply(sentiment_data, class)

#factorize data
# data that cant be 'integer' numbers and have levels are transformed, e.g we can't have 7,3 weeks or 1,2 municipality == transformed 
sentiment_data <- sentiment_data %>%
  mutate(
    intervention = as.factor(intervention),
    main_post = as.factor(main_post),
    week = as.factor(week),
    subcomment = as.factor(subcomment),
    municipality = as.factor(municipality),
    offentlig_privat = as.factor(offentlig_privat),
    roberta_label = as.factor(roberta_label),
    name_abbreviation = as.factor(name_abbreviation)
  )


#check the levels look right 
sapply(sentiment_data, levels)

#can check the number of levels for a factor column
nlevels(sentiment_data$name_abbreviation)


```

#getting an idea of how the data looks, to understand the output of the models better

```{r}
library(ggplot2)
library(gridExtra)

# Plotting positive scores
p1 <- ggplot(sentiment_data, aes(x = intervention, y = pos_score_roberta)) +
  geom_bar(stat = "summary", fun = "mean", fill = "skyblue", color = "black") +
  labs(title = "Positive") +
  theme_minimal()

# Plotting neutral scores
p2 <- ggplot(sentiment_data, aes(x = intervention, y = neu_score_roberta)) +
  geom_bar(stat = "summary", fun = "mean", fill = "lightgreen", color = "black") +
  labs(title = "Neutral") +
  theme_minimal()

# Plotting negative scores
p3 <- ggplot(sentiment_data, aes(x = intervention, y = neg_score_roberta)) +
  geom_bar(stat = "summary", fun = "mean", fill = "salmon", color = "black") +
  labs(title = "Negative") +
  theme_minimal()

# Plotting compound scores
p4 <- ggplot(sentiment_data, aes(x = intervention, y = compound_roberta)) +
  geom_bar(stat = "summary", fun = "mean", fill = "lightgrey", color = "black") +
  labs(title = "Compound") +
  theme_minimal()


# Combining plots
grid.arrange(p1, p2, p3, p4, ncol = 2)


#looking here we see that when the intervention is yes the comments are generally more negative (lower pos score + higher neg score + lower compound score). This is good to know before starting to model the effect of intervention. So looking at this, we expect that an intervention (intervention==yes) will entail a more negative sentiment in comments compared to no intervention (intervention == no)

```


Now we can start on making multilevel logistic regression models predicting intervention, i.e intervention as a function of different predictors

The data has a 4 level structure with nestedness: comments (here comments are represented by a sentiment score) nested in posts (ID) nested in politicians (name_abbreviation) nested in kommune (municipality)


```{r}
#First: check level of the outcome variable 
levels(sentiment_data$intervention)
#first level (here no) is encoded as 0 and the second level (here yes) is encoded as 1, estimates we are getting are **log odds of level 1** i.e. the probability of the intervention being yes 
```

read: https://rips-irsp.com/articles/10.5334/irsp.90

predictors
- compound_vader
- compound_roberta
- bert_emotion_label
- attack
- rec-nition
- municipality 
- offentlig_privat
- total_n_comments
- total_n_reactions
- count_XX


a '/' is the syntax used to account for nestedness. Nested random effects are hierarchical, with one level nested within another meaning that the same politician e.g. cant be part of multiple municipalities 

It is different from using ':' which is used to specify crossed random effects. Crossed random effects are random effects that are not nested within each other but are crossed with each other. For example, if you have random effects for both municipalities and politicians, and each politician can make posts in multiple municipalities and each municipality can have multiple politicians, you might use the :` syntax to specify crossed random effects:


```{r}
#remember that in logistic regression coefficients are a on log-oods scale = positive means increase in possibility
##log odds of intervention is predicted by compound score (fixed effect) allowing some of the models to vary by groups (random effects)




##INTERCEPT ONLY MODEL:

#Below are the commands to run an empty model, that is, a model containing no predictors, 
empty_model <- glmer(intervention ~ ( 1 | ID), data=sentiment_data, family = "binomial")
summary(empty_model)
#There is substantial variability in the intercept across different levels of ID (Std.Dev. = 84.32), suggesting that the random effect of ID is important in the model.
# The intercept of -17.455 is significantly different from zero, indicating that on average, without considering the random effect, the log odds of intervention are very low. That makes sense since there are way more no-intervention posts, so the general probability of the post being intervention is very low




## SIMPLE LOGISTIC REGRESSION MODEL (no mixed effects):

#no mixed effects model
no_mixed_model <- glm(intervention ~ compound_roberta,family=binomial(link='logit'),data=sentiment_data)
summary(no_mixed_model)
#no random effects: assume all data are independent from each other (not the case in our data though)
#when the compound score increase with 1 (more positive sentiment) the log odds of the intervention being yes decreases with -0.59, i.e. more positive sentiment entails a lower probability of the intervention being yes, in accordance with what the plots above are showing. The predictor is significant here.  



## 2-LEVEL MODEL (Comments nested in ID):
two_level_model <- glmer(intervention ~ compound_roberta + (1| ID), data = sentiment_data, family = binomial)
summary(two_level_model)
# allowing to vary by ID 
# The intercept of the fixed effects are still negative, indicating that in increase in compound decreases the possibility of intervention. After having accounted for the fact that some of the variance in sentiment can be accounted for by ID, not 'much is left' for the model to explain the compound by the intervention (so significance)




## 3-LEVEL MODEL (comments nested in ID nested in politicians):
three_level_model <- glmer(intervention ~ compound_roberta + (1| ID/name_abbreviation), data = sentiment_data, family = binomial)
summary(three_level_model)
# Same case as with the 2-level model 




## 4-LEVEL MODEL (comments nested in ID nested in politicians nested in municipality):
four_level_model <- glmer(intervention ~ compound_roberta + (1| ID/name_abbreviation/municipality), data = sentiment_data, family = binomial)
summary(four_level_model)
#Same case again



## NO HIERARCHY MODEL

#Exploratory: a model with separate random intercepts for each grouping variable without explicitly specifying the nesting. This is assuming that the grouping variables are independent of each other.
no_hier_model <- glmer(intervention ~ compound_roberta + (1| ID) + (1| name_abbreviation) + (1| municipality), data = sentiment_data, family = binomial)
summary(no_hier_model)



#compare the different models:
f1 <- performance::model_performance(empty_model, metrics= "common")
f2 <- performance::model_performance(no_mixed_model, metrics= "common")
f3 <- performance::model_performance(two_level_model, metrics= "common")
f4 <- performance::model_performance(three_level_model, metrics= "common")
f5 <- performance::model_performance(four_level_model, metrics= "common")
f6 <- performance::model_performance(no_hier_model, metrics= "common")

print("empty_model:")
f1
print("no_mixed_model:")
f2
print("two_level_model:")
f3
print("three_level_model:")
f4
print("four_level_model:")
f5
print("no_hier_model:")
f6

# The empty model and and the 2 level models has the lowest AIC indicating better model performance. These however are not very useful to us. The empty model has obviously no predictors. The 2-level model does not account for the nestedness in the data. 

```

```{r}
# make a plot like this one: https://blogs.uoregon.edu/rclub/2016/04/05/plotting-your-logistic-regression-models/


#make a model like two_level_model with muni as predictor also:
two_level_model_muni <- glmer(intervention ~ compound_roberta + municipality + (1| ID), data = sentiment_data, family = binomial)
summary(two_level_model_muni)


# check the levels
levels(sentiment_data$municipality)


#Get the coefficients from the new model
fixed_effects <- fixef(two_level_model_muni)
print(fixed_effects)

b0 <- -16.2807   # intercept
rob <- -0.4848 
cop <- -1.9202

#set range
compound_range <- seq(from=min(sentiment_data$compound_roberta), to=max(sentiment_data$compound_roberta), by=.01)

#calculate probs for each of the 2 levels
aar_logits <-b0 + 
  rob * compound_range +
  cop *0  #This is the reference group, i.e the first level of the muni i.e. aarhus

cop_logits <-b0 + 
  rob * compound_range +
  cop *1  

# Compute the probabilities (this is what will actually get plotted):
aar_probs<- exp(aar_logits)/(1 + exp(aar_logits))
cop_probs<- exp(cop_logits)/(1 + exp(cop_logits))


# the plot can be done in ggplot, which automatically adds legends 
# first you have to get the information into a long dataframe, which is what ggplot likes 
plot.data <- data.frame(aar=aar_probs, cop=cop_probs, compound_roberta=compound_range)
plot.data <- gather(plot.data, key=group, value=probs, aar:cop)
head(plot.data)


# plotting code
ggplot(plot.data, aes(x=compound_roberta, y=probs, color=group)) + 
  geom_line(lwd=2) + 
  labs(x="Compound", y="Probability of the intervention being yes", title="Probability of intervention by municipality") +
  
  # Scale the y-axis using log10 transformation
  scale_y_continuous(trans = "log10", 
                     breaks = scales::trans_breaks("log10", function(x) 10^x),
                     labels = scales::trans_format("log10", scales::math_format(10^.x)))



#the results show any possible difference in effect for the different municipalities. Generally, the probability for the intervention being yes is low, hence the very small numbers on the y-axis. The curvature of the 2 lines resemble each other 
```



# predcting the sentiment, i.e. can the sentiment of the comments be predicted by e.g. municipality, n_likes, n_hearts, politician (name_abbreviation)

predictors
- compound_vader
- compound_roberta
- bert_emotion_label
- attack
- rec-nition
- municipality 
- offentlig_privat
- total_n_comments
- n_total_reactions
- count_XX

```{r}
#Explorative models with more predictors 

model <- lmer(compound_roberta ~ municipality + offentlig_privat + total_n_comments + n_total_reactions + (1 | ID), data=sentiment_data)

summary(model)

levels(sentiment_data$offentlig_privat)

#0.2915654 is the compound score when municipality is århus, offentlig, and total number of comments and reaction are both 0. The estimates are the change in compound when all the other predictors are being held constant. If e.g. the level change from Århus to Copenhagen it will entail a change in compound by -0.1795006 (still offentlig, and total number of comments and reaction are both 0) This is in accordance with previous findings showing that comments are generally more negative on copenhagen posts. 

#the estimate for offentlig_privatP -0.0013759 shows that a change from offentlig to privat will entail a drop in sentiment i.e more negative sentiment. The low estimates for n_total_reactions and total_n_comments show that an increase in comments per post or n_total_reactions will only entail a very small increase in sentiment


#incorporate count of different types of reactions, to determine if any types of reactions, e.g. 'angry' or 'sad' will significantly predict the sentiment 
model_reactions <- lmer(compound_roberta ~ municipality + offentlig_privat + total_n_comments + n_total_reactions + count_like + count_haha+ count_heart+ count_care + count_sad + count_wow + count_angry + (1 | ID), data=sentiment_data)
summary(model_reactions)

#interestingly, only an increase in the count of heart and care reactions to a comment will increase the compound score. Like the model above, this one also shows that if the level change from Århus to Copenhagen it will entail a negative change in compound by -0.2156951 

```


